{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2822650,"sourceType":"datasetVersion","datasetId":1715304},{"sourceId":13015029,"sourceType":"datasetVersion","datasetId":8239947}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-10T16:51:39.099199Z","iopub.execute_input":"2025-09-10T16:51:39.099431Z","iopub.status.idle":"2025-09-10T16:51:48.830515Z","shell.execute_reply.started":"2025-09-10T16:51:39.099406Z","shell.execute_reply":"2025-09-10T16:51:48.829786Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/aptos2019/valid.csv\n/kaggle/input/aptos2019/test.csv\n/kaggle/input/aptos2019/train_1.csv\n/kaggle/input/aptos2019/val_images/val_images/17f6c7072f61.png\n/kaggle/input/aptos2019/val_images/val_images/0243404e8a00.png\n/kaggle/input/aptos2019/val_images/val_images/0083ee8054ee.png\n/kaggle/input/aptos2019/val_images/val_images/0ac436400db4.png\n/kaggle/input/aptos2019/val_images/val_images/0d0a21fd354f.png\n/kaggle/input/aptos2019/val_images/val_images/02da652c74b8.png\n/kaggle/input/aptos2019/val_images/val_images/15e96e848b46.png\n/kaggle/input/aptos2019/val_images/val_images/059bc89df7f4.png\n/kaggle/input/aptos2019/val_images/val_images/04d029cfb612.png\n/kaggle/input/aptos2019/val_images/val_images/08752092140d.png\n/kaggle/input/aptos2019/val_images/val_images/0ef4c61dc056.png\n/kaggle/input/aptos2019/val_images/val_images/1a7e3356b39c.png\n/kaggle/input/aptos2019/val_images/val_images/06be1092a062.png\n/kaggle/input/aptos2019/val_images/val_images/03a7f4a5786f.png\n/kaggle/input/aptos2019/val_images/val_images/0d0b8fc9ab5c.png\n/kaggle/input/aptos2019/val_images/val_images/0125fbd2e791.png\n/kaggle/input/aptos2019/val_images/val_images/0e43c8298fc0.png\n/kaggle/input/aptos2019/val_images/val_images/09662e462531.png\n/kaggle/input/aptos2019/val_images/val_images/12e6e66c80a7.png\n/kaggle/input/aptos2019/val_images/val_images/0afbeeef0ff7.png\n/kaggle/input/aptos2019/val_images/val_images/0eff8eacb2f7.png\n/kaggle/input/aptos2019/val_images/val_images/1ade1e949383.png\n/kaggle/input/aptos2019/val_images/val_images/0abf0c485f66.png\n/kaggle/input/aptos2019/val_images/val_images/0a61bddab956.png\n/kaggle/input/aptos2019/val_images/val_images/1608c82a263f.png\n/kaggle/input/aptos2019/val_images/val_images/19244004583f.png\n/kaggle/input/aptos2019/val_images/val_images/064af6592ba6.png\n/kaggle/input/aptos2019/val_images/val_images/12058bbb8299.png\n/kaggle/input/aptos2019/val_images/val_images/0a9ec1e99ce4.png\n/kaggle/input/aptos2019/val_images/val_images/15f8d769935c.png\n/kaggle/input/aptos2019/val_images/val_images/093cf723fede.png\n/kaggle/input/aptos2019/val_images/val_images/13073f075a56.png\n/kaggle/input/aptos2019/val_images/val_images/1509d097b69a.png\n/kaggle/input/aptos2019/val_images/val_images/101b9ebfc720.png\n/kaggle/input/aptos2019/val_images/val_images/0ae2dd2e09ea.png\n/kaggle/input/aptos2019/val_images/val_images/0d310aba6373.png\n/kaggle/input/aptos2019/val_images/val_images/00f6c1be5a33.png\n/kaggle/input/aptos2019/val_images/val_images/09c8323c612e.png\n/kaggle/input/aptos2019/val_images/val_images/07596907347b.png\n/kaggle/input/aptos2019/val_images/val_images/1a19f2ef4472.png\n/kaggle/input/aptos2019/val_images/val_images/022f820027b8.png\n/kaggle/input/aptos2019/val_images/val_images/10a5026eb8e6.png\n/kaggle/input/aptos2019/val_images/val_images/17eb5d4ad740.png\n/kaggle/input/aptos2019/val_images/val_images/1541226c5d72.png\n/kaggle/input/aptos2019/val_images/val_images/032d7b0b4bf6.png\n/kaggle/input/aptos2019/val_images/val_images/05cd0178ccfe.png\n/kaggle/input/aptos2019/val_images/val_images/01c7808d901d.png\n/kaggle/input/aptos2019/val_images/val_images/060e00d1e2ab.png\n/kaggle/input/aptos2019/val_images/val_images/002c21358ce6.png\n/kaggle/input/aptos2019/val_images/val_images/08b6e3240858.png\n/kaggle/input/aptos2019/val_images/val_images/0fc6829da85b.png\n/kaggle/input/aptos2019/val_images/val_images/0d744aed4d64.png\n/kaggle/input/aptos2019/val_images/val_images/194814669fee.png\n/kaggle/input/aptos2019/val_images/val_images/1943983492e5.png\n/kaggle/input/aptos2019/val_images/val_images/18af532e7e1e.png\n/kaggle/input/aptos2019/val_images/val_images/143db89c11c8.png\n/kaggle/input/aptos2019/val_images/val_images/054b1b305160.png\n/kaggle/input/aptos2019/val_images/val_images/00cc2b75cddd.png\n/kaggle/input/aptos2019/val_images/val_images/17e6116b89b3.png\n/kaggle/input/aptos2019/val_images/val_images/1124ffcd76c2.png\n/kaggle/input/aptos2019/val_images/val_images/0ada12c0e78f.png\n/kaggle/input/aptos2019/val_images/val_images/04aef84a2cc1.png\n/kaggle/input/aptos2019/val_images/val_images/10f6ef37fe43.png\n/kaggle/input/aptos2019/val_images/val_images/10ecc5292ab1.png\n/kaggle/input/aptos2019/val_images/val_images/150fc7127582.png\n/kaggle/input/aptos2019/val_images/val_images/17d7d6b092f4.png\n/kaggle/input/aptos2019/val_images/val_images/188a9323be03.png\n/kaggle/input/aptos2019/val_images/val_images/15cd5f52d300.png\n/kaggle/input/aptos2019/val_images/val_images/00e4ddff966a.png\n/kaggle/input/aptos2019/val_images/val_images/0afdfe5f422c.png\n/kaggle/input/aptos2019/val_images/val_images/1409ab48175a.png\n/kaggle/input/aptos2019/val_images/val_images/07d8db76b301.png\n/kaggle/input/aptos2019/val_images/val_images/0ca0aee4d57e.png\n/kaggle/input/aptos2019/val_images/val_images/18ce0cdc473d.png\n/kaggle/input/aptos2019/val_images/val_images/10eefba568dd.png\n/kaggle/input/aptos2019/val_images/val_images/18323d8f2470.png\n/kaggle/input/aptos2019/val_images/val_images/15b21c80cc31.png\n/kaggle/input/aptos2019/val_images/val_images/166068a24416.png\n/kaggle/input/aptos2019/val_images/val_images/10bf25731c08.png\n/kaggle/input/aptos2019/val_images/val_images/02685f13cefd.png\n/kaggle/input/aptos2019/val_images/val_images/00b74780d31d.png\n/kaggle/input/aptos2019/val_images/val_images/093a42649c29.png\n/kaggle/input/aptos2019/val_images/val_images/11d8e5eaee5b.png\n/kaggle/input/aptos2019/val_images/val_images/0f96c358a250.png\n/kaggle/input/aptos2019/val_images/val_images/144b01e7b993.png\n/kaggle/input/aptos2019/val_images/val_images/0ad7f631dedb.png\n/kaggle/input/aptos2019/val_images/val_images/0519b934f6b1.png\n/kaggle/input/aptos2019/val_images/val_images/12025b34deb8.png\n/kaggle/input/aptos2019/val_images/val_images/144a1a426137.png\n/kaggle/input/aptos2019/val_images/val_images/1438288bb2e1.png\n/kaggle/input/aptos2019/val_images/val_images/0104b032c141.png\n/kaggle/input/aptos2019/val_images/val_images/0dbe6c26cedc.png\n/kaggle/input/aptos2019/val_images/val_images/086d41d17da8.png\n/kaggle/input/aptos2019/val_images/val_images/042470a92154.png\n/kaggle/input/aptos2019/val_images/val_images/0cd31078cd08.png\n/kaggle/input/aptos2019/val_images/val_images/01b3aed3ed4c.png\n/kaggle/input/aptos2019/val_images/val_images/03b373718013.png\n/kaggle/input/aptos2019/val_images/val_images/1968183f0e61.png\n/kaggle/input/aptos2019/val_images/val_images/19722bff5a09.png\n/kaggle/input/aptos2019/val_images/val_images/03c85870824c.png\n/kaggle/input/aptos2019/val_images/val_images/070d4ce5fd90.png\n/kaggle/input/aptos2019/val_images/val_images/0b8bdec9d869.png\n/kaggle/input/aptos2019/val_images/val_images/1594ca6c30d3.png\n/kaggle/input/aptos2019/val_images/val_images/05e9126dfa5c.png\n/kaggle/input/aptos2019/val_images/val_images/150f92b45349.png\n/kaggle/input/aptos2019/val_images/val_images/005b95c28852.png\n/kaggle/input/aptos2019/val_images/val_images/1632c4311fc9.png\n/kaggle/input/aptos2019/val_images/val_images/115e42dd6a81.png\n/kaggle/input/aptos2019/val_images/val_images/191cf5668f33.png\n/kaggle/input/aptos2019/val_images/val_images/0e0003ddd8df.png\n/kaggle/input/aptos2019/val_images/val_images/16ce555748d8.png\n/kaggle/input/aptos2019/val_images/val_images/0fd16b64697e.png\n/kaggle/input/aptos2019/val_images/val_images/0fffa73e2402.png\n/kaggle/input/aptos2019/val_images/val_images/107aea0d9289.png\n/kaggle/input/aptos2019/val_images/val_images/0cecc2864b7f.png\n/kaggle/input/aptos2019/val_images/val_images/0dbaa09a458c.png\n/kaggle/input/aptos2019/val_images/val_images/06024377d573.png\n/kaggle/input/aptos2019/val_images/val_images/18f1f979d30d.png\n/kaggle/input/aptos2019/val_images/val_images/0fb1053285cf.png\n/kaggle/input/aptos2019/val_images/val_images/0f882877bf13.png\n/kaggle/input/aptos2019/val_images/val_images/197af0de76e2.png\n/kaggle/input/aptos2019/val_images/val_images/0c55d58bebaf.png\n/kaggle/input/aptos2019/val_images/val_images/0f364b7d4384.png\n/kaggle/input/aptos2019/val_images/val_images/17eff993386f.png\n/kaggle/input/aptos2019/val_images/val_images/16060f05d047.png\n/kaggle/input/aptos2019/val_images/val_images/07f5d7baf907.png\n/kaggle/input/aptos2019/val_images/val_images/0180bfa26c0b.png\n/kaggle/input/aptos2019/val_images/val_images/186c1835eec5.png\n/kaggle/input/aptos2019/val_images/val_images/0151781fe50b.png\n/kaggle/input/aptos2019/val_images/val_images/05339950962e.png\n/kaggle/input/aptos2019/val_images/val_images/1a03a7970337.png\n/kaggle/input/aptos2019/val_images/val_images/0a38b552372d.png\n/kaggle/input/aptos2019/val_images/val_images/19b0e3c734f5.png\n/kaggle/input/aptos2019/val_images/val_images/0babc12807b2.png\n/kaggle/input/aptos2019/val_images/val_images/157d17349cc6.png\n/kaggle/input/aptos2019/val_images/val_images/02358b47ea89.png\n/kaggle/input/aptos2019/val_images/val_images/0212dd31f623.png\n/kaggle/input/aptos2019/val_images/val_images/0cbcc7b23613.png\n/kaggle/input/aptos2019/val_images/val_images/14515b8f19b6.png\n/kaggle/input/aptos2019/val_images/val_images/04a6fc58dabc.png\n/kaggle/input/aptos2019/val_images/val_images/04efb1a284cc.png\n/kaggle/input/aptos2019/val_images/val_images/12a82fc7d73e.png\n/kaggle/input/aptos2019/val_images/val_images/174db0854291.png\n/kaggle/input/aptos2019/val_images/val_images/06586082a24d.png\n/kaggle/input/aptos2019/val_images/val_images/026dcd9af143.png\n/kaggle/input/aptos2019/val_images/val_images/0b64a0a06f9a.png\n/kaggle/input/aptos2019/val_images/val_images/12ef75375322.png\n/kaggle/input/aptos2019/val_images/val_images/0851d6a69589.png\n/kaggle/input/aptos2019/val_images/val_images/187f6ccda87a.png\n/kaggle/input/aptos2019/val_images/val_images/19ef4d292196.png\n/kaggle/input/aptos2019/val_images/val_images/0a74c92e287c.png\n/kaggle/input/aptos2019/val_images/val_images/1623e8e3adc4.png\n/kaggle/input/aptos2019/val_images/val_images/0b00f8a77510.png\n/kaggle/input/aptos2019/val_images/val_images/09eeafa9656a.png\n/kaggle/input/aptos2019/val_images/val_images/12b57dac703e.png\n/kaggle/input/aptos2019/val_images/val_images/000c1434d8d7.png\n/kaggle/input/aptos2019/val_images/val_images/1864d3411143.png\n/kaggle/input/aptos2019/val_images/val_images/1782142e17d9.png\n/kaggle/input/aptos2019/val_images/val_images/0161338f53cc.png\n/kaggle/input/aptos2019/val_images/val_images/152db3de8120.png\n/kaggle/input/aptos2019/val_images/val_images/19e350c7c83c.png\n/kaggle/input/aptos2019/val_images/val_images/190a309f2cc5.png\n/kaggle/input/aptos2019/val_images/val_images/0bf37ca3156a.png\n/kaggle/input/aptos2019/val_images/val_images/0a85a1e8f9e9.png\n/kaggle/input/aptos2019/val_images/val_images/0af296d2f04a.png\n/kaggle/input/aptos2019/val_images/val_images/0a3202889f4d.png\n/kaggle/input/aptos2019/val_images/val_images/07751b94a88a.png\n/kaggle/input/aptos2019/val_images/val_images/05195a3db5e2.png\n/kaggle/input/aptos2019/val_images/val_images/1006345f70b7.png\n/kaggle/input/aptos2019/val_images/val_images/0c38940e1f80.png\n/kaggle/input/aptos2019/val_images/val_images/13ab8db8c700.png\n/kaggle/input/aptos2019/val_images/val_images/1844a039b4ea.png\n/kaggle/input/aptos2019/val_images/val_images/0b2ea8f268cf.png\n/kaggle/input/aptos2019/val_images/val_images/111898ab463d.png\n/kaggle/input/aptos2019/val_images/val_images/13c191b59ed0.png\n/kaggle/input/aptos2019/val_images/val_images/13d71389563f.png\n/kaggle/input/aptos2019/val_images/val_images/0eced86c9db8.png\n/kaggle/input/aptos2019/val_images/val_images/165c548185f8.png\n/kaggle/input/aptos2019/val_images/val_images/1601c939412f.png\n/kaggle/input/aptos2019/val_images/val_images/001639a390f0.png\n/kaggle/input/aptos2019/val_images/val_images/12ab2f6397f0.png\n/kaggle/input/aptos2019/val_images/val_images/07a2b8cabf6b.png\n/kaggle/input/aptos2019/val_images/val_images/0318598cfd16.png\n/kaggle/input/aptos2019/val_images/val_images/08bef347f40d.png\n/kaggle/input/aptos2019/val_images/val_images/1414128bead0.png\n/kaggle/input/aptos2019/val_images/val_images/103f97a2ab15.png\n/kaggle/input/aptos2019/val_images/val_images/03ff7d159f10.png\n/kaggle/input/aptos2019/val_images/val_images/18b99159a14f.png\n/kaggle/input/aptos2019/val_images/val_images/18cde9649e90.png\n/kaggle/input/aptos2019/val_images/val_images/1120f6d08d95.png\n/kaggle/input/aptos2019/val_images/val_images/094858f005ab.png\n/kaggle/input/aptos2019/val_images/val_images/1ab3f1c71a5f.png\n/kaggle/input/aptos2019/val_images/val_images/17d997fe1090.png\n/kaggle/input/aptos2019/val_images/val_images/12ce6a1a1f31.png\n/kaggle/input/aptos2019/val_images/val_images/11b5c77fbf79.png\n/kaggle/input/aptos2019/val_images/val_images/1177d583c807.png\n/kaggle/input/aptos2019/val_images/val_images/0c2e2369dfff.png\n/kaggle/input/aptos2019/val_images/val_images/099021fac3c9.png\n/kaggle/input/aptos2019/val_images/val_images/03747397839f.png\n/kaggle/input/aptos2019/val_images/val_images/0cae727cf119.png\n/kaggle/input/aptos2019/val_images/val_images/1a0dbc6c0cda.png\n/kaggle/input/aptos2019/val_images/val_images/12e3f5f2cb17.png\n/kaggle/input/aptos2019/val_images/val_images/01d9477b1171.png\n/kaggle/input/aptos2019/val_images/val_images/05a5183c92d0.png\n/kaggle/input/aptos2019/val_images/val_images/0231642cf1c2.png\n/kaggle/input/aptos2019/val_images/val_images/0da632ca45e0.png\n/kaggle/input/aptos2019/val_images/val_images/191348830ddf.png\n/kaggle/input/aptos2019/val_images/val_images/1633f8291a80.png\n/kaggle/input/aptos2019/val_images/val_images/18b06f56ab27.png\n/kaggle/input/aptos2019/val_images/val_images/0c917c372572.png\n/kaggle/input/aptos2019/val_images/val_images/06b71823f9cd.png\n/kaggle/input/aptos2019/val_images/val_images/1ae3c58759fb.png\n/kaggle/input/aptos2019/val_images/val_images/11242a67122d.png\n/kaggle/input/aptos2019/val_images/val_images/071435a218ec.png\n/kaggle/input/aptos2019/val_images/val_images/14c3b41d289c.png\n/kaggle/input/aptos2019/val_images/val_images/0304bedad8fe.png\n/kaggle/input/aptos2019/val_images/val_images/0b3efe669365.png\n/kaggle/input/aptos2019/val_images/val_images/10de500cf0c5.png\n/kaggle/input/aptos2019/val_images/val_images/0423237770a7.png\n/kaggle/input/aptos2019/val_images/val_images/180afe1d5ef7.png\n/kaggle/input/aptos2019/val_images/val_images/164cd5a3a6cd.png\n/kaggle/input/aptos2019/val_images/val_images/0a1076183736.png\n/kaggle/input/aptos2019/val_images/val_images/04579e31e4be.png\n/kaggle/input/aptos2019/val_images/val_images/1269ab57c2e6.png\n/kaggle/input/aptos2019/val_images/val_images/0182152c50de.png\n/kaggle/input/aptos2019/val_images/val_images/15c24478ac72.png\n/kaggle/input/aptos2019/val_images/val_images/03676c71ed1b.png\n/kaggle/input/aptos2019/val_images/val_images/096436d68d06.png\n/kaggle/input/aptos2019/val_images/val_images/1638404f385c.png\n/kaggle/input/aptos2019/val_images/val_images/19113e5f45ec.png\n/kaggle/input/aptos2019/val_images/val_images/17188c13e635.png\n/kaggle/input/aptos2019/val_images/val_images/15e24b73d4a7.png\n/kaggle/input/aptos2019/val_images/val_images/13d411c85ffd.png\n/kaggle/input/aptos2019/val_images/val_images/0981195eb9fb.png\n/kaggle/input/aptos2019/val_images/val_images/172df1330a60.png\n/kaggle/input/aptos2019/val_images/val_images/0fb560f9adb2.png\n/kaggle/input/aptos2019/val_images/val_images/15bed5adde74.png\n/kaggle/input/aptos2019/val_images/val_images/02cd34a85b24.png\n/kaggle/input/aptos2019/val_images/val_images/0fbbd665431f.png\n/kaggle/input/aptos2019/val_images/val_images/0773a1c326ad.png\n/kaggle/input/aptos2019/val_images/val_images/0eb52045349f.png\n/kaggle/input/aptos2019/val_images/val_images/191a711852bd.png\n/kaggle/input/aptos2019/val_images/val_images/05b1bb2bdb81.png\n/kaggle/input/aptos2019/val_images/val_images/0e82bcacc475.png\n/kaggle/input/aptos2019/val_images/val_images/11b220a397b8.png\n/kaggle/input/aptos2019/val_images/val_images/188219f2d9c6.png\n/kaggle/input/aptos2019/val_images/val_images/0232dfea7547.png\n/kaggle/input/aptos2019/val_images/val_images/1ab8d3431ffc.png\n/kaggle/input/aptos2019/val_images/val_images/025a169a0bb0.png\n/kaggle/input/aptos2019/val_images/val_images/070f67572d03.png\n/kaggle/input/aptos2019/val_images/val_images/1a1b4b2450ca.png\n/kaggle/input/aptos2019/val_images/val_images/08037e4490e5.png\n/kaggle/input/aptos2019/val_images/val_images/041f09eec1e8.png\n/kaggle/input/aptos2019/val_images/val_images/0e3572b5884a.png\n/kaggle/input/aptos2019/val_images/val_images/0124dffecf29.png\n/kaggle/input/aptos2019/val_images/val_images/07a1c7073982.png\n/kaggle/input/aptos2019/val_images/val_images/0369f3efe69b.png\n/kaggle/input/aptos2019/val_images/val_images/03fd50da928d.png\n/kaggle/input/aptos2019/val_images/val_images/141735b57ec0.png\n/kaggle/input/aptos2019/val_images/val_images/0c76fd494af6.png\n/kaggle/input/aptos2019/val_images/val_images/0e75d51152fc.png\n/kaggle/input/aptos2019/val_images/val_images/0a4e1a29ffff.png\n/kaggle/input/aptos2019/val_images/val_images/0da09e3ce8f1.png\n/kaggle/input/aptos2019/val_images/val_images/04ac765f91a1.png\n/kaggle/input/aptos2019/val_images/val_images/0684311afdfc.png\n/kaggle/input/aptos2019/val_images/val_images/135575dc57c9.png\n/kaggle/input/aptos2019/val_images/val_images/10f10fd30718.png\n/kaggle/input/aptos2019/val_images/val_images/0924cec998fa.png\n/kaggle/input/aptos2019/val_images/val_images/08c17a2d95b7.png\n/kaggle/input/aptos2019/val_images/val_images/08f8838d69bb.png\n/kaggle/input/aptos2019/val_images/val_images/0e94cd271c00.png\n/kaggle/input/aptos2019/val_images/val_images/0097f532ac9f.png\n/kaggle/input/aptos2019/val_images/val_images/19545647508e.png\n/kaggle/input/aptos2019/val_images/val_images/09934421c79e.png\n/kaggle/input/aptos2019/val_images/val_images/0da321efbce6.png\n/kaggle/input/aptos2019/val_images/val_images/07a0e34c8d20.png\n/kaggle/input/aptos2019/val_images/val_images/178412895d5e.png\n/kaggle/input/aptos2019/val_images/val_images/14e3f84445f7.png\n/kaggle/input/aptos2019/val_images/val_images/0ce062f26edc.png\n/kaggle/input/aptos2019/val_images/val_images/0d8f60ed9280.png\n/kaggle/input/aptos2019/val_images/val_images/0c7e82daf5a0.png\n/kaggle/input/aptos2019/val_images/val_images/012a242ac6ff.png\n/kaggle/input/aptos2019/val_images/val_images/18621b9ca978.png\n/kaggle/input/aptos2019/val_images/val_images/08a3875063c3.png\n/kaggle/input/aptos2019/val_images/val_images/0551676cc2aa.png\n/kaggle/input/aptos2019/val_images/val_images/0efc93ec838b.png\n/kaggle/input/aptos2019/val_images/val_images/0024cdab0c1e.png\n/kaggle/input/aptos2019/val_images/val_images/052d9a3fe55a.png\n/kaggle/input/aptos2019/val_images/val_images/0db1d8dcf219.png\n/kaggle/input/aptos2019/val_images/val_images/1a369baf9ee6.png\n/kaggle/input/aptos2019/val_images/val_images/1002b5151b8e.png\n/kaggle/input/aptos2019/val_images/val_images/165cd2070ebd.png\n/kaggle/input/aptos2019/val_images/val_images/080ee76c958c.png\n/kaggle/input/aptos2019/val_images/val_images/0e0fc1d9810c.png\n/kaggle/input/aptos2019/val_images/val_images/07419eddd6be.png\n/kaggle/input/aptos2019/val_images/val_images/01eb826f6467.png\n/kaggle/input/aptos2019/val_images/val_images/12ae44be0d38.png\n/kaggle/input/aptos2019/val_images/val_images/175dd560810a.png\n/kaggle/input/aptos2019/val_images/val_images/09f6ab477654.png\n/kaggle/input/aptos2019/val_images/val_images/09935d72892b.png\n/kaggle/input/aptos2019/val_images/val_images/0cb14014117d.png\n/kaggle/input/aptos2019/val_images/val_images/0dc031c94225.png\n/kaggle/input/aptos2019/val_images/val_images/0daddc45d832.png\n/kaggle/input/aptos2019/val_images/val_images/15f440753916.png\n/kaggle/input/aptos2019/val_images/val_images/03e25101e8e8.png\n/kaggle/input/aptos2019/val_images/val_images/0dc8d25b3f69.png\n/kaggle/input/aptos2019/val_images/val_images/07083738b75e.png\n/kaggle/input/aptos2019/val_images/val_images/0709652336e2.png\n/kaggle/input/aptos2019/val_images/val_images/189cbbc9e5e3.png\n/kaggle/input/aptos2019/val_images/val_images/155e2df6bfcf.png\n/kaggle/input/aptos2019/val_images/val_images/0790515cf5af.png\n/kaggle/input/aptos2019/val_images/val_images/0f495d87656a.png\n/kaggle/input/aptos2019/val_images/val_images/0d9a9896f801.png\n/kaggle/input/aptos2019/val_images/val_images/13063d1bc4ea.png\n/kaggle/input/aptos2019/val_images/val_images/0415fc68b176.png\n/kaggle/input/aptos2019/val_images/val_images/069f43616fab.png\n/kaggle/input/aptos2019/val_images/val_images/0a09aa7356c0.png\n/kaggle/input/aptos2019/val_images/val_images/14ee87d6cc42.png\n/kaggle/input/aptos2019/val_images/val_images/02dda30d3acf.png\n/kaggle/input/aptos2019/val_images/val_images/15528e740543.png\n/kaggle/input/aptos2019/val_images/val_images/0c43c79e8cfb.png\n/kaggle/input/aptos2019/val_images/val_images/184a185e7447.png\n/kaggle/input/aptos2019/val_images/val_images/13d014ccd136.png\n/kaggle/input/aptos2019/val_images/val_images/033f2b43de6d.png\n/kaggle/input/aptos2019/val_images/val_images/0ceb222f6629.png\n/kaggle/input/aptos2019/val_images/val_images/0cb6b898389f.png\n/kaggle/input/aptos2019/val_images/val_images/0a902c80d5da.png\n/kaggle/input/aptos2019/val_images/val_images/080f66eedfb9.png\n/kaggle/input/aptos2019/val_images/val_images/1891698febce.png\n/kaggle/input/aptos2019/val_images/val_images/0f6e645466a2.png\n/kaggle/input/aptos2019/val_images/val_images/10f36b0239fb.png\n/kaggle/input/aptos2019/val_images/val_images/165634a6167e.png\n/kaggle/input/aptos2019/val_images/val_images/0dce95217626.png\n/kaggle/input/aptos2019/val_images/val_images/07a3be30563b.png\n/kaggle/input/aptos2019/val_images/val_images/196e6a186452.png\n/kaggle/input/aptos2019/val_images/val_images/1a90fad9ffa2.png\n/kaggle/input/aptos2019/val_images/val_images/014508ccb9cb.png\n/kaggle/input/aptos2019/val_images/val_images/0fcfc6301f3d.png\n/kaggle/input/aptos2019/val_images/val_images/09f1111a388a.png\n/kaggle/input/aptos2019/val_images/val_images/08ee569d4721.png\n/kaggle/input/aptos2019/val_images/val_images/10fca1abf338.png\n/kaggle/input/aptos2019/val_images/val_images/00a8624548a9.png\n/kaggle/input/aptos2019/val_images/val_images/084c02cf077f.png\n/kaggle/input/aptos2019/val_images/val_images/07929d32b5b3.png\n/kaggle/input/aptos2019/val_images/val_images/01f7bb8be950.png\n/kaggle/input/aptos2019/val_images/val_images/034cb07a550f.png\n/kaggle/input/aptos2019/val_images/val_images/18b7e34eab8f.png\n/kaggle/input/aptos2019/val_images/val_images/0fe31196e0e8.png\n/kaggle/input/aptos2019/val_images/val_images/07122e268a1d.png\n/kaggle/input/aptos2019/val_images/val_images/050bb1eafa76.png\n/kaggle/input/aptos2019/val_images/val_images/07a0be6b347f.png\n/kaggle/input/aptos2019/val_images/val_images/15cc2aef772a.png\n/kaggle/input/aptos2019/val_images/val_images/1a1e974a7dbf.png\n/kaggle/input/aptos2019/val_images/val_images/0edadb2aa127.png\n/kaggle/input/aptos2019/val_images/val_images/08c60c647673.png\n/kaggle/input/aptos2019/val_images/val_images/07e827469099.png\n/kaggle/input/aptos2019/val_images/val_images/18d8fdb140b7.png\n/kaggle/input/aptos2019/val_images/val_images/12bc439d373a.png\n/kaggle/input/aptos2019/val_images/val_images/1116271db4ea.png\n/kaggle/input/aptos2019/val_images/val_images/09237bf783a4.png\n/kaggle/input/aptos2019/val_images/val_images/00cb6555d108.png\n/kaggle/input/aptos2019/val_images/val_images/1002f3fe38f0.png\n/kaggle/input/aptos2019/val_images/val_images/05113073b268.png\n/kaggle/input/aptos2019/val_images/val_images/1411c8ab7161.png\n/kaggle/input/aptos2019/val_images/val_images/0953c0ac1735.png\n/kaggle/input/aptos2019/val_images/val_images/103abbd8b63e.png\n/kaggle/input/aptos2019/train_images/train_images/6dcde47060f9.png\n/kaggle/input/aptos2019/train_images/train_images/b49b2fac2514.png\n/kaggle/input/aptos2019/train_images/train_images/af6166d57f13.png\n/kaggle/input/aptos2019/train_images/train_images/8d13c46e7d75.png\n/kaggle/input/aptos2019/train_images/train_images/c3b15bf9b4bc.png\n/kaggle/input/aptos2019/train_images/train_images/be68322c7223.png\n/kaggle/input/aptos2019/train_images/train_images/88e4399d207c.png\n/kaggle/input/aptos2019/train_images/train_images/77ab222bf85c.png\n/kaggle/input/aptos2019/train_images/train_images/4a05f81b3aba.png\n/kaggle/input/aptos2019/train_images/train_images/61d9c88a3a4b.png\n/kaggle/input/aptos2019/train_images/train_images/8448af27ba07.png\n/kaggle/input/aptos2019/train_images/train_images/4554062fa836.png\n/kaggle/input/aptos2019/train_images/train_images/a688f20f8895.png\n/kaggle/input/aptos2019/train_images/train_images/3af9aaa880e9.png\n/kaggle/input/aptos2019/train_images/train_images/cb68fce07789.png\n/kaggle/input/aptos2019/train_images/train_images/5d9c841eb245.png\n/kaggle/input/aptos2019/train_images/train_images/d4be0403e6ab.png\n/kaggle/input/aptos2019/train_images/train_images/388f12e8df0b.png\n/kaggle/input/aptos2019/train_images/train_images/bb7e0a2544cd.png\n/kaggle/input/aptos2019/train_images/train_images/1d29cb2f4296.png\n/kaggle/input/aptos2019/train_images/train_images/d83c3efade75.png\n/kaggle/input/aptos2019/train_images/train_images/2927665214e1.png\n/kaggle/input/aptos2019/train_images/train_images/1e4650743fa2.png\n/kaggle/input/aptos2019/train_images/train_images/abdb365cacbc.png\n/kaggle/input/aptos2019/train_images/train_images/d15ca3469b87.png\n/kaggle/input/aptos2019/train_images/train_images/576e189d23d4.png\n/kaggle/input/aptos2019/train_images/train_images/33ffddea8c6e.png\n/kaggle/input/aptos2019/train_images/train_images/28f93cad89c5.png\n/kaggle/input/aptos2019/train_images/train_images/8af50c9d0a86.png\n/kaggle/input/aptos2019/train_images/train_images/932181b93b2f.png\n/kaggle/input/aptos2019/train_images/train_images/c68dfa021d62.png\n/kaggle/input/aptos2019/train_images/train_images/a4d4b69f7404.png\n/kaggle/input/aptos2019/train_images/train_images/278aa860dffd.png\n/kaggle/input/aptos2019/train_images/train_images/90bde2ff8953.png\n/kaggle/input/aptos2019/train_images/train_images/7d1b40fdbd86.png\n/kaggle/input/aptos2019/train_images/train_images/9f285b3e57ed.png\n/kaggle/input/aptos2019/train_images/train_images/c252da9b41d8.png\n/kaggle/input/aptos2019/train_images/train_images/dfea19863428.png\n/kaggle/input/aptos2019/train_images/train_images/8ee50c26fc13.png\n/kaggle/input/aptos2019/train_images/train_images/ba0107fb1bfd.png\n/kaggle/input/aptos2019/train_images/train_images/436fa3fd145a.png\n/kaggle/input/aptos2019/train_images/train_images/8fd7ad26e691.png\n/kaggle/input/aptos2019/train_images/train_images/82910bba4753.png\n/kaggle/input/aptos2019/train_images/train_images/a9e984b57556.png\n/kaggle/input/aptos2019/train_images/train_images/75ed83dbccce.png\n/kaggle/input/aptos2019/train_images/train_images/d66b6f333dc7.png\n/kaggle/input/aptos2019/train_images/train_images/45369821d6a3.png\n/kaggle/input/aptos2019/train_images/train_images/65c958379680.png\n/kaggle/input/aptos2019/train_images/train_images/b83a6eca125f.png\n/kaggle/input/aptos2019/train_images/train_images/79cbae28d8b2.png\n/kaggle/input/aptos2019/train_images/train_images/69b3a00927fc.png\n/kaggle/input/aptos2019/train_images/train_images/b05922e7abd3.png\n/kaggle/input/aptos2019/train_images/train_images/4ffa38550c95.png\n/kaggle/input/aptos2019/train_images/train_images/cb547e723a16.png\n/kaggle/input/aptos2019/train_images/train_images/a8c950a99107.png\n/kaggle/input/aptos2019/train_images/train_images/549381330191.png\n/kaggle/input/aptos2019/train_images/train_images/705f508d1e42.png\n/kaggle/input/aptos2019/train_images/train_images/934104859e68.png\n/kaggle/input/aptos2019/train_images/train_images/36e4b704b905.png\n/kaggle/input/aptos2019/train_images/train_images/6666c4f18396.png\n/kaggle/input/aptos2019/train_images/train_images/7525ebb3434d.png\n/kaggle/input/aptos2019/train_images/train_images/6363b360aefb.png\n/kaggle/input/aptos2019/train_images/train_images/a06b353e7bed.png\n/kaggle/input/aptos2019/train_images/train_images/8a9bef2fbd4e.png\n/kaggle/input/aptos2019/train_images/train_images/5078caaf1f57.png\n/kaggle/input/aptos2019/train_images/train_images/5ac7a414560e.png\n/kaggle/input/aptos2019/train_images/train_images/9bd008aab548.png\n/kaggle/input/aptos2019/train_images/train_images/77acc2cafee1.png\n/kaggle/input/aptos2019/train_images/train_images/812d5adafaf2.png\n/kaggle/input/aptos2019/train_images/train_images/ca891d37a43c.png\n/kaggle/input/aptos2019/train_images/train_images/437cbec4a3f8.png\n/kaggle/input/aptos2019/train_images/train_images/d865997a6280.png\n/kaggle/input/aptos2019/train_images/train_images/6294b378d09f.png\n/kaggle/input/aptos2019/train_images/train_images/cab3dfa7962d.png\n/kaggle/input/aptos2019/train_images/train_images/6b869f37cdf3.png\n/kaggle/input/aptos2019/train_images/train_images/ab7991df166b.png\n/kaggle/input/aptos2019/train_images/train_images/63363410389a.png\n/kaggle/input/aptos2019/train_images/train_images/e229aca862c7.png\n/kaggle/input/aptos2019/train_images/train_images/4da2961e62fe.png\n/kaggle/input/aptos2019/train_images/train_images/3a122851e526.png\n/kaggle/input/aptos2019/train_images/train_images/958c1fa044ba.png\n/kaggle/input/aptos2019/train_images/train_images/64bad93fde3f.png\n/kaggle/input/aptos2019/train_images/train_images/906d02fb822d.png\n/kaggle/input/aptos2019/train_images/train_images/a384e688e228.png\n/kaggle/input/aptos2019/train_images/train_images/22098b1fe461.png\n/kaggle/input/aptos2019/train_images/train_images/2e26762daed5.png\n/kaggle/input/aptos2019/train_images/train_images/9a28d4e8aef0.png\n/kaggle/input/aptos2019/train_images/train_images/530d78467615.png\n/kaggle/input/aptos2019/train_images/train_images/cf1b9d26d38d.png\n/kaggle/input/aptos2019/train_images/train_images/3ddb86eb530e.png\n/kaggle/input/aptos2019/train_images/train_images/6c2555a9cae4.png\n/kaggle/input/aptos2019/train_images/train_images/4a589edaea60.png\n/kaggle/input/aptos2019/train_images/train_images/ccd6dcb2f568.png\n/kaggle/input/aptos2019/train_images/train_images/2fefb720869a.png\n/kaggle/input/aptos2019/train_images/train_images/da44f80b422b.png\n/kaggle/input/aptos2019/train_images/train_images/31616ff6b53b.png\n/kaggle/input/aptos2019/train_images/train_images/bd500a73beae.png\n/kaggle/input/aptos2019/train_images/train_images/4a5a6efc0bef.png\n/kaggle/input/aptos2019/train_images/train_images/aef9016557ca.png\n/kaggle/input/aptos2019/train_images/train_images/4c129470cec4.png\n/kaggle/input/aptos2019/train_images/train_images/252305189b3a.png\n/kaggle/input/aptos2019/train_images/train_images/639915f58a2f.png\n/kaggle/input/aptos2019/train_images/train_images/8a759f94613a.png\n/kaggle/input/aptos2019/train_images/train_images/6b07971c3bf6.png\n/kaggle/input/aptos2019/train_images/train_images/c4e8b1ec8893.png\n/kaggle/input/aptos2019/train_images/train_images/2ba0b0d9bda2.png\n/kaggle/input/aptos2019/train_images/train_images/31b5d6fb0256.png\n/kaggle/input/aptos2019/train_images/train_images/9faad91b6578.png\n/kaggle/input/aptos2019/train_images/train_images/64b9206afb3f.png\n/kaggle/input/aptos2019/train_images/train_images/cbc23af521f3.png\n/kaggle/input/aptos2019/train_images/train_images/b1197f2cc9b3.png\n/kaggle/input/aptos2019/train_images/train_images/b91ef82e723a.png\n/kaggle/input/aptos2019/train_images/train_images/71e4130bf5c8.png\n/kaggle/input/aptos2019/train_images/train_images/90c982cc2d96.png\n/kaggle/input/aptos2019/train_images/train_images/3601dac9bed7.png\n/kaggle/input/aptos2019/train_images/train_images/d1afdb8cf70d.png\n/kaggle/input/aptos2019/train_images/train_images/a3706ce27869.png\n/kaggle/input/aptos2019/train_images/train_images/1f15ca672675.png\n/kaggle/input/aptos2019/train_images/train_images/a12ca80bb8c7.png\n/kaggle/input/aptos2019/train_images/train_images/58184d6fd087.png\n/kaggle/input/aptos2019/train_images/train_images/3ca8be3b40d6.png\n/kaggle/input/aptos2019/train_images/train_images/529906ff9dfa.png\n/kaggle/input/aptos2019/train_images/train_images/367c7049929c.png\n/kaggle/input/aptos2019/train_images/train_images/4409965eb2a4.png\n/kaggle/input/aptos2019/train_images/train_images/2a8a9e957a6c.png\n/kaggle/input/aptos2019/train_images/train_images/b0d35981708b.png\n/kaggle/input/aptos2019/train_images/train_images/847b04287c9c.png\n/kaggle/input/aptos2019/train_images/train_images/4d17559ac1e2.png\n/kaggle/input/aptos2019/train_images/train_images/87774aafe068.png\n/kaggle/input/aptos2019/train_images/train_images/a8263d248523.png\n/kaggle/input/aptos2019/train_images/train_images/9eaac43744f5.png\n/kaggle/input/aptos2019/train_images/train_images/51030843fde2.png\n/kaggle/input/aptos2019/train_images/train_images/b6bf847fbcb2.png\n/kaggle/input/aptos2019/train_images/train_images/62ecdc90dd42.png\n/kaggle/input/aptos2019/train_images/train_images/a7b7dc8788b9.png\n/kaggle/input/aptos2019/train_images/train_images/8a3eb86ae4bd.png\n/kaggle/input/aptos2019/train_images/train_images/8421107255ae.png\n/kaggle/input/aptos2019/train_images/train_images/76be29bb30b2.png\n/kaggle/input/aptos2019/train_images/train_images/876deb29f000.png\n/kaggle/input/aptos2019/train_images/train_images/42b08dca9b2f.png\n/kaggle/input/aptos2019/train_images/train_images/9d9bfefa809c.png\n/kaggle/input/aptos2019/train_images/train_images/2b48daf24be0.png\n/kaggle/input/aptos2019/train_images/train_images/c2f3281cf528.png\n/kaggle/input/aptos2019/train_images/train_images/cadde4030858.png\n/kaggle/input/aptos2019/train_images/train_images/63c0eafd6aa9.png\n/kaggle/input/aptos2019/train_images/train_images/302bcdb635ff.png\n/kaggle/input/aptos2019/train_images/train_images/290ecdba359f.png\n/kaggle/input/aptos2019/train_images/train_images/b9b99dad668d.png\n/kaggle/input/aptos2019/train_images/train_images/436e7a7af761.png\n/kaggle/input/aptos2019/train_images/train_images/4826d10030b3.png\n/kaggle/input/aptos2019/train_images/train_images/4489d421e5aa.png\n/kaggle/input/aptos2019/train_images/train_images/33778d136069.png\n/kaggle/input/aptos2019/train_images/train_images/ca2b54b95ade.png\n/kaggle/input/aptos2019/train_images/train_images/2682e6da9050.png\n/kaggle/input/aptos2019/train_images/train_images/8000a6b97a84.png\n/kaggle/input/aptos2019/train_images/train_images/873fe0404d6e.png\n/kaggle/input/aptos2019/train_images/train_images/1c578b72d7b3.png\n/kaggle/input/aptos2019/train_images/train_images/a0445785e2f7.png\n/kaggle/input/aptos2019/train_images/train_images/e1ab92228e60.png\n/kaggle/input/aptos2019/train_images/train_images/a3fcf42ff56d.png\n/kaggle/input/aptos2019/train_images/train_images/97da093947e8.png\n/kaggle/input/aptos2019/train_images/train_images/c5a9ebef1517.png\n/kaggle/input/aptos2019/train_images/train_images/9985375d709f.png\n/kaggle/input/aptos2019/train_images/train_images/b549af91bd30.png\n/kaggle/input/aptos2019/train_images/train_images/58f07741ee3b.png\n/kaggle/input/aptos2019/train_images/train_images/8344c783da65.png\n/kaggle/input/aptos2019/train_images/train_images/9870ce41cac4.png\n/kaggle/input/aptos2019/train_images/train_images/2c827005b8f8.png\n/kaggle/input/aptos2019/train_images/train_images/8d3d67661620.png\n/kaggle/input/aptos2019/train_images/train_images/8ed586c43023.png\n/kaggle/input/aptos2019/train_images/train_images/4a3da369b227.png\n/kaggle/input/aptos2019/train_images/train_images/849a91e9ab28.png\n/kaggle/input/aptos2019/train_images/train_images/9a78c6a7b1c2.png\n/kaggle/input/aptos2019/train_images/train_images/ba4d2c4b3039.png\n/kaggle/input/aptos2019/train_images/train_images/5c7ab966a3ee.png\n/kaggle/input/aptos2019/train_images/train_images/97a5ad7548b7.png\n/kaggle/input/aptos2019/train_images/train_images/4dc2211a1c31.png\n/kaggle/input/aptos2019/train_images/train_images/7d3835e4e63a.png\n/kaggle/input/aptos2019/train_images/train_images/61a62b1dcc36.png\n/kaggle/input/aptos2019/train_images/train_images/d1a60c3b9fe5.png\n/kaggle/input/aptos2019/train_images/train_images/b9d0b83d70c3.png\n/kaggle/input/aptos2019/train_images/train_images/521b5377a727.png\n/kaggle/input/aptos2019/train_images/train_images/44e0d56e9d42.png\n/kaggle/input/aptos2019/train_images/train_images/a8a6588c8eb7.png\n/kaggle/input/aptos2019/train_images/train_images/7a238a1d3cf3.png\n/kaggle/input/aptos2019/train_images/train_images/d3d578fe433f.png\n/kaggle/input/aptos2019/train_images/train_images/930fee99213a.png\n/kaggle/input/aptos2019/train_images/train_images/c67117c6ab3b.png\n/kaggle/input/aptos2019/train_images/train_images/1c47815f4a6b.png\n/kaggle/input/aptos2019/train_images/train_images/a419fcb2dfb5.png\n/kaggle/input/aptos2019/train_images/train_images/8f2996b8d855.png\n/kaggle/input/aptos2019/train_images/train_images/2b4c7b5f1f1e.png\n/kaggle/input/aptos2019/train_images/train_images/913b1890ed1e.png\n/kaggle/input/aptos2019/train_images/train_images/2f284b6a1940.png\n/kaggle/input/aptos2019/train_images/train_images/246e4506824a.png\n/kaggle/input/aptos2019/train_images/train_images/650fbed3fdca.png\n/kaggle/input/aptos2019/train_images/train_images/9b7b6e4db1d5.png\n/kaggle/input/aptos2019/train_images/train_images/7ddcfcea7369.png\n/kaggle/input/aptos2019/train_images/train_images/e499434242cc.png\n/kaggle/input/aptos2019/train_images/train_images/73ef3c3dcbe4.png\n/kaggle/input/aptos2019/train_images/train_images/bda8c973b09d.png\n/kaggle/input/aptos2019/train_images/train_images/df8365d6ac33.png\n/kaggle/input/aptos2019/train_images/train_images/207dd0487264.png\n/kaggle/input/aptos2019/train_images/train_images/c3acf47700ea.png\n/kaggle/input/aptos2019/train_images/train_images/d8da9de62743.png\n/kaggle/input/aptos2019/train_images/train_images/4b6cb0bcfd44.png\n/kaggle/input/aptos2019/train_images/train_images/a125377fb985.png\n/kaggle/input/aptos2019/train_images/train_images/ae94ce412de9.png\n/kaggle/input/aptos2019/train_images/train_images/66393d8c60ba.png\n/kaggle/input/aptos2019/train_images/train_images/db49cdf1ea64.png\n/kaggle/input/aptos2019/train_images/train_images/7eee3d1f1268.png\n/kaggle/input/aptos2019/train_images/train_images/cc3d2e961768.png\n/kaggle/input/aptos2019/train_images/train_images/6d454444f17c.png\n/kaggle/input/aptos2019/train_images/train_images/b5a3ca5c0a80.png\n/kaggle/input/aptos2019/train_images/train_images/c76664770c07.png\n/kaggle/input/aptos2019/train_images/train_images/28751f290ba3.png\n/kaggle/input/aptos2019/train_images/train_images/348598d01e18.png\n/kaggle/input/aptos2019/train_images/train_images/4ef7144e24ff.png\n/kaggle/input/aptos2019/train_images/train_images/5bea250d8bf5.png\n/kaggle/input/aptos2019/train_images/train_images/4f20f9a9a65b.png\n/kaggle/input/aptos2019/train_images/train_images/b9fe7da14a32.png\n/kaggle/input/aptos2019/train_images/train_images/524f240e0c90.png\n/kaggle/input/aptos2019/train_images/train_images/a53d6d2472a6.png\n/kaggle/input/aptos2019/train_images/train_images/799214e8b07c.png\n/kaggle/input/aptos2019/train_images/train_images/d4bc001f7224.png\n/kaggle/input/aptos2019/train_images/train_images/7269a1d84a57.png\n/kaggle/input/aptos2019/train_images/train_images/7b29e3783919.png\n/kaggle/input/aptos2019/train_images/train_images/b640e3bdff75.png\n/kaggle/input/aptos2019/train_images/train_images/7a3ea1779b13.png\n/kaggle/input/aptos2019/train_images/train_images/7ed4128b2a4e.png\n/kaggle/input/aptos2019/train_images/train_images/42a850acd2ac.png\n/kaggle/input/aptos2019/train_images/train_images/880edb2cdb69.png\n/kaggle/input/aptos2019/train_images/train_images/7c90ab025331.png\n/kaggle/input/aptos2019/train_images/train_images/6889bc64ab09.png\n/kaggle/input/aptos2019/train_images/train_images/80dbeb0fdc75.png\n/kaggle/input/aptos2019/train_images/train_images/5efa24b03d5e.png\n/kaggle/input/aptos2019/train_images/train_images/6b7cf869622a.png\n/kaggle/input/aptos2019/train_images/train_images/65e120143825.png\n/kaggle/input/aptos2019/train_images/train_images/3402124408ea.png\n/kaggle/input/aptos2019/train_images/train_images/a484bdf85b4c.png\n/kaggle/input/aptos2019/train_images/train_images/5889a0c75cac.png\n/kaggle/input/aptos2019/train_images/train_images/d6130f2ec903.png\n/kaggle/input/aptos2019/train_images/train_images/921433215353.png\n/kaggle/input/aptos2019/train_images/train_images/46923eea9a4e.png\n/kaggle/input/aptos2019/train_images/train_images/6b664ed2a938.png\n/kaggle/input/aptos2019/train_images/train_images/9ba469af2980.png\n/kaggle/input/aptos2019/train_images/train_images/7d48f8cdfb69.png\n/kaggle/input/aptos2019/train_images/train_images/90b8bf342032.png\n/kaggle/input/aptos2019/train_images/train_images/59ee65760535.png\n/kaggle/input/aptos2019/train_images/train_images/3ca12e02dd4e.png\n/kaggle/input/aptos2019/train_images/train_images/6f689fced922.png\n/kaggle/input/aptos2019/train_images/train_images/22449af52060.png\n/kaggle/input/aptos2019/train_images/train_images/e47770a2e5d1.png\n/kaggle/input/aptos2019/train_images/train_images/26d60db3bbfd.png\n/kaggle/input/aptos2019/train_images/train_images/513b0a4651fa.png\n/kaggle/input/aptos2019/train_images/train_images/bdc6c60e9133.png\n/kaggle/input/aptos2019/train_images/train_images/d91273efb92a.png\n/kaggle/input/aptos2019/train_images/train_images/417f408ee8e0.png\n/kaggle/input/aptos2019/train_images/train_images/976082127e2a.png\n/kaggle/input/aptos2019/train_images/train_images/4ee1ad981a6d.png\n/kaggle/input/aptos2019/train_images/train_images/df9cb3729eb1.png\n/kaggle/input/aptos2019/train_images/train_images/547b37da9223.png\n/kaggle/input/aptos2019/train_images/train_images/91b7a4179ecf.png\n/kaggle/input/aptos2019/train_images/train_images/d968a983d4d2.png\n/kaggle/input/aptos2019/train_images/train_images/c373b73a80c8.png\n/kaggle/input/aptos2019/train_images/train_images/3dbfbc11e105.png\n/kaggle/input/aptos2019/train_images/train_images/d51b3fe0fa1b.png\n/kaggle/input/aptos2019/train_images/train_images/c1ebe785503a.png\n/kaggle/input/aptos2019/train_images/train_images/1b329a127307.png\n/kaggle/input/aptos2019/train_images/train_images/4dd5d5ccddcf.png\n/kaggle/input/aptos2019/train_images/train_images/57760be09c03.png\n/kaggle/input/aptos2019/train_images/train_images/a07d9a5045cb.png\n/kaggle/input/aptos2019/train_images/train_images/6c250a30593b.png\n/kaggle/input/aptos2019/train_images/train_images/4f7755e74a9e.png\n/kaggle/input/aptos2019/train_images/train_images/9e5737f771c3.png\n/kaggle/input/aptos2019/train_images/train_images/73d40ce06a67.png\n/kaggle/input/aptos2019/train_images/train_images/1b8701231c8f.png\n/kaggle/input/aptos2019/train_images/train_images/308f7fce6f0d.png\n/kaggle/input/aptos2019/train_images/train_images/65a3b13ad9a0.png\n/kaggle/input/aptos2019/train_images/train_images/901a3552fe26.png\n/kaggle/input/aptos2019/train_images/train_images/b532dedd928c.png\n/kaggle/input/aptos2019/train_images/train_images/49eb73968c44.png\n/kaggle/input/aptos2019/train_images/train_images/d02b79fc3200.png\n/kaggle/input/aptos2019/train_images/train_images/ab50123abadb.png\n/kaggle/input/aptos2019/train_images/train_images/7d0a871c45db.png\n/kaggle/input/aptos2019/train_images/train_images/59fee5bc3479.png\n/kaggle/input/aptos2019/train_images/train_images/1dd9adcbfff4.png\n/kaggle/input/aptos2019/train_images/train_images/e0863b353093.png\n/kaggle/input/aptos2019/train_images/train_images/4d7d6928534a.png\n/kaggle/input/aptos2019/train_images/train_images/7bc00e58d419.png\n/kaggle/input/aptos2019/train_images/train_images/4aa3d771c5e4.png\n/kaggle/input/aptos2019/train_images/train_images/c23ff6dcf15e.png\n/kaggle/input/aptos2019/train_images/train_images/6f460f9968c7.png\n/kaggle/input/aptos2019/train_images/train_images/50916d67bb51.png\n/kaggle/input/aptos2019/train_images/train_images/1cb6961d141c.png\n/kaggle/input/aptos2019/train_images/train_images/542964865b1e.png\n/kaggle/input/aptos2019/train_images/train_images/24de56d433cd.png\n/kaggle/input/aptos2019/train_images/train_images/8e7981855125.png\n/kaggle/input/aptos2019/train_images/train_images/499c8df39222.png\n/kaggle/input/aptos2019/train_images/train_images/99ecdb41d5e7.png\n/kaggle/input/aptos2019/train_images/train_images/a95d9d61ddd4.png\n/kaggle/input/aptos2019/train_images/train_images/b67ae80f7eba.png\n/kaggle/input/aptos2019/train_images/train_images/ba08cee68c71.png\n/kaggle/input/aptos2019/train_images/train_images/c56e65f74187.png\n/kaggle/input/aptos2019/train_images/train_images/3132556f5352.png\n/kaggle/input/aptos2019/train_images/train_images/e1c02f6c3362.png\n/kaggle/input/aptos2019/train_images/train_images/a1b12fdce6c3.png\n/kaggle/input/aptos2019/train_images/train_images/6504b703c429.png\n/kaggle/input/aptos2019/train_images/train_images/1d674e2e32e0.png\n/kaggle/input/aptos2019/train_images/train_images/d69698f838db.png\n/kaggle/input/aptos2019/train_images/train_images/80c67efc8101.png\n/kaggle/input/aptos2019/train_images/train_images/cbe633765ea7.png\n/kaggle/input/aptos2019/train_images/train_images/a2b97d98f130.png\n/kaggle/input/aptos2019/train_images/train_images/3218a6d8eb2c.png\n/kaggle/input/aptos2019/train_images/train_images/545df1bbcd61.png\n/kaggle/input/aptos2019/train_images/train_images/4528fbbd43a3.png\n/kaggle/input/aptos2019/train_images/train_images/a49b0b4484ea.png\n/kaggle/input/aptos2019/train_images/train_images/52dbec057cc8.png\n/kaggle/input/aptos2019/train_images/train_images/48c72dec46e5.png\n/kaggle/input/aptos2019/train_images/train_images/b191ba0a2b12.png\n/kaggle/input/aptos2019/train_images/train_images/2bbcfdc477db.png\n/kaggle/input/aptos2019/train_images/train_images/7ccf9d25dc48.png\n/kaggle/input/aptos2019/train_images/train_images/bb11db08584a.png\n/kaggle/input/aptos2019/train_images/train_images/c25e02b39c01.png\n/kaggle/input/aptos2019/train_images/train_images/35aa7f5c2ec0.png\n/kaggle/input/aptos2019/train_images/train_images/454792eb6e05.png\n/kaggle/input/aptos2019/train_images/train_images/441affbe99aa.png\n/kaggle/input/aptos2019/train_images/train_images/7a77c3eb468c.png\n/kaggle/input/aptos2019/train_images/train_images/1c9521878baf.png\n/kaggle/input/aptos2019/train_images/train_images/43fb6eda9b97.png\n/kaggle/input/aptos2019/train_images/train_images/a56729de89e9.png\n/kaggle/input/aptos2019/train_images/train_images/3aa2b1ce6700.png\n/kaggle/input/aptos2019/train_images/train_images/cec299c2a2d5.png\n/kaggle/input/aptos2019/train_images/train_images/49e4b95ee2dc.png\n/kaggle/input/aptos2019/train_images/train_images/b73d0bcd3d33.png\n/kaggle/input/aptos2019/train_images/train_images/af8aa32beee4.png\n/kaggle/input/aptos2019/train_images/train_images/51af8a689511.png\n/kaggle/input/aptos2019/train_images/train_images/3044022c6969.png\n/kaggle/input/aptos2019/train_images/train_images/af3b0115aad1.png\n/kaggle/input/aptos2019/train_images/train_images/7f2123bc89a3.png\n/kaggle/input/aptos2019/train_images/train_images/ca360bec5851.png\n/kaggle/input/aptos2019/train_images/train_images/49d69c4c6290.png\n/kaggle/input/aptos2019/train_images/train_images/7435e9a3e36e.png\n/kaggle/input/aptos2019/train_images/train_images/bf811911acf9.png\n/kaggle/input/aptos2019/train_images/train_images/a75bab2463d4.png\n/kaggle/input/aptos2019/train_images/train_images/bf7047dc683c.png\n/kaggle/input/aptos2019/train_images/train_images/9fab29e69a6b.png\n/kaggle/input/aptos2019/train_images/train_images/52230bbef30e.png\n/kaggle/input/aptos2019/train_images/train_images/de16416220de.png\n/kaggle/input/aptos2019/train_images/train_images/2131aa3a1e6f.png\n/kaggle/input/aptos2019/train_images/train_images/835b9f6e12ba.png\n/kaggle/input/aptos2019/train_images/train_images/d16e39b9d6f0.png\n/kaggle/input/aptos2019/train_images/train_images/c0a117de7d0a.png\n/kaggle/input/aptos2019/train_images/train_images/ab32db41c409.png\n/kaggle/input/aptos2019/train_images/train_images/2eba4279e503.png\n/kaggle/input/aptos2019/train_images/train_images/3c28fd846b43.png\n/kaggle/input/aptos2019/train_images/train_images/e30a890600e1.png\n/kaggle/input/aptos2019/train_images/train_images/6fbaaf8eb67a.png\n/kaggle/input/aptos2019/train_images/train_images/b6d9974443ce.png\n/kaggle/input/aptos2019/train_images/train_images/b6a0e348a01e.png\n/kaggle/input/aptos2019/train_images/train_images/e4d3d437b0a8.png\n/kaggle/input/aptos2019/train_images/train_images/4a558a1cd243.png\n/kaggle/input/aptos2019/train_images/train_images/1d3e9b939732.png\n/kaggle/input/aptos2019/train_images/train_images/628b581aa905.png\n/kaggle/input/aptos2019/train_images/train_images/7e160c8b611e.png\n/kaggle/input/aptos2019/train_images/train_images/be7f791a7877.png\n/kaggle/input/aptos2019/train_images/train_images/a664d2055886.png\n/kaggle/input/aptos2019/train_images/train_images/d2ffe9287dc7.png\n/kaggle/input/aptos2019/train_images/train_images/55eac26bd383.png\n/kaggle/input/aptos2019/train_images/train_images/b9127e38d9b9.png\n/kaggle/input/aptos2019/train_images/train_images/460893cd86e3.png\n/kaggle/input/aptos2019/train_images/train_images/5a27b9b2a9c1.png\n/kaggle/input/aptos2019/train_images/train_images/9bbb6c455913.png\n/kaggle/input/aptos2019/train_images/train_images/d95959798b57.png\n/kaggle/input/aptos2019/train_images/train_images/2e79041ef722.png\n/kaggle/input/aptos2019/train_images/train_images/da9262d9f5d9.png\n/kaggle/input/aptos2019/train_images/train_images/a82a12ad3fb1.png\n/kaggle/input/aptos2019/train_images/train_images/d3e884109b45.png\n/kaggle/input/aptos2019/train_images/train_images/6d292ca4c9ad.png\n/kaggle/input/aptos2019/train_images/train_images/d0d59ed675b5.png\n/kaggle/input/aptos2019/train_images/train_images/3b0190bbe615.png\n/kaggle/input/aptos2019/train_images/train_images/2ef955d6d9ff.png\n/kaggle/input/aptos2019/train_images/train_images/d6f36ec5564a.png\n/kaggle/input/aptos2019/train_images/train_images/3f752fcccec0.png\n/kaggle/input/aptos2019/train_images/train_images/a62e995f167c.png\n/kaggle/input/aptos2019/train_images/train_images/4145dcb25053.png\n/kaggle/input/aptos2019/train_images/train_images/4b422b48d0d4.png\n/kaggle/input/aptos2019/train_images/train_images/1c3a6b4449e9.png\n/kaggle/input/aptos2019/train_images/train_images/de57c9e9fa93.png\n/kaggle/input/aptos2019/train_images/train_images/bc34ed91c9bc.png\n/kaggle/input/aptos2019/train_images/train_images/92e3d608fd3c.png\n/kaggle/input/aptos2019/train_images/train_images/66460ecab347.png\n/kaggle/input/aptos2019/train_images/train_images/c6a145742708.png\n/kaggle/input/aptos2019/train_images/train_images/51405d042000.png\n/kaggle/input/aptos2019/train_images/train_images/afc345cc9145.png\n/kaggle/input/aptos2019/train_images/train_images/1f9ccda4ddf2.png\n/kaggle/input/aptos2019/train_images/train_images/261c6bd63bff.png\n/kaggle/input/aptos2019/train_images/train_images/59f3f70abddd.png\n/kaggle/input/aptos2019/train_images/train_images/cf8f1bc7a215.png\n/kaggle/input/aptos2019/train_images/train_images/942f544c4e15.png\n/kaggle/input/aptos2019/train_images/train_images/aa60813e1a8d.png\n/kaggle/input/aptos2019/train_images/train_images/6bf26b777e3a.png\n/kaggle/input/aptos2019/train_images/train_images/db4ed1e07aa3.png\n/kaggle/input/aptos2019/train_images/train_images/7ec1ffe8220b.png\n/kaggle/input/aptos2019/train_images/train_images/6f4719c6bb4b.png\n/kaggle/input/aptos2019/train_images/train_images/b07bc463b718.png\n/kaggle/input/aptos2019/train_images/train_images/9dab2e6ba44b.png\n/kaggle/input/aptos2019/train_images/train_images/226c6ceb9185.png\n/kaggle/input/aptos2019/train_images/train_images/382752f6694a.png\n/kaggle/input/aptos2019/train_images/train_images/5265dc9acdf8.png\n/kaggle/input/aptos2019/train_images/train_images/5f4a8c074bd5.png\n/kaggle/input/aptos2019/train_images/train_images/29a13e666266.png\n/kaggle/input/aptos2019/train_images/train_images/d659d7fd5ccf.png\n/kaggle/input/aptos2019/train_images/train_images/bd34a0639575.png\n/kaggle/input/aptos2019/train_images/train_images/44976c3b11a6.png\n/kaggle/input/aptos2019/train_images/train_images/d0b132d2c7ec.png\n/kaggle/input/aptos2019/train_images/train_images/b8e20c076b03.png\n/kaggle/input/aptos2019/train_images/train_images/abf0f56c6f12.png\n/kaggle/input/aptos2019/train_images/train_images/ad029ba7fa8b.png\n/kaggle/input/aptos2019/train_images/train_images/ad312ca98202.png\n/kaggle/input/aptos2019/train_images/train_images/737ef6226677.png\n/kaggle/input/aptos2019/train_images/train_images/5dd2e26fc244.png\n/kaggle/input/aptos2019/train_images/train_images/5c8482926a08.png\n/kaggle/input/aptos2019/train_images/train_images/d94e10f42861.png\n/kaggle/input/aptos2019/train_images/train_images/3f3de2a6b0f5.png\n/kaggle/input/aptos2019/train_images/train_images/c704bd669f36.png\n/kaggle/input/aptos2019/train_images/train_images/76e6a9238570.png\n/kaggle/input/aptos2019/train_images/train_images/58eb3809f456.png\n/kaggle/input/aptos2019/train_images/train_images/84c663f39632.png\n/kaggle/input/aptos2019/train_images/train_images/43ddd0ab0cc4.png\n/kaggle/input/aptos2019/train_images/train_images/2b10f138e67d.png\n/kaggle/input/aptos2019/train_images/train_images/3b9c1f42c2f2.png\n/kaggle/input/aptos2019/train_images/train_images/62b826899151.png\n/kaggle/input/aptos2019/train_images/train_images/710b05a96e0f.png\n/kaggle/input/aptos2019/train_images/train_images/857002ed4e49.png\n/kaggle/input/aptos2019/train_images/train_images/98f48850ebce.png\n/kaggle/input/aptos2019/train_images/train_images/d99b0f7dd9b9.png\n/kaggle/input/aptos2019/train_images/train_images/a88f68b0b114.png\n/kaggle/input/aptos2019/train_images/train_images/262ad704319c.png\n/kaggle/input/aptos2019/train_images/train_images/236f56771ec6.png\n/kaggle/input/aptos2019/train_images/train_images/709784f7fcc2.png\n/kaggle/input/aptos2019/train_images/train_images/211518c46162.png\n/kaggle/input/aptos2019/train_images/train_images/7102f29e052e.png\n/kaggle/input/aptos2019/train_images/train_images/ceb601fe8dba.png\n/kaggle/input/aptos2019/train_images/train_images/7bc4dd99eee5.png\n/kaggle/input/aptos2019/train_images/train_images/aeccef0bdc26.png\n/kaggle/input/aptos2019/train_images/train_images/2f9b66784109.png\n/kaggle/input/aptos2019/train_images/train_images/33e8e26a75d4.png\n/kaggle/input/aptos2019/train_images/train_images/86b3a7929bec.png\n/kaggle/input/aptos2019/train_images/train_images/d16398c971e9.png\n/kaggle/input/aptos2019/train_images/train_images/e10190a9d52f.png\n/kaggle/input/aptos2019/train_images/train_images/996f9bba4ef0.png\n/kaggle/input/aptos2019/train_images/train_images/93a1b984de84.png\n/kaggle/input/aptos2019/train_images/train_images/6c6efb6b1358.png\n/kaggle/input/aptos2019/train_images/train_images/9ac41b9a809e.png\n/kaggle/input/aptos2019/train_images/train_images/cc1eebed9276.png\n/kaggle/input/aptos2019/train_images/train_images/60e269e3e188.png\n/kaggle/input/aptos2019/train_images/train_images/944a233fbf8e.png\n/kaggle/input/aptos2019/train_images/train_images/b8fb9f55cd6d.png\n/kaggle/input/aptos2019/train_images/train_images/49386d603494.png\n/kaggle/input/aptos2019/train_images/train_images/4dd14c380696.png\n/kaggle/input/aptos2019/train_images/train_images/53704c80f0d8.png\n/kaggle/input/aptos2019/train_images/train_images/cb39761f0712.png\n/kaggle/input/aptos2019/train_images/train_images/35362d43e753.png\n/kaggle/input/aptos2019/train_images/train_images/6e861bc3bd7b.png\n/kaggle/input/aptos2019/train_images/train_images/ad6b07d5c338.png\n/kaggle/input/aptos2019/train_images/train_images/4360a112db10.png\n/kaggle/input/aptos2019/train_images/train_images/6e092caa065f.png\n/kaggle/input/aptos2019/train_images/train_images/263d8851e33b.png\n/kaggle/input/aptos2019/train_images/train_images/bdb98063fe84.png\n/kaggle/input/aptos2019/train_images/train_images/c639d837f5e4.png\n/kaggle/input/aptos2019/train_images/train_images/3079490a4b9c.png\n/kaggle/input/aptos2019/train_images/train_images/58059e73d2d4.png\n/kaggle/input/aptos2019/train_images/train_images/6e0f78e188ff.png\n/kaggle/input/aptos2019/train_images/train_images/49c5e7f6b8d2.png\n/kaggle/input/aptos2019/train_images/train_images/64ac539f58cb.png\n/kaggle/input/aptos2019/train_images/train_images/b0619ca93a5f.png\n/kaggle/input/aptos2019/train_images/train_images/23d7ca170bdb.png\n/kaggle/input/aptos2019/train_images/train_images/1d46f1326394.png\n/kaggle/input/aptos2019/train_images/train_images/7d94a000c2d0.png\n/kaggle/input/aptos2019/train_images/train_images/40140a925c43.png\n/kaggle/input/aptos2019/train_images/train_images/91a88d3b0358.png\n/kaggle/input/aptos2019/train_images/train_images/453a1e2754b2.png\n/kaggle/input/aptos2019/train_images/train_images/c8fc0df22999.png\n/kaggle/input/aptos2019/train_images/train_images/77b7b71ebcc3.png\n/kaggle/input/aptos2019/train_images/train_images/da8900ac7f29.png\n/kaggle/input/aptos2019/train_images/train_images/61c2fbd16e38.png\n/kaggle/input/aptos2019/train_images/train_images/48afe8c47454.png\n/kaggle/input/aptos2019/train_images/train_images/30db694bee42.png\n/kaggle/input/aptos2019/train_images/train_images/80e7cc0a0649.png\n/kaggle/input/aptos2019/train_images/train_images/bb85097857fa.png\n/kaggle/input/aptos2019/train_images/train_images/885fa5fc5da8.png\n/kaggle/input/aptos2019/train_images/train_images/32ed318235b8.png\n/kaggle/input/aptos2019/train_images/train_images/aa6242f9e08c.png\n/kaggle/input/aptos2019/train_images/train_images/a7b0d0c51731.png\n/kaggle/input/aptos2019/train_images/train_images/788ddb0b70b7.png\n/kaggle/input/aptos2019/train_images/train_images/41ab357d103f.png\n/kaggle/input/aptos2019/train_images/train_images/91cf56d3d1af.png\n/kaggle/input/aptos2019/train_images/train_images/6f3b62e5b7f5.png\n/kaggle/input/aptos2019/train_images/train_images/1bea04b2bb2d.png\n/kaggle/input/aptos2019/train_images/train_images/e47452069ea1.png\n/kaggle/input/aptos2019/train_images/train_images/a9c7b83caf81.png\n/kaggle/input/aptos2019/train_images/train_images/53273d664cd8.png\n/kaggle/input/aptos2019/train_images/train_images/5e505e25cd3e.png\n/kaggle/input/aptos2019/train_images/train_images/62cc7ddb53b6.png\n/kaggle/input/aptos2019/train_images/train_images/6cd606dc52e9.png\n/kaggle/input/aptos2019/train_images/train_images/b200c23b299b.png\n/kaggle/input/aptos2019/train_images/train_images/1ca35d483772.png\n/kaggle/input/aptos2019/train_images/train_images/a1faeb4d5f10.png\n/kaggle/input/aptos2019/train_images/train_images/58c12863f33d.png\n/kaggle/input/aptos2019/train_images/train_images/65dda202653d.png\n/kaggle/input/aptos2019/train_images/train_images/1f5496352859.png\n/kaggle/input/aptos2019/train_images/train_images/bfa30ebf63a8.png\n/kaggle/input/aptos2019/train_images/train_images/9d74428188bb.png\n/kaggle/input/aptos2019/train_images/train_images/6dc0281f11e3.png\n/kaggle/input/aptos2019/train_images/train_images/63a03880939c.png\n/kaggle/input/aptos2019/train_images/train_images/237aa50edc34.png\n/kaggle/input/aptos2019/train_images/train_images/4a1afe4044f4.png\n/kaggle/input/aptos2019/train_images/train_images/a8c9fcdbc0be.png\n/kaggle/input/aptos2019/train_images/train_images/8433a032b96c.png\n/kaggle/input/aptos2019/train_images/train_images/c4aef0d88d1b.png\n/kaggle/input/aptos2019/train_images/train_images/bf8092e4001d.png\n/kaggle/input/aptos2019/train_images/train_images/6c3745a222da.png\n/kaggle/input/aptos2019/train_images/train_images/3908b3cfd620.png\n/kaggle/input/aptos2019/train_images/train_images/ce6f33a81ad5.png\n/kaggle/input/aptos2019/train_images/train_images/b9b6ee2b9453.png\n/kaggle/input/aptos2019/train_images/train_images/4b6895d0cf8d.png\n/kaggle/input/aptos2019/train_images/train_images/1f63d44d9e3c.png\n/kaggle/input/aptos2019/train_images/train_images/8446826853d0.png\n/kaggle/input/aptos2019/train_images/train_images/523d0c2cb4d6.png\n/kaggle/input/aptos2019/train_images/train_images/9eaf735cf01f.png\n/kaggle/input/aptos2019/train_images/train_images/a73d012c4c38.png\n/kaggle/input/aptos2019/train_images/train_images/c9e697117f3f.png\n/kaggle/input/aptos2019/train_images/train_images/d801c0a66738.png\n/kaggle/input/aptos2019/train_images/train_images/45e4b7eada54.png\n/kaggle/input/aptos2019/train_images/train_images/8b76c3c5cb3e.png\n/kaggle/input/aptos2019/train_images/train_images/207a580de0ea.png\n/kaggle/input/aptos2019/train_images/train_images/7526cf435753.png\n/kaggle/input/aptos2019/train_images/train_images/b5b913358b32.png\n/kaggle/input/aptos2019/train_images/train_images/9a159d4674cd.png\n/kaggle/input/aptos2019/train_images/train_images/dcc6c0ad5cad.png\n/kaggle/input/aptos2019/train_images/train_images/374535e0adb8.png\n/kaggle/input/aptos2019/train_images/train_images/77a1f1398fdb.png\n/kaggle/input/aptos2019/train_images/train_images/a2696f444ecb.png\n/kaggle/input/aptos2019/train_images/train_images/2ef10194e80d.png\n/kaggle/input/aptos2019/train_images/train_images/5077cdb88aed.png\n/kaggle/input/aptos2019/train_images/train_images/4cfd22ae43d4.png\n/kaggle/input/aptos2019/train_images/train_images/c755a0c4edcc.png\n/kaggle/input/aptos2019/train_images/train_images/1df0a4c23c95.png\n/kaggle/input/aptos2019/train_images/train_images/342edf9b889d.png\n/kaggle/input/aptos2019/train_images/train_images/1d55e689cf84.png\n/kaggle/input/aptos2019/train_images/train_images/d8cdb7d7283a.png\n/kaggle/input/aptos2019/train_images/train_images/ba2624883599.png\n/kaggle/input/aptos2019/train_images/train_images/e322acd46152.png\n/kaggle/input/aptos2019/train_images/train_images/9a94e0316ee3.png\n/kaggle/input/aptos2019/train_images/train_images/98e44127872f.png\n/kaggle/input/aptos2019/train_images/train_images/349f3c0ac83e.png\n/kaggle/input/aptos2019/train_images/train_images/8bf2d925dc0c.png\n/kaggle/input/aptos2019/train_images/train_images/657859f893d9.png\n/kaggle/input/aptos2019/train_images/train_images/8dfff47b06b7.png\n/kaggle/input/aptos2019/train_images/train_images/6ea07d19b4ce.png\n/kaggle/input/aptos2019/train_images/train_images/9f8112c710be.png\n/kaggle/input/aptos2019/train_images/train_images/85cc6d636898.png\n/kaggle/input/aptos2019/train_images/train_images/224c14366e11.png\n/kaggle/input/aptos2019/train_images/train_images/bf1b7e21e774.png\n/kaggle/input/aptos2019/train_images/train_images/8cb6b5b2f19c.png\n/kaggle/input/aptos2019/train_images/train_images/e246cd89e1cc.png\n/kaggle/input/aptos2019/train_images/train_images/b4b04d81acbb.png\n/kaggle/input/aptos2019/train_images/train_images/a5bb85afc6e8.png\n/kaggle/input/aptos2019/train_images/train_images/4e54ccfd49b2.png\n/kaggle/input/aptos2019/train_images/train_images/4c3c1ed09771.png\n/kaggle/input/aptos2019/train_images/train_images/3de8ad4151e1.png\n/kaggle/input/aptos2019/train_images/train_images/1fb455685328.png\n/kaggle/input/aptos2019/train_images/train_images/b927a9238434.png\n/kaggle/input/aptos2019/train_images/train_images/370f575adb23.png\n/kaggle/input/aptos2019/train_images/train_images/7ce671f952be.png\n/kaggle/input/aptos2019/train_images/train_images/e160a3b19911.png\n/kaggle/input/aptos2019/train_images/train_images/d85588ff2ebd.png\n/kaggle/input/aptos2019/train_images/train_images/4bcee3cbe232.png\n/kaggle/input/aptos2019/train_images/train_images/4c17e85686f0.png\n/kaggle/input/aptos2019/train_images/train_images/25d069089c5e.png\n/kaggle/input/aptos2019/train_images/train_images/445a8a6da55c.png\n/kaggle/input/aptos2019/train_images/train_images/c8a3eb9a5b52.png\n/kaggle/input/aptos2019/train_images/train_images/da9fe02dead3.png\n/kaggle/input/aptos2019/train_images/train_images/a0d04a19cf40.png\n/kaggle/input/aptos2019/train_images/train_images/883ddb650967.png\n/kaggle/input/aptos2019/train_images/train_images/63c7b0265775.png\n/kaggle/input/aptos2019/train_images/train_images/b86fb2d5be1a.png\n/kaggle/input/aptos2019/train_images/train_images/47e51065b819.png\n/kaggle/input/aptos2019/train_images/train_images/30941b65348b.png\n/kaggle/input/aptos2019/train_images/train_images/b376def52ccc.png\n/kaggle/input/aptos2019/train_images/train_images/aa8a1e814811.png\n/kaggle/input/aptos2019/train_images/train_images/c98f623d08d1.png\n/kaggle/input/aptos2019/train_images/train_images/624fb7317106.png\n/kaggle/input/aptos2019/train_images/train_images/66cd9c28e636.png\n/kaggle/input/aptos2019/train_images/train_images/d6df4fe492ec.png\n/kaggle/input/aptos2019/train_images/train_images/573ea80a53be.png\n/kaggle/input/aptos2019/train_images/train_images/e2a233493b90.png\n/kaggle/input/aptos2019/train_images/train_images/4f6abc40c72d.png\n/kaggle/input/aptos2019/train_images/train_images/6cbc3dad809c.png\n/kaggle/input/aptos2019/train_images/train_images/4ecd1fdd1435.png\n/kaggle/input/aptos2019/train_images/train_images/4e82c3c8d31f.png\n/kaggle/input/aptos2019/train_images/train_images/62b4be2799ca.png\n/kaggle/input/aptos2019/train_images/train_images/757e39293591.png\n/kaggle/input/aptos2019/train_images/train_images/5288f7441f64.png\n/kaggle/input/aptos2019/train_images/train_images/d7a01fca9838.png\n/kaggle/input/aptos2019/train_images/train_images/441117562359.png\n/kaggle/input/aptos2019/train_images/train_images/74898f372d2b.png\n/kaggle/input/aptos2019/train_images/train_images/1ca91751be4d.png\n/kaggle/input/aptos2019/train_images/train_images/6a244e855d0e.png\n/kaggle/input/aptos2019/train_images/train_images/b553e7909535.png\n/kaggle/input/aptos2019/train_images/train_images/504a69096fcb.png\n/kaggle/input/aptos2019/train_images/train_images/aca88f566228.png\n/kaggle/input/aptos2019/train_images/train_images/3d2ecffe0386.png\n/kaggle/input/aptos2019/train_images/train_images/6630f8675a97.png\n/kaggle/input/aptos2019/train_images/train_images/5d4e5fd34d91.png\n/kaggle/input/aptos2019/train_images/train_images/22895c89792f.png\n/kaggle/input/aptos2019/train_images/train_images/3730c322d35b.png\n/kaggle/input/aptos2019/train_images/train_images/58af2c054ced.png\n/kaggle/input/aptos2019/train_images/train_images/655cafb4c932.png\n/kaggle/input/aptos2019/train_images/train_images/86baef833ae0.png\n/kaggle/input/aptos2019/train_images/train_images/d6283ded6aea.png\n/kaggle/input/aptos2019/train_images/train_images/76bc31e0d3be.png\n/kaggle/input/aptos2019/train_images/train_images/9da74370835a.png\n/kaggle/input/aptos2019/train_images/train_images/351e842842a2.png\n/kaggle/input/aptos2019/train_images/train_images/883c6a184f16.png\n/kaggle/input/aptos2019/train_images/train_images/415f2d2bd2a1.png\n/kaggle/input/aptos2019/train_images/train_images/a1b28bcbce00.png\n/kaggle/input/aptos2019/train_images/train_images/92f313287a29.png\n/kaggle/input/aptos2019/train_images/train_images/dee1031a76ae.png\n/kaggle/input/aptos2019/train_images/train_images/57f933d3d7c7.png\n/kaggle/input/aptos2019/train_images/train_images/9f436886e056.png\n/kaggle/input/aptos2019/train_images/train_images/4e0656629d02.png\n/kaggle/input/aptos2019/train_images/train_images/4e85aa647534.png\n/kaggle/input/aptos2019/train_images/train_images/2bd4d4fbed5c.png\n/kaggle/input/aptos2019/train_images/train_images/8d9516ea3587.png\n/kaggle/input/aptos2019/train_images/train_images/bc92a61a1f9c.png\n/kaggle/input/aptos2019/train_images/train_images/d7bc62d60e8c.png\n/kaggle/input/aptos2019/train_images/train_images/568455854a11.png\n/kaggle/input/aptos2019/train_images/train_images/5fcff7280019.png\n/kaggle/input/aptos2019/train_images/train_images/6cb96a6fb029.png\n/kaggle/input/aptos2019/train_images/train_images/a87f53bc984a.png\n/kaggle/input/aptos2019/train_images/train_images/338326891d84.png\n/kaggle/input/aptos2019/train_images/train_images/66bae1ba227f.png\n/kaggle/input/aptos2019/train_images/train_images/df6d13d04da1.png\n/kaggle/input/aptos2019/train_images/train_images/c3c8fdda50c0.png\n/kaggle/input/aptos2019/train_images/train_images/ad570b850a4f.png\n/kaggle/input/aptos2019/train_images/train_images/33b893e18eb3.png\n/kaggle/input/aptos2019/train_images/train_images/3ccf96c1dd6d.png\n/kaggle/input/aptos2019/train_images/train_images/354b8911d6ed.png\n/kaggle/input/aptos2019/train_images/train_images/c7e827fc7f41.png\n/kaggle/input/aptos2019/train_images/train_images/e2a47a74e6e1.png\n/kaggle/input/aptos2019/train_images/train_images/e2ec22b3d07e.png\n/kaggle/input/aptos2019/train_images/train_images/1cb814ed6332.png\n/kaggle/input/aptos2019/train_images/train_images/2bbd1f99ecc3.png\n/kaggle/input/aptos2019/train_images/train_images/874f8c1929f6.png\n/kaggle/input/aptos2019/train_images/train_images/40dd4e6e4444.png\n/kaggle/input/aptos2019/train_images/train_images/87d46b1cc4e9.png\n/kaggle/input/aptos2019/train_images/train_images/692e946b1f85.png\n/kaggle/input/aptos2019/train_images/train_images/760b6f4c6d82.png\n/kaggle/input/aptos2019/train_images/train_images/1c4d87baaffc.png\n/kaggle/input/aptos2019/train_images/train_images/84b472c49cfa.png\n/kaggle/input/aptos2019/train_images/train_images/2cef97083e6f.png\n/kaggle/input/aptos2019/train_images/train_images/71c22da3d6c6.png\n/kaggle/input/aptos2019/train_images/train_images/25002fe43f92.png\n/kaggle/input/aptos2019/train_images/train_images/401fdfd0db07.png\n/kaggle/input/aptos2019/train_images/train_images/7bda86d95c5b.png\n/kaggle/input/aptos2019/train_images/train_images/7455e2b5fc57.png\n/kaggle/input/aptos2019/train_images/train_images/1e8c31e29dd3.png\n/kaggle/input/aptos2019/train_images/train_images/b1c6f0997e27.png\n/kaggle/input/aptos2019/train_images/train_images/200d947f75db.png\n/kaggle/input/aptos2019/train_images/train_images/75c180e04f65.png\n/kaggle/input/aptos2019/train_images/train_images/55034b1dbff2.png\n/kaggle/input/aptos2019/train_images/train_images/959bb2d01091.png\n/kaggle/input/aptos2019/train_images/train_images/3ac92ac3d65a.png\n/kaggle/input/aptos2019/train_images/train_images/d29096bd94aa.png\n/kaggle/input/aptos2019/train_images/train_images/7ec0e61a7e29.png\n/kaggle/input/aptos2019/train_images/train_images/85f99e7e4052.png\n/kaggle/input/aptos2019/train_images/train_images/1db0393cdbc1.png\n/kaggle/input/aptos2019/train_images/train_images/565f3404f9b2.png\n/kaggle/input/aptos2019/train_images/train_images/2b07790a2422.png\n/kaggle/input/aptos2019/train_images/train_images/bcb0498ed2c1.png\n/kaggle/input/aptos2019/train_images/train_images/a3ad6c2db6f1.png\n/kaggle/input/aptos2019/train_images/train_images/328d141ed3aa.png\n/kaggle/input/aptos2019/train_images/train_images/b70cb31b9abb.png\n/kaggle/input/aptos2019/train_images/train_images/1f0e223b8055.png\n/kaggle/input/aptos2019/train_images/train_images/5e7db41b3bee.png\n/kaggle/input/aptos2019/train_images/train_images/2c1d5be654dd.png\n/kaggle/input/aptos2019/train_images/train_images/83517eaeccb9.png\n/kaggle/input/aptos2019/train_images/train_images/d1f1ea894da1.png\n/kaggle/input/aptos2019/train_images/train_images/203275daf46d.png\n/kaggle/input/aptos2019/train_images/train_images/356304d15a5c.png\n/kaggle/input/aptos2019/train_images/train_images/946545473380.png\n/kaggle/input/aptos2019/train_images/train_images/3bf3085ac167.png\n/kaggle/input/aptos2019/train_images/train_images/95a4cc805c7b.png\n/kaggle/input/aptos2019/train_images/train_images/5ea9e447bb62.png\n/kaggle/input/aptos2019/train_images/train_images/9f4132bd6ed6.png\n/kaggle/input/aptos2019/train_images/train_images/e4c799738a19.png\n/kaggle/input/aptos2019/train_images/train_images/239f2c348ea4.png\n/kaggle/input/aptos2019/train_images/train_images/6181aa9f75f4.png\n/kaggle/input/aptos2019/train_images/train_images/55eb405ec71e.png\n/kaggle/input/aptos2019/train_images/train_images/d436c06f0490.png\n/kaggle/input/aptos2019/train_images/train_images/6e018411ba4a.png\n/kaggle/input/aptos2019/train_images/train_images/87a9f4d20f07.png\n/kaggle/input/aptos2019/train_images/train_images/d2901144070c.png\n/kaggle/input/aptos2019/train_images/train_images/b64e1eef3d63.png\n/kaggle/input/aptos2019/train_images/train_images/89ee1fa16f90.png\n/kaggle/input/aptos2019/train_images/train_images/ae58ccb5905e.png\n/kaggle/input/aptos2019/train_images/train_images/8bbd7835e9aa.png\n/kaggle/input/aptos2019/train_images/train_images/7adfb8fc0621.png\n/kaggle/input/aptos2019/train_images/train_images/a30a143a53a3.png\n/kaggle/input/aptos2019/train_images/train_images/75a7bc945b7d.png\n/kaggle/input/aptos2019/train_images/train_images/b468ebf5cb11.png\n/kaggle/input/aptos2019/train_images/train_images/5b644a403e1f.png\n/kaggle/input/aptos2019/train_images/train_images/dc0eea0b68a7.png\n/kaggle/input/aptos2019/train_images/train_images/dbb2c63f6f08.png\n/kaggle/input/aptos2019/train_images/train_images/55092c0071eb.png\n/kaggle/input/aptos2019/train_images/train_images/299086c6d1b5.png\n/kaggle/input/aptos2019/train_images/train_images/97bf61736b86.png\n/kaggle/input/aptos2019/train_images/train_images/5327f88a1919.png\n/kaggle/input/aptos2019/train_images/train_images/b5bf7b84fc66.png\n/kaggle/input/aptos2019/train_images/train_images/3dbc90c7ee7d.png\n/kaggle/input/aptos2019/train_images/train_images/2dd28ac497d2.png\n/kaggle/input/aptos2019/train_images/train_images/ca7570c5925c.png\n/kaggle/input/aptos2019/train_images/train_images/9cedf5c7016b.png\n/kaggle/input/aptos2019/train_images/train_images/94b9ccc73bb9.png\n/kaggle/input/aptos2019/train_images/train_images/5f13e8a07344.png\n/kaggle/input/aptos2019/train_images/train_images/6966abf40b8c.png\n/kaggle/input/aptos2019/train_images/train_images/6af071b0ac6e.png\n/kaggle/input/aptos2019/train_images/train_images/80f6b30ece8c.png\n/kaggle/input/aptos2019/train_images/train_images/cc839823755b.png\n/kaggle/input/aptos2019/train_images/train_images/be3a7d9e981e.png\n/kaggle/input/aptos2019/train_images/train_images/63e041a757eb.png\n/kaggle/input/aptos2019/train_images/train_images/9b418ce42c13.png\n/kaggle/input/aptos2019/train_images/train_images/44271f3cb18f.png\n/kaggle/input/aptos2019/train_images/train_images/a627eb8c08c5.png\n/kaggle/input/aptos2019/train_images/train_images/2d7666b8884f.png\n/kaggle/input/aptos2019/train_images/train_images/ae61e19fb766.png\n/kaggle/input/aptos2019/train_images/train_images/23fca0693e2a.png\n/kaggle/input/aptos2019/train_images/train_images/b498b84d383f.png\n/kaggle/input/aptos2019/train_images/train_images/6110ecb3bb1c.png\n/kaggle/input/aptos2019/train_images/train_images/2f7789c1e046.png\n/kaggle/input/aptos2019/train_images/train_images/aaaadb174012.png\n/kaggle/input/aptos2019/train_images/train_images/4e8585a96739.png\n/kaggle/input/aptos2019/train_images/train_images/2994f17f58a5.png\n/kaggle/input/aptos2019/train_images/train_images/a4b8de38eac1.png\n/kaggle/input/aptos2019/train_images/train_images/a45d77edf8d9.png\n/kaggle/input/aptos2019/train_images/train_images/b402daa0864c.png\n/kaggle/input/aptos2019/train_images/train_images/c62585bd68fb.png\n/kaggle/input/aptos2019/train_images/train_images/7f1f3269f546.png\n/kaggle/input/aptos2019/train_images/train_images/d18b1d8ac4de.png\n/kaggle/input/aptos2019/train_images/train_images/bb783d8e496f.png\n/kaggle/input/aptos2019/train_images/train_images/c6f5b5b5be41.png\n/kaggle/input/aptos2019/train_images/train_images/2967e578939f.png\n/kaggle/input/aptos2019/train_images/train_images/e1e490773462.png\n/kaggle/input/aptos2019/train_images/train_images/42c65af5ab16.png\n/kaggle/input/aptos2019/train_images/train_images/907aaff827e5.png\n/kaggle/input/aptos2019/train_images/train_images/6324d77cf926.png\n/kaggle/input/aptos2019/train_images/train_images/586f5c56081e.png\n/kaggle/input/aptos2019/train_images/train_images/4ccfa0b4e96c.png\n/kaggle/input/aptos2019/train_images/train_images/89ed6a0dd53f.png\n/kaggle/input/aptos2019/train_images/train_images/9df31421cdd2.png\n/kaggle/input/aptos2019/train_images/train_images/5e5275ddee29.png\n/kaggle/input/aptos2019/train_images/train_images/4318b6adeb97.png\n/kaggle/input/aptos2019/train_images/train_images/d990a3f0cbdb.png\n/kaggle/input/aptos2019/train_images/train_images/5b301a6d1ac7.png\n/kaggle/input/aptos2019/train_images/train_images/26d9576e8043.png\n/kaggle/input/aptos2019/train_images/train_images/ae57c8630249.png\n/kaggle/input/aptos2019/train_images/train_images/a76132e79688.png\n/kaggle/input/aptos2019/train_images/train_images/383e72af1955.png\n/kaggle/input/aptos2019/train_images/train_images/762d6e5d5068.png\n/kaggle/input/aptos2019/train_images/train_images/6d259b5b4c76.png\n/kaggle/input/aptos2019/train_images/train_images/d3be5346684b.png\n/kaggle/input/aptos2019/train_images/train_images/2974c6ad1d58.png\n/kaggle/input/aptos2019/train_images/train_images/8c84e96d9b01.png\n/kaggle/input/aptos2019/train_images/train_images/89fc080f7e83.png\n/kaggle/input/aptos2019/train_images/train_images/b94c58d063bf.png\n/kaggle/input/aptos2019/train_images/train_images/4d1e7def7624.png\n/kaggle/input/aptos2019/train_images/train_images/902dc5a91a3f.png\n/kaggle/input/aptos2019/train_images/train_images/91f3c4c1e72b.png\n/kaggle/input/aptos2019/train_images/train_images/d144144a2f3f.png\n/kaggle/input/aptos2019/train_images/train_images/4982378d72f9.png\n/kaggle/input/aptos2019/train_images/train_images/aafb0c944f14.png\n/kaggle/input/aptos2019/train_images/train_images/3f44d749cd0b.png\n/kaggle/input/aptos2019/train_images/train_images/38373431d996.png\n/kaggle/input/aptos2019/train_images/train_images/8010c931321f.png\n/kaggle/input/aptos2019/train_images/train_images/77e15f213b04.png\n/kaggle/input/aptos2019/train_images/train_images/5ad3dabeb2cd.png\n/kaggle/input/aptos2019/train_images/train_images/582115961a3d.png\n/kaggle/input/aptos2019/train_images/train_images/975252e325e3.png\n/kaggle/input/aptos2019/train_images/train_images/e4730ddde408.png\n/kaggle/input/aptos2019/train_images/train_images/54f57cf26126.png\n/kaggle/input/aptos2019/train_images/train_images/3e61703b5ab2.png\n/kaggle/input/aptos2019/train_images/train_images/2af1bf226f51.png\n/kaggle/input/aptos2019/train_images/train_images/83b61051737f.png\n/kaggle/input/aptos2019/train_images/train_images/6810410187a0.png\n/kaggle/input/aptos2019/train_images/train_images/a804cef3e51f.png\n/kaggle/input/aptos2019/train_images/train_images/9d1feed37610.png\n/kaggle/input/aptos2019/train_images/train_images/916ec976ff30.png\n/kaggle/input/aptos2019/train_images/train_images/34acae864963.png\n/kaggle/input/aptos2019/train_images/train_images/63b71347e95d.png\n/kaggle/input/aptos2019/train_images/train_images/a8c54e2a4b79.png\n/kaggle/input/aptos2019/train_images/train_images/c58971bcebb2.png\n/kaggle/input/aptos2019/train_images/train_images/79ce83c07588.png\n/kaggle/input/aptos2019/train_images/train_images/5a36cea278ae.png\n/kaggle/input/aptos2019/train_images/train_images/1c6d119c3d70.png\n/kaggle/input/aptos2019/train_images/train_images/4189d4e631ec.png\n/kaggle/input/aptos2019/train_images/train_images/4c60f6fcea75.png\n/kaggle/input/aptos2019/train_images/train_images/c6229222bf22.png\n/kaggle/input/aptos2019/train_images/train_images/e26d8718ca58.png\n/kaggle/input/aptos2019/train_images/train_images/cd48cfab4e44.png\n/kaggle/input/aptos2019/train_images/train_images/bc7bf19b84e3.png\n/kaggle/input/aptos2019/train_images/train_images/cd563556cb57.png\n/kaggle/input/aptos2019/train_images/train_images/767d777ee889.png\n/kaggle/input/aptos2019/train_images/train_images/60aa4e649abf.png\n/kaggle/input/aptos2019/train_images/train_images/247ac63e5510.png\n/kaggle/input/aptos2019/train_images/train_images/24f3e70f0419.png\n/kaggle/input/aptos2019/train_images/train_images/1e8a1fdee5b9.png\n/kaggle/input/aptos2019/train_images/train_images/6852f4531591.png\n/kaggle/input/aptos2019/train_images/train_images/8a01daa423f7.png\n/kaggle/input/aptos2019/train_images/train_images/435d900fa7b2.png\n/kaggle/input/aptos2019/train_images/train_images/9c72ed6befa0.png\n/kaggle/input/aptos2019/train_images/train_images/855f0a5442b6.png\n/kaggle/input/aptos2019/train_images/train_images/358d2224de73.png\n/kaggle/input/aptos2019/train_images/train_images/a0cd7bffdaa0.png\n/kaggle/input/aptos2019/train_images/train_images/2f7fbdcc9a4b.png\n/kaggle/input/aptos2019/train_images/train_images/7a9f45fdf29b.png\n/kaggle/input/aptos2019/train_images/train_images/aeab0a63bcaf.png\n/kaggle/input/aptos2019/train_images/train_images/74211a2b6dcf.png\n/kaggle/input/aptos2019/train_images/train_images/7a6e384a0846.png\n/kaggle/input/aptos2019/train_images/train_images/5347b4c8e9b3.png\n/kaggle/input/aptos2019/train_images/train_images/878a3a097436.png\n/kaggle/input/aptos2019/train_images/train_images/6bf2a81a5d91.png\n/kaggle/input/aptos2019/train_images/train_images/1dbdc32c17db.png\n/kaggle/input/aptos2019/train_images/train_images/9904939ab83d.png\n/kaggle/input/aptos2019/train_images/train_images/a73c3d516c59.png\n/kaggle/input/aptos2019/train_images/train_images/bfda2fd0533a.png\n/kaggle/input/aptos2019/train_images/train_images/b2748ac28fc1.png\n/kaggle/input/aptos2019/train_images/train_images/d567a1a22d33.png\n/kaggle/input/aptos2019/train_images/train_images/2c9dfc270f1b.png\n/kaggle/input/aptos2019/train_images/train_images/772af553b8b7.png\n/kaggle/input/aptos2019/train_images/train_images/cae51154e1ce.png\n/kaggle/input/aptos2019/train_images/train_images/4d167ca69ea8.png\n/kaggle/input/aptos2019/train_images/train_images/9ad92f1c1542.png\n/kaggle/input/aptos2019/train_images/train_images/c80f79579fed.png\n/kaggle/input/aptos2019/train_images/train_images/aabd867043cf.png\n/kaggle/input/aptos2019/train_images/train_images/bba38f2294a3.png\n/kaggle/input/aptos2019/train_images/train_images/51a1d162e223.png\n/kaggle/input/aptos2019/train_images/train_images/ace2281f00c4.png\n/kaggle/input/aptos2019/train_images/train_images/248139c423c4.png\n/kaggle/input/aptos2019/train_images/train_images/c568e5245ea5.png\n/kaggle/input/aptos2019/train_images/train_images/96ce10a1dbd7.png\n/kaggle/input/aptos2019/train_images/train_images/76cab26493f1.png\n/kaggle/input/aptos2019/train_images/train_images/b0cc9f8d06e4.png\n/kaggle/input/aptos2019/train_images/train_images/595446774178.png\n/kaggle/input/aptos2019/train_images/train_images/caec68f11c86.png\n/kaggle/input/aptos2019/train_images/train_images/cfd1bd0fcbb4.png\n/kaggle/input/aptos2019/train_images/train_images/9b70f84400af.png\n/kaggle/input/aptos2019/train_images/train_images/345b1f0abbba.png\n/kaggle/input/aptos2019/train_images/train_images/2a3a1ed1c285.png\n/kaggle/input/aptos2019/train_images/train_images/aba3063c5413.png\n/kaggle/input/aptos2019/train_images/train_images/5db2e3a4594a.png\n/kaggle/input/aptos2019/train_images/train_images/a04fb36db784.png\n/kaggle/input/aptos2019/train_images/train_images/ce8d2efd9d4f.png\n/kaggle/input/aptos2019/train_images/train_images/a2dff8dbc9f8.png\n/kaggle/input/aptos2019/train_images/train_images/61c667663f2f.png\n/kaggle/input/aptos2019/train_images/train_images/cae33655ca00.png\n/kaggle/input/aptos2019/train_images/train_images/adb56cecafaf.png\n/kaggle/input/aptos2019/train_images/train_images/83d81ba5959c.png\n/kaggle/input/aptos2019/train_images/train_images/a8652b2de23f.png\n/kaggle/input/aptos2019/train_images/train_images/e12df54e0d1e.png\n/kaggle/input/aptos2019/train_images/train_images/d807c53c1399.png\n/kaggle/input/aptos2019/train_images/train_images/d10d315f123f.png\n/kaggle/input/aptos2019/train_images/train_images/d29b37d110f3.png\n/kaggle/input/aptos2019/train_images/train_images/4350a1b2f3cb.png\n/kaggle/input/aptos2019/train_images/train_images/c8823cdaf7fa.png\n/kaggle/input/aptos2019/train_images/train_images/3d663a6a50a3.png\n/kaggle/input/aptos2019/train_images/train_images/8ffa608170d3.png\n/kaggle/input/aptos2019/train_images/train_images/7e70344b0c25.png\n/kaggle/input/aptos2019/train_images/train_images/1db6bb46c102.png\n/kaggle/input/aptos2019/train_images/train_images/1e9224ccca95.png\n/kaggle/input/aptos2019/train_images/train_images/6e73acb2cf60.png\n/kaggle/input/aptos2019/train_images/train_images/2a2a6435f7f3.png\n/kaggle/input/aptos2019/train_images/train_images/7d1da90d3ca9.png\n/kaggle/input/aptos2019/train_images/train_images/80feb1f7ca5e.png\n/kaggle/input/aptos2019/train_images/train_images/a64273801bde.png\n/kaggle/input/aptos2019/train_images/train_images/2735be026d44.png\n/kaggle/input/aptos2019/train_images/train_images/3f49f8d100e9.png\n/kaggle/input/aptos2019/train_images/train_images/b574d229ec4c.png\n/kaggle/input/aptos2019/train_images/train_images/5ed6dc419e4d.png\n/kaggle/input/aptos2019/train_images/train_images/7a42443ed106.png\n/kaggle/input/aptos2019/train_images/train_images/aeb6f4fd2eed.png\n/kaggle/input/aptos2019/train_images/train_images/9c5dd3612f0c.png\n/kaggle/input/aptos2019/train_images/train_images/ababe19ed448.png\n/kaggle/input/aptos2019/train_images/train_images/d57d1be1bbd1.png\n/kaggle/input/aptos2019/train_images/train_images/4f60129e9a5b.png\n/kaggle/input/aptos2019/train_images/train_images/c90c6b94cf40.png\n/kaggle/input/aptos2019/train_images/train_images/d2fb715b0c41.png\n/kaggle/input/aptos2019/train_images/train_images/3ca637fddd56.png\n/kaggle/input/aptos2019/train_images/train_images/df0886f1e76b.png\n/kaggle/input/aptos2019/train_images/train_images/d1a24527a15d.png\n/kaggle/input/aptos2019/train_images/train_images/d9d2631f043c.png\n/kaggle/input/aptos2019/train_images/train_images/1c5e6cdc7ee1.png\n/kaggle/input/aptos2019/train_images/train_images/54038e56131d.png\n/kaggle/input/aptos2019/train_images/train_images/b0f8613305a3.png\n/kaggle/input/aptos2019/train_images/train_images/5905a9b06a73.png\n/kaggle/input/aptos2019/train_images/train_images/3732de8b416f.png\n/kaggle/input/aptos2019/train_images/train_images/c9c563864ab1.png\n/kaggle/input/aptos2019/train_images/train_images/8e67f2d7e0ee.png\n/kaggle/input/aptos2019/train_images/train_images/a9b3177f01c0.png\n/kaggle/input/aptos2019/train_images/train_images/e07045d7c5f7.png\n/kaggle/input/aptos2019/train_images/train_images/6531070bf03c.png\n/kaggle/input/aptos2019/train_images/train_images/283c3aeba594.png\n/kaggle/input/aptos2019/train_images/train_images/9c52b87d01f1.png\n/kaggle/input/aptos2019/train_images/train_images/c31651ea04c6.png\n/kaggle/input/aptos2019/train_images/train_images/38b9bb961847.png\n/kaggle/input/aptos2019/train_images/train_images/a654b25124c3.png\n/kaggle/input/aptos2019/train_images/train_images/1f4bf8e28b41.png\n/kaggle/input/aptos2019/train_images/train_images/ae20112e7a1e.png\n/kaggle/input/aptos2019/train_images/train_images/78937523f7a8.png\n/kaggle/input/aptos2019/train_images/train_images/5e18af29d812.png\n/kaggle/input/aptos2019/train_images/train_images/be21d8b60e2a.png\n/kaggle/input/aptos2019/train_images/train_images/ace287a5c991.png\n/kaggle/input/aptos2019/train_images/train_images/c57c164bca05.png\n/kaggle/input/aptos2019/train_images/train_images/2cdcc910778d.png\n/kaggle/input/aptos2019/train_images/train_images/d6228d951958.png\n/kaggle/input/aptos2019/train_images/train_images/41960d5f58c2.png\n/kaggle/input/aptos2019/train_images/train_images/b598bc9753c2.png\n/kaggle/input/aptos2019/train_images/train_images/a7c10ca6c117.png\n/kaggle/input/aptos2019/train_images/train_images/51af8c112682.png\n/kaggle/input/aptos2019/train_images/train_images/3b185ac445d0.png\n/kaggle/input/aptos2019/train_images/train_images/8a234d68b27e.png\n/kaggle/input/aptos2019/train_images/train_images/cf6551521a35.png\n/kaggle/input/aptos2019/train_images/train_images/cfdbaef73a8b.png\n/kaggle/input/aptos2019/train_images/train_images/5e52c9fe676f.png\n/kaggle/input/aptos2019/train_images/train_images/331b87d1b9d1.png\n/kaggle/input/aptos2019/train_images/train_images/4ccee4db09b6.png\n/kaggle/input/aptos2019/train_images/train_images/ac720570dd0f.png\n/kaggle/input/aptos2019/train_images/train_images/28503940d10b.png\n/kaggle/input/aptos2019/train_images/train_images/254052cf3e48.png\n/kaggle/input/aptos2019/train_images/train_images/698d6e422a80.png\n/kaggle/input/aptos2019/train_images/train_images/be7bc89f5fec.png\n/kaggle/input/aptos2019/train_images/train_images/8eeac97f02f0.png\n/kaggle/input/aptos2019/train_images/train_images/6cffc6c6851a.png\n/kaggle/input/aptos2019/train_images/train_images/6f0e5848d9ce.png\n/kaggle/input/aptos2019/train_images/train_images/540e4973829e.png\n/kaggle/input/aptos2019/train_images/train_images/8a482c024fc2.png\n/kaggle/input/aptos2019/train_images/train_images/d9a475dfe59a.png\n/kaggle/input/aptos2019/train_images/train_images/596f4fdb0004.png\n/kaggle/input/aptos2019/train_images/train_images/4393c5bc576a.png\n/kaggle/input/aptos2019/train_images/train_images/d9bbdc33db83.png\n/kaggle/input/aptos2019/train_images/train_images/1b398c0494d1.png\n/kaggle/input/aptos2019/train_images/train_images/6dc07f968794.png\n/kaggle/input/aptos2019/train_images/train_images/5b1c4cefeb24.png\n/kaggle/input/aptos2019/train_images/train_images/3cd801ffdbf0.png\n/kaggle/input/aptos2019/train_images/train_images/6cb98da77e3e.png\n/kaggle/input/aptos2019/train_images/train_images/2a4520f1f9a3.png\n/kaggle/input/aptos2019/train_images/train_images/7b8c78b41c0d.png\n/kaggle/input/aptos2019/train_images/train_images/b576c5269ad1.png\n/kaggle/input/aptos2019/train_images/train_images/a0b7ad98df57.png\n/kaggle/input/aptos2019/train_images/train_images/27f82ada84ac.png\n/kaggle/input/aptos2019/train_images/train_images/2d3f4094c08a.png\n/kaggle/input/aptos2019/train_images/train_images/e019b3e0f33d.png\n/kaggle/input/aptos2019/train_images/train_images/896ad584a841.png\n/kaggle/input/aptos2019/train_images/train_images/a28bfb772f50.png\n/kaggle/input/aptos2019/train_images/train_images/c3789c1dab96.png\n/kaggle/input/aptos2019/train_images/train_images/a3bd2e034614.png\n/kaggle/input/aptos2019/train_images/train_images/d81b6ed83bc2.png\n/kaggle/input/aptos2019/train_images/train_images/799cb4c816ae.png\n/kaggle/input/aptos2019/train_images/train_images/9de9421f17e3.png\n/kaggle/input/aptos2019/train_images/train_images/4abca30b676b.png\n/kaggle/input/aptos2019/train_images/train_images/721214151233.png\n/kaggle/input/aptos2019/train_images/train_images/6fb656d506b2.png\n/kaggle/input/aptos2019/train_images/train_images/be161517d3ac.png\n/kaggle/input/aptos2019/train_images/train_images/bfb578c0e8d8.png\n/kaggle/input/aptos2019/train_images/train_images/4d21ce39c905.png\n/kaggle/input/aptos2019/train_images/train_images/388279491b5d.png\n/kaggle/input/aptos2019/train_images/train_images/1c7a013eeba7.png\n/kaggle/input/aptos2019/train_images/train_images/c8d2d32f7f29.png\n/kaggle/input/aptos2019/train_images/train_images/d85ea1220a03.png\n/kaggle/input/aptos2019/train_images/train_images/ac2c814949f9.png\n/kaggle/input/aptos2019/train_images/train_images/61bbe8db6f3a.png\n/kaggle/input/aptos2019/train_images/train_images/b8ac328009e0.png\n/kaggle/input/aptos2019/train_images/train_images/ae8424cdb029.png\n/kaggle/input/aptos2019/train_images/train_images/37c523296d42.png\n/kaggle/input/aptos2019/train_images/train_images/8e6df9eedcd8.png\n/kaggle/input/aptos2019/train_images/train_images/4818672273af.png\n/kaggle/input/aptos2019/train_images/train_images/4bd941611343.png\n/kaggle/input/aptos2019/train_images/train_images/af87d48ffe01.png\n/kaggle/input/aptos2019/train_images/train_images/22a6da005395.png\n/kaggle/input/aptos2019/train_images/train_images/6f4e0538d1e4.png\n/kaggle/input/aptos2019/train_images/train_images/96ea316ed0ab.png\n/kaggle/input/aptos2019/train_images/train_images/da0a83f074f3.png\n/kaggle/input/aptos2019/train_images/train_images/e2161692a0b4.png\n/kaggle/input/aptos2019/train_images/train_images/999ad827ed35.png\n/kaggle/input/aptos2019/train_images/train_images/4ef16a53d899.png\n/kaggle/input/aptos2019/train_images/train_images/1d74c4713e21.png\n/kaggle/input/aptos2019/train_images/train_images/c24bcf7a1bc4.png\n/kaggle/input/aptos2019/train_images/train_images/46cdc8b685bd.png\n/kaggle/input/aptos2019/train_images/train_images/82f2784ead76.png\n/kaggle/input/aptos2019/train_images/train_images/c94f37085d0f.png\n/kaggle/input/aptos2019/train_images/train_images/9519a590985d.png\n/kaggle/input/aptos2019/train_images/train_images/521d3e264d71.png\n/kaggle/input/aptos2019/train_images/train_images/dd02d60bef14.png\n/kaggle/input/aptos2019/train_images/train_images/bcc762618e7d.png\n/kaggle/input/aptos2019/train_images/train_images/4c5ab774a381.png\n/kaggle/input/aptos2019/train_images/train_images/4ed31cc07366.png\n/kaggle/input/aptos2019/train_images/train_images/a21b37719f9b.png\n/kaggle/input/aptos2019/train_images/train_images/75369248dba0.png\n/kaggle/input/aptos2019/train_images/train_images/3abac0961bfd.png\n/kaggle/input/aptos2019/train_images/train_images/1fd5d860d4d7.png\n/kaggle/input/aptos2019/train_images/train_images/b960142a8de7.png\n/kaggle/input/aptos2019/train_images/train_images/2fdffb6160a6.png\n/kaggle/input/aptos2019/train_images/train_images/b82d5f1f1145.png\n/kaggle/input/aptos2019/train_images/train_images/7427dedafccf.png\n/kaggle/input/aptos2019/train_images/train_images/9b32e8ef0ca0.png\n/kaggle/input/aptos2019/train_images/train_images/69c4cbb630de.png\n/kaggle/input/aptos2019/train_images/train_images/3ce2f8a77a32.png\n/kaggle/input/aptos2019/train_images/train_images/d2c6b99ef62c.png\n/kaggle/input/aptos2019/train_images/train_images/d7bc00091cfc.png\n/kaggle/input/aptos2019/train_images/train_images/e12d41e7b221.png\n/kaggle/input/aptos2019/train_images/train_images/e3cd96cb094c.png\n/kaggle/input/aptos2019/train_images/train_images/389552047476.png\n/kaggle/input/aptos2019/train_images/train_images/5a091e8cd95c.png\n/kaggle/input/aptos2019/train_images/train_images/27e4c800a449.png\n/kaggle/input/aptos2019/train_images/train_images/cd45bfa07d41.png\n/kaggle/input/aptos2019/train_images/train_images/878e356c8fc9.png\n/kaggle/input/aptos2019/train_images/train_images/5b47043942f4.png\n/kaggle/input/aptos2019/train_images/train_images/895fe2bfc5b6.png\n/kaggle/input/aptos2019/train_images/train_images/663a923d5398.png\n/kaggle/input/aptos2019/train_images/train_images/875a2fc5fe23.png\n/kaggle/input/aptos2019/train_images/train_images/3fd45879afe6.png\n/kaggle/input/aptos2019/train_images/train_images/3810040096cb.png\n/kaggle/input/aptos2019/train_images/train_images/d035c2bd9104.png\n/kaggle/input/aptos2019/train_images/train_images/b0eeae01b8ab.png\n/kaggle/input/aptos2019/train_images/train_images/d7ab5c040294.png\n/kaggle/input/aptos2019/train_images/train_images/d868acdccb5b.png\n/kaggle/input/aptos2019/train_images/train_images/969f92a390db.png\n/kaggle/input/aptos2019/train_images/train_images/8f318a978844.png\n/kaggle/input/aptos2019/train_images/train_images/6377e23928f6.png\n/kaggle/input/aptos2019/train_images/train_images/8acffaf1f4b9.png\n/kaggle/input/aptos2019/train_images/train_images/d88806d9ece9.png\n/kaggle/input/aptos2019/train_images/train_images/362c4a96cebb.png\n/kaggle/input/aptos2019/train_images/train_images/aa9b8f05f4bf.png\n/kaggle/input/aptos2019/train_images/train_images/8ead8f37423c.png\n/kaggle/input/aptos2019/train_images/train_images/98104c8c67eb.png\n/kaggle/input/aptos2019/train_images/train_images/467b7d9d811c.png\n/kaggle/input/aptos2019/train_images/train_images/c446985355f1.png\n/kaggle/input/aptos2019/train_images/train_images/7af4d8704032.png\n/kaggle/input/aptos2019/train_images/train_images/d27ac9e54901.png\n/kaggle/input/aptos2019/train_images/train_images/a3957df90a78.png\n/kaggle/input/aptos2019/train_images/train_images/62ab144d5cee.png\n/kaggle/input/aptos2019/train_images/train_images/a8854768549f.png\n/kaggle/input/aptos2019/train_images/train_images/1b3647865779.png\n/kaggle/input/aptos2019/train_images/train_images/269b44e628eb.png\n/kaggle/input/aptos2019/train_images/train_images/7ae69d22075a.png\n/kaggle/input/aptos2019/train_images/train_images/bac1744955c2.png\n/kaggle/input/aptos2019/train_images/train_images/a32b5ce3d48a.png\n/kaggle/input/aptos2019/train_images/train_images/a2163f0c2af5.png\n/kaggle/input/aptos2019/train_images/train_images/e067b06fd655.png\n/kaggle/input/aptos2019/train_images/train_images/41345cec5957.png\n/kaggle/input/aptos2019/train_images/train_images/8f14bca04b47.png\n/kaggle/input/aptos2019/train_images/train_images/3b58b02c89ed.png\n/kaggle/input/aptos2019/train_images/train_images/26e231747848.png\n/kaggle/input/aptos2019/train_images/train_images/b21abe5d9722.png\n/kaggle/input/aptos2019/train_images/train_images/71a39c660432.png\n/kaggle/input/aptos2019/train_images/train_images/8dafa62f9322.png\n/kaggle/input/aptos2019/train_images/train_images/8596a24a14bd.png\n/kaggle/input/aptos2019/train_images/train_images/9e5ec293267c.png\n/kaggle/input/aptos2019/train_images/train_images/54334705a34d.png\n/kaggle/input/aptos2019/train_images/train_images/991a0b7a8c87.png\n/kaggle/input/aptos2019/train_images/train_images/8ff2733f6aef.png\n/kaggle/input/aptos2019/train_images/train_images/8185ce1cdcef.png\n/kaggle/input/aptos2019/train_images/train_images/b4e15102cd7a.png\n/kaggle/input/aptos2019/train_images/train_images/7b691d9ced34.png\n/kaggle/input/aptos2019/train_images/train_images/3c726de3ee90.png\n/kaggle/input/aptos2019/train_images/train_images/3323fd59782e.png\n/kaggle/input/aptos2019/train_images/train_images/da6389d129aa.png\n/kaggle/input/aptos2019/train_images/train_images/badb5ff8d3c7.png\n/kaggle/input/aptos2019/train_images/train_images/cd54d022e37d.png\n/kaggle/input/aptos2019/train_images/train_images/a5c9a8c726b2.png\n/kaggle/input/aptos2019/train_images/train_images/582f739b8f62.png\n/kaggle/input/aptos2019/train_images/train_images/2d9d97a6e713.png\n/kaggle/input/aptos2019/train_images/train_images/a15590a7d774.png\n/kaggle/input/aptos2019/train_images/train_images/d1b279cc02ae.png\n/kaggle/input/aptos2019/train_images/train_images/33b91def2035.png\n/kaggle/input/aptos2019/train_images/train_images/61da799bf0aa.png\n/kaggle/input/aptos2019/train_images/train_images/731b19a460ad.png\n/kaggle/input/aptos2019/train_images/train_images/e1dc02a3dc2a.png\n/kaggle/input/aptos2019/train_images/train_images/a8582e346df0.png\n/kaggle/input/aptos2019/train_images/train_images/37c4dfe03aba.png\n/kaggle/input/aptos2019/train_images/train_images/9cf7c1349673.png\n/kaggle/input/aptos2019/train_images/train_images/29b52f64d2db.png\n/kaggle/input/aptos2019/train_images/train_images/789f0ec1eab8.png\n/kaggle/input/aptos2019/train_images/train_images/aed4e743c230.png\n/kaggle/input/aptos2019/train_images/train_images/31452ad8808c.png\n/kaggle/input/aptos2019/train_images/train_images/b842b43cb7fb.png\n/kaggle/input/aptos2019/train_images/train_images/28dc010a0780.png\n/kaggle/input/aptos2019/train_images/train_images/c58e5c0c5b33.png\n/kaggle/input/aptos2019/train_images/train_images/a4d41c495666.png\n/kaggle/input/aptos2019/train_images/train_images/22d843b2bbd1.png\n/kaggle/input/aptos2019/train_images/train_images/c7d0deb71576.png\n/kaggle/input/aptos2019/train_images/train_images/44ecf3f4efa5.png\n/kaggle/input/aptos2019/train_images/train_images/28824d12d31d.png\n/kaggle/input/aptos2019/train_images/train_images/4731e708ede3.png\n/kaggle/input/aptos2019/train_images/train_images/20688cb25704.png\n/kaggle/input/aptos2019/train_images/train_images/e16af45285e5.png\n/kaggle/input/aptos2019/train_images/train_images/7f43becd3e83.png\n/kaggle/input/aptos2019/train_images/train_images/d364423ec6f9.png\n/kaggle/input/aptos2019/train_images/train_images/bf87aedf2489.png\n/kaggle/input/aptos2019/train_images/train_images/64fedbf97473.png\n/kaggle/input/aptos2019/train_images/train_images/29192375ab1b.png\n/kaggle/input/aptos2019/train_images/train_images/e4b0df29b96f.png\n/kaggle/input/aptos2019/train_images/train_images/8acdf12f412a.png\n/kaggle/input/aptos2019/train_images/train_images/9cc6b1f9bcbd.png\n/kaggle/input/aptos2019/train_images/train_images/65cf00be6fb4.png\n/kaggle/input/aptos2019/train_images/train_images/51da6aebba8f.png\n/kaggle/input/aptos2019/train_images/train_images/ad20080452de.png\n/kaggle/input/aptos2019/train_images/train_images/ae2c3f6312ef.png\n/kaggle/input/aptos2019/train_images/train_images/2209daf71aab.png\n/kaggle/input/aptos2019/train_images/train_images/55f7f018c61c.png\n/kaggle/input/aptos2019/train_images/train_images/20404ec7b518.png\n/kaggle/input/aptos2019/train_images/train_images/2376e5415458.png\n/kaggle/input/aptos2019/train_images/train_images/9910c827e2fe.png\n/kaggle/input/aptos2019/train_images/train_images/30263a7d5609.png\n/kaggle/input/aptos2019/train_images/train_images/8201cab8322d.png\n/kaggle/input/aptos2019/train_images/train_images/242fc19be06f.png\n/kaggle/input/aptos2019/train_images/train_images/8c0d05233238.png\n/kaggle/input/aptos2019/train_images/train_images/3748349334f6.png\n/kaggle/input/aptos2019/train_images/train_images/e1fb532f55df.png\n/kaggle/input/aptos2019/train_images/train_images/2532613a584a.png\n/kaggle/input/aptos2019/train_images/train_images/756b0d6488bb.png\n/kaggle/input/aptos2019/train_images/train_images/d9ba044671e1.png\n/kaggle/input/aptos2019/train_images/train_images/6ccfdb031184.png\n/kaggle/input/aptos2019/train_images/train_images/1e4b3b823b95.png\n/kaggle/input/aptos2019/train_images/train_images/8906c9ed54a2.png\n/kaggle/input/aptos2019/train_images/train_images/52886bed8a07.png\n/kaggle/input/aptos2019/train_images/train_images/df841a0440d8.png\n/kaggle/input/aptos2019/train_images/train_images/1d37f1c8b6d8.png\n/kaggle/input/aptos2019/train_images/train_images/5c85d22bd0de.png\n/kaggle/input/aptos2019/train_images/train_images/79ade634c633.png\n/kaggle/input/aptos2019/train_images/train_images/894a37fc3738.png\n/kaggle/input/aptos2019/train_images/train_images/50d8249f7bc9.png\n/kaggle/input/aptos2019/train_images/train_images/1efa5d443707.png\n/kaggle/input/aptos2019/train_images/train_images/c9f0dc2c8b43.png\n/kaggle/input/aptos2019/train_images/train_images/78bcdffb8785.png\n/kaggle/input/aptos2019/train_images/train_images/a1eb88562239.png\n/kaggle/input/aptos2019/train_images/train_images/e1418d28d668.png\n/kaggle/input/aptos2019/train_images/train_images/8846b09384a4.png\n/kaggle/input/aptos2019/train_images/train_images/2ef4a04aed1b.png\n/kaggle/input/aptos2019/train_images/train_images/9be0683649ff.png\n/kaggle/input/aptos2019/train_images/train_images/72606afaf3da.png\n/kaggle/input/aptos2019/train_images/train_images/4134b290f5f3.png\n/kaggle/input/aptos2019/train_images/train_images/c73c5f6ef664.png\n/kaggle/input/aptos2019/train_images/train_images/8e4a354e3da2.png\n/kaggle/input/aptos2019/train_images/train_images/750e0168399d.png\n/kaggle/input/aptos2019/train_images/train_images/4d47300e3ddb.png\n/kaggle/input/aptos2019/train_images/train_images/44878f34e31f.png\n/kaggle/input/aptos2019/train_images/train_images/b37aae3c8fe1.png\n/kaggle/input/aptos2019/train_images/train_images/a81b06f50612.png\n/kaggle/input/aptos2019/train_images/train_images/36a1e3c780a0.png\n/kaggle/input/aptos2019/train_images/train_images/27933cdbe0cc.png\n/kaggle/input/aptos2019/train_images/train_images/bffca6eeb2bf.png\n/kaggle/input/aptos2019/train_images/train_images/b09101adb478.png\n/kaggle/input/aptos2019/train_images/train_images/9122b31414d3.png\n/kaggle/input/aptos2019/train_images/train_images/dd285d9e97fe.png\n/kaggle/input/aptos2019/train_images/train_images/92fcf50b3562.png\n/kaggle/input/aptos2019/train_images/train_images/9f935fb38440.png\n/kaggle/input/aptos2019/train_images/train_images/97d02a9b94f7.png\n/kaggle/input/aptos2019/train_images/train_images/e135d7ba9a0e.png\n/kaggle/input/aptos2019/train_images/train_images/c3e02d4a1798.png\n/kaggle/input/aptos2019/train_images/train_images/735836b1ffa6.png\n/kaggle/input/aptos2019/train_images/train_images/52ae917fcea4.png\n/kaggle/input/aptos2019/train_images/train_images/86722fcd802c.png\n/kaggle/input/aptos2019/train_images/train_images/3796af4d987a.png\n/kaggle/input/aptos2019/train_images/train_images/1f543a86c4d4.png\n/kaggle/input/aptos2019/train_images/train_images/db3cd58aa315.png\n/kaggle/input/aptos2019/train_images/train_images/20f86e068276.png\n/kaggle/input/aptos2019/train_images/train_images/282bc792d23a.png\n/kaggle/input/aptos2019/train_images/train_images/dbfd238b3468.png\n/kaggle/input/aptos2019/train_images/train_images/3cdda8b3df19.png\n/kaggle/input/aptos2019/train_images/train_images/52ddde91a349.png\n/kaggle/input/aptos2019/train_images/train_images/de778495a1cd.png\n/kaggle/input/aptos2019/train_images/train_images/25b0e72705a8.png\n/kaggle/input/aptos2019/train_images/train_images/a673193cd5a9.png\n/kaggle/input/aptos2019/train_images/train_images/6b00cb764237.png\n/kaggle/input/aptos2019/train_images/train_images/369229040a34.png\n/kaggle/input/aptos2019/train_images/train_images/77a9538b8362.png\n/kaggle/input/aptos2019/train_images/train_images/2fe06bedb2c4.png\n/kaggle/input/aptos2019/train_images/train_images/2b5bb6d33959.png\n/kaggle/input/aptos2019/train_images/train_images/2b88cb6e31cd.png\n/kaggle/input/aptos2019/train_images/train_images/76516f828d88.png\n/kaggle/input/aptos2019/train_images/train_images/27e2be850a99.png\n/kaggle/input/aptos2019/train_images/train_images/272d9c043c81.png\n/kaggle/input/aptos2019/train_images/train_images/82deb07a6618.png\n/kaggle/input/aptos2019/train_images/train_images/1c0e5dd1b14c.png\n/kaggle/input/aptos2019/train_images/train_images/a08a0133754a.png\n/kaggle/input/aptos2019/train_images/train_images/5879285f9d8d.png\n/kaggle/input/aptos2019/train_images/train_images/bec0acd539b2.png\n/kaggle/input/aptos2019/train_images/train_images/59e5212f7139.png\n/kaggle/input/aptos2019/train_images/train_images/6c3589d7ed8d.png\n/kaggle/input/aptos2019/train_images/train_images/830e297965a1.png\n/kaggle/input/aptos2019/train_images/train_images/b56340f472d2.png\n/kaggle/input/aptos2019/train_images/train_images/7d37a2939f12.png\n/kaggle/input/aptos2019/train_images/train_images/876e1dd12d38.png\n/kaggle/input/aptos2019/train_images/train_images/ccd34029493d.png\n/kaggle/input/aptos2019/train_images/train_images/48c49f662f7d.png\n/kaggle/input/aptos2019/train_images/train_images/2df07eb5779f.png\n/kaggle/input/aptos2019/train_images/train_images/98d41bce73a8.png\n/kaggle/input/aptos2019/train_images/train_images/cd1c98ec48b1.png\n/kaggle/input/aptos2019/train_images/train_images/81371b0c01ad.png\n/kaggle/input/aptos2019/train_images/train_images/7828dd083cdc.png\n/kaggle/input/aptos2019/train_images/train_images/983c98354e9c.png\n/kaggle/input/aptos2019/train_images/train_images/c0e15e8e2b46.png\n/kaggle/input/aptos2019/train_images/train_images/c6916bc42016.png\n/kaggle/input/aptos2019/train_images/train_images/3f82631e9080.png\n/kaggle/input/aptos2019/train_images/train_images/cf8ae5501bd6.png\n/kaggle/input/aptos2019/train_images/train_images/77baa08a1345.png\n/kaggle/input/aptos2019/train_images/train_images/6987804eb464.png\n/kaggle/input/aptos2019/train_images/train_images/9bafbbd152d2.png\n/kaggle/input/aptos2019/train_images/train_images/cc671a73e1cb.png\n/kaggle/input/aptos2019/train_images/train_images/a85cda5f725d.png\n/kaggle/input/aptos2019/train_images/train_images/726dff37edc0.png\n/kaggle/input/aptos2019/train_images/train_images/dad71ba27a9b.png\n/kaggle/input/aptos2019/train_images/train_images/4d3de40ced3a.png\n/kaggle/input/aptos2019/train_images/train_images/c0202976c670.png\n/kaggle/input/aptos2019/train_images/train_images/beb2ad14fd2d.png\n/kaggle/input/aptos2019/train_images/train_images/882a71de424e.png\n/kaggle/input/aptos2019/train_images/train_images/cbc2e57447c2.png\n/kaggle/input/aptos2019/train_images/train_images/93d6d20a5ee3.png\n/kaggle/input/aptos2019/train_images/train_images/408ea9d5e082.png\n/kaggle/input/aptos2019/train_images/train_images/531b39880c32.png\n/kaggle/input/aptos2019/train_images/train_images/b7bd4a6627b6.png\n/kaggle/input/aptos2019/train_images/train_images/e33766353db2.png\n/kaggle/input/aptos2019/train_images/train_images/abf09c44d5f4.png\n/kaggle/input/aptos2019/train_images/train_images/5bf6f2958e53.png\n/kaggle/input/aptos2019/train_images/train_images/2923971566fe.png\n/kaggle/input/aptos2019/train_images/train_images/4e7694eebb91.png\n/kaggle/input/aptos2019/train_images/train_images/d7ac4a0c9760.png\n/kaggle/input/aptos2019/train_images/train_images/ca63fe4f4b52.png\n/kaggle/input/aptos2019/train_images/train_images/9274e75dc4d5.png\n/kaggle/input/aptos2019/train_images/train_images/1c0cf251b426.png\n/kaggle/input/aptos2019/train_images/train_images/b72f59b85f7c.png\n/kaggle/input/aptos2019/train_images/train_images/dcf109df1a2b.png\n/kaggle/input/aptos2019/train_images/train_images/ca6842bfcbc9.png\n/kaggle/input/aptos2019/train_images/train_images/6253f23229b1.png\n/kaggle/input/aptos2019/train_images/train_images/96c699221180.png\n/kaggle/input/aptos2019/train_images/train_images/ca7f5caddf96.png\n/kaggle/input/aptos2019/train_images/train_images/c6d4e4a3bd4c.png\n/kaggle/input/aptos2019/train_images/train_images/26463a5fb949.png\n/kaggle/input/aptos2019/train_images/train_images/5b2648ad455e.png\n/kaggle/input/aptos2019/train_images/train_images/5814cbd2e9bf.png\n/kaggle/input/aptos2019/train_images/train_images/89d9c071a56f.png\n/kaggle/input/aptos2019/train_images/train_images/c0a0828e01b4.png\n/kaggle/input/aptos2019/train_images/train_images/36041171f441.png\n/kaggle/input/aptos2019/train_images/train_images/6ba5ed791444.png\n/kaggle/input/aptos2019/train_images/train_images/8e63fc4ab532.png\n/kaggle/input/aptos2019/train_images/train_images/c2a58b2cfd0b.png\n/kaggle/input/aptos2019/train_images/train_images/691eeb59b4cb.png\n/kaggle/input/aptos2019/train_images/train_images/8660e1864665.png\n/kaggle/input/aptos2019/train_images/train_images/973b0facfa9b.png\n/kaggle/input/aptos2019/train_images/train_images/b5204c0decc7.png\n/kaggle/input/aptos2019/train_images/train_images/7b49041cbf17.png\n/kaggle/input/aptos2019/train_images/train_images/63c3c571b8ee.png\n/kaggle/input/aptos2019/train_images/train_images/e32a359be36d.png\n/kaggle/input/aptos2019/train_images/train_images/aeed1f251ceb.png\n/kaggle/input/aptos2019/train_images/train_images/65f5d2a6eb7e.png\n/kaggle/input/aptos2019/train_images/train_images/2017cd92c63d.png\n/kaggle/input/aptos2019/train_images/train_images/a879c3569552.png\n/kaggle/input/aptos2019/train_images/train_images/5cab3ef4b31c.png\n/kaggle/input/aptos2019/train_images/train_images/a2b995b81692.png\n/kaggle/input/aptos2019/train_images/train_images/7e6e90a93aa5.png\n/kaggle/input/aptos2019/train_images/train_images/8241e43408a8.png\n/kaggle/input/aptos2019/train_images/train_images/a2811f512c1c.png\n/kaggle/input/aptos2019/train_images/train_images/598b8f5b3822.png\n/kaggle/input/aptos2019/train_images/train_images/3c78bfca247b.png\n/kaggle/input/aptos2019/train_images/train_images/44e951e45dca.png\n/kaggle/input/aptos2019/train_images/train_images/3fa4f4d77177.png\n/kaggle/input/aptos2019/train_images/train_images/3254e48c8aa0.png\n/kaggle/input/aptos2019/train_images/train_images/82bb8a01935f.png\n/kaggle/input/aptos2019/train_images/train_images/c12e9ca420a5.png\n/kaggle/input/aptos2019/train_images/train_images/b10fca20c885.png\n/kaggle/input/aptos2019/train_images/train_images/d4f32b9c07df.png\n/kaggle/input/aptos2019/train_images/train_images/905cc86bf100.png\n/kaggle/input/aptos2019/train_images/train_images/7e0598cc88a0.png\n/kaggle/input/aptos2019/train_images/train_images/58ccba7eec9c.png\n/kaggle/input/aptos2019/train_images/train_images/cb28adab4e8a.png\n/kaggle/input/aptos2019/train_images/train_images/75238d945315.png\n/kaggle/input/aptos2019/train_images/train_images/c096131ad065.png\n/kaggle/input/aptos2019/train_images/train_images/4dd71fc7f22b.png\n/kaggle/input/aptos2019/train_images/train_images/56e56aa08362.png\n/kaggle/input/aptos2019/train_images/train_images/519c6e8f78dc.png\n/kaggle/input/aptos2019/train_images/train_images/ab653b8554c0.png\n/kaggle/input/aptos2019/train_images/train_images/68ddb15a74de.png\n/kaggle/input/aptos2019/train_images/train_images/5671eb95512b.png\n/kaggle/input/aptos2019/train_images/train_images/bfe467b7e997.png\n/kaggle/input/aptos2019/train_images/train_images/7eeb191ad06b.png\n/kaggle/input/aptos2019/train_images/train_images/9a1029536d78.png\n/kaggle/input/aptos2019/train_images/train_images/8f06ca4642bd.png\n/kaggle/input/aptos2019/train_images/train_images/64a13949e879.png\n/kaggle/input/aptos2019/train_images/train_images/a11bf2edd470.png\n/kaggle/input/aptos2019/train_images/train_images/ae2e888905ba.png\n/kaggle/input/aptos2019/train_images/train_images/a6356a3c5d11.png\n/kaggle/input/aptos2019/train_images/train_images/365f8c01d994.png\n/kaggle/input/aptos2019/train_images/train_images/c1819db0aece.png\n/kaggle/input/aptos2019/train_images/train_images/2db0cd3e30da.png\n/kaggle/input/aptos2019/train_images/train_images/5bda2ed09e62.png\n/kaggle/input/aptos2019/train_images/train_images/201f6e10c108.png\n/kaggle/input/aptos2019/train_images/train_images/e01b7bac822b.png\n/kaggle/input/aptos2019/train_images/train_images/80b5a9519aec.png\n/kaggle/input/aptos2019/train_images/train_images/72a867980067.png\n/kaggle/input/aptos2019/train_images/train_images/79540be95177.png\n/kaggle/input/aptos2019/train_images/train_images/68332fdcaa70.png\n/kaggle/input/aptos2019/train_images/train_images/44f7f3ef9d50.png\n/kaggle/input/aptos2019/train_images/train_images/1ec95179cdfe.png\n/kaggle/input/aptos2019/train_images/train_images/7f60f2a083d3.png\n/kaggle/input/aptos2019/train_images/train_images/9e7a63b2fc6a.png\n/kaggle/input/aptos2019/train_images/train_images/b746a6681ba9.png\n/kaggle/input/aptos2019/train_images/train_images/81bc03e2ff2b.png\n/kaggle/input/aptos2019/train_images/train_images/39aa3cd93c50.png\n/kaggle/input/aptos2019/train_images/train_images/dd19428c3d29.png\n/kaggle/input/aptos2019/train_images/train_images/c96f743915b5.png\n/kaggle/input/aptos2019/train_images/train_images/c9485c38fdd5.png\n/kaggle/input/aptos2019/train_images/train_images/310c27067ac0.png\n/kaggle/input/aptos2019/train_images/train_images/cb02bb47fdc5.png\n/kaggle/input/aptos2019/train_images/train_images/5548a7961a3e.png\n/kaggle/input/aptos2019/train_images/train_images/495106ae3b68.png\n/kaggle/input/aptos2019/train_images/train_images/ba2ea9182090.png\n/kaggle/input/aptos2019/train_images/train_images/291f581d365e.png\n/kaggle/input/aptos2019/train_images/train_images/a3475dc3ac80.png\n/kaggle/input/aptos2019/train_images/train_images/6fe67482bfae.png\n/kaggle/input/aptos2019/train_images/train_images/286e9981dd9b.png\n/kaggle/input/aptos2019/train_images/train_images/7a39c91416e2.png\n/kaggle/input/aptos2019/train_images/train_images/6c30dd481717.png\n/kaggle/input/aptos2019/train_images/train_images/a56230242a95.png\n/kaggle/input/aptos2019/train_images/train_images/d85d052900b4.png\n/kaggle/input/aptos2019/train_images/train_images/5a444c32cd9a.png\n/kaggle/input/aptos2019/train_images/train_images/47536db39f00.png\n/kaggle/input/aptos2019/train_images/train_images/51e656e5a541.png\n/kaggle/input/aptos2019/train_images/train_images/609be3ca5ddf.png\n/kaggle/input/aptos2019/train_images/train_images/b835b6e31a59.png\n/kaggle/input/aptos2019/train_images/train_images/aa31bc6b8f4d.png\n/kaggle/input/aptos2019/train_images/train_images/1db18bdd43aa.png\n/kaggle/input/aptos2019/train_images/train_images/c5431b81cbc9.png\n/kaggle/input/aptos2019/train_images/train_images/d5a39339ff3d.png\n/kaggle/input/aptos2019/train_images/train_images/ddb222ff7c1d.png\n/kaggle/input/aptos2019/train_images/train_images/be8697eb2078.png\n/kaggle/input/aptos2019/train_images/train_images/ba25f947f4ec.png\n/kaggle/input/aptos2019/train_images/train_images/7347f5133a6a.png\n/kaggle/input/aptos2019/train_images/train_images/dc3c0d8ee20b.png\n/kaggle/input/aptos2019/train_images/train_images/b351ae99413a.png\n/kaggle/input/aptos2019/train_images/train_images/33596a635b53.png\n/kaggle/input/aptos2019/train_images/train_images/3b232b394e4f.png\n/kaggle/input/aptos2019/train_images/train_images/992599744a23.png\n/kaggle/input/aptos2019/train_images/train_images/423abbaa5fad.png\n/kaggle/input/aptos2019/train_images/train_images/9d62478042b6.png\n/kaggle/input/aptos2019/train_images/train_images/3325b1fe55d2.png\n/kaggle/input/aptos2019/train_images/train_images/4dd9d29eae5d.png\n/kaggle/input/aptos2019/train_images/train_images/7247a2c97f71.png\n/kaggle/input/aptos2019/train_images/train_images/d41b33fcb94f.png\n/kaggle/input/aptos2019/train_images/train_images/cd01672507c9.png\n/kaggle/input/aptos2019/train_images/train_images/8dfa629ca74e.png\n/kaggle/input/aptos2019/train_images/train_images/d9311f7497cb.png\n/kaggle/input/aptos2019/train_images/train_images/8bed09514c3b.png\n/kaggle/input/aptos2019/train_images/train_images/7efc91af4ae6.png\n/kaggle/input/aptos2019/train_images/train_images/9287e57326d0.png\n/kaggle/input/aptos2019/train_images/train_images/d1fa0f744620.png\n/kaggle/input/aptos2019/train_images/train_images/ca1036496659.png\n/kaggle/input/aptos2019/train_images/train_images/971bb98ab935.png\n/kaggle/input/aptos2019/train_images/train_images/b7a1bb106051.png\n/kaggle/input/aptos2019/train_images/train_images/d1ca85af57c9.png\n/kaggle/input/aptos2019/train_images/train_images/3f5b4c2948e8.png\n/kaggle/input/aptos2019/train_images/train_images/821789e9053f.png\n/kaggle/input/aptos2019/train_images/train_images/4403538fb50f.png\n/kaggle/input/aptos2019/train_images/train_images/da949aa67a4f.png\n/kaggle/input/aptos2019/train_images/train_images/25a0a1e41afd.png\n/kaggle/input/aptos2019/train_images/train_images/b8ebedd382de.png\n/kaggle/input/aptos2019/train_images/train_images/8bdb891661a8.png\n/kaggle/input/aptos2019/train_images/train_images/587146a55885.png\n/kaggle/input/aptos2019/train_images/train_images/1c9c583c10bf.png\n/kaggle/input/aptos2019/train_images/train_images/86d6808f0609.png\n/kaggle/input/aptos2019/train_images/train_images/64eb5a79dfdd.png\n/kaggle/input/aptos2019/train_images/train_images/493d99f030e2.png\n/kaggle/input/aptos2019/train_images/train_images/4cf4d528c08e.png\n/kaggle/input/aptos2019/train_images/train_images/4c570172778b.png\n/kaggle/input/aptos2019/train_images/train_images/c5ba9e455d5e.png\n/kaggle/input/aptos2019/train_images/train_images/9a3109657ac1.png\n/kaggle/input/aptos2019/train_images/train_images/33b978734eab.png\n/kaggle/input/aptos2019/train_images/train_images/a77eb914b383.png\n/kaggle/input/aptos2019/train_images/train_images/c739ff9580d3.png\n/kaggle/input/aptos2019/train_images/train_images/3435fd8675a2.png\n/kaggle/input/aptos2019/train_images/train_images/ab686895533e.png\n/kaggle/input/aptos2019/train_images/train_images/ae8472f8d310.png\n/kaggle/input/aptos2019/train_images/train_images/224bb938e2dd.png\n/kaggle/input/aptos2019/train_images/train_images/475300735b7f.png\n/kaggle/input/aptos2019/train_images/train_images/c0f15fe3b4b7.png\n/kaggle/input/aptos2019/train_images/train_images/a66c3165876f.png\n/kaggle/input/aptos2019/train_images/train_images/d93b61dc8f64.png\n/kaggle/input/aptos2019/train_images/train_images/d0079cc188e9.png\n/kaggle/input/aptos2019/train_images/train_images/73881f55a3ec.png\n/kaggle/input/aptos2019/train_images/train_images/e34fa07bd64d.png\n/kaggle/input/aptos2019/train_images/train_images/e4ae1ee6aada.png\n/kaggle/input/aptos2019/train_images/train_images/233d948e2544.png\n/kaggle/input/aptos2019/train_images/train_images/68987fb159ab.png\n/kaggle/input/aptos2019/train_images/train_images/3a643599f852.png\n/kaggle/input/aptos2019/train_images/train_images/d516f77d4516.png\n/kaggle/input/aptos2019/train_images/train_images/3286073a976e.png\n/kaggle/input/aptos2019/train_images/train_images/b96b518596b3.png\n/kaggle/input/aptos2019/train_images/train_images/4158c340fa49.png\n/kaggle/input/aptos2019/train_images/train_images/c52bb7343387.png\n/kaggle/input/aptos2019/train_images/train_images/cc12453ea915.png\n/kaggle/input/aptos2019/train_images/train_images/5b068765e846.png\n/kaggle/input/aptos2019/train_images/train_images/3fc219927a97.png\n/kaggle/input/aptos2019/train_images/train_images/7743f4e04a6d.png\n/kaggle/input/aptos2019/train_images/train_images/7d626a7ffe76.png\n/kaggle/input/aptos2019/train_images/train_images/419406328dcd.png\n/kaggle/input/aptos2019/train_images/train_images/80b5697f2a5e.png\n/kaggle/input/aptos2019/train_images/train_images/38055d8b9f08.png\n/kaggle/input/aptos2019/train_images/train_images/1d11794057ff.png\n/kaggle/input/aptos2019/train_images/train_images/2fde69f20585.png\n/kaggle/input/aptos2019/train_images/train_images/810d3779abd9.png\n/kaggle/input/aptos2019/train_images/train_images/bfefa7344e7d.png\n/kaggle/input/aptos2019/train_images/train_images/51cd8d2057fa.png\n/kaggle/input/aptos2019/train_images/train_images/b7278b4f2448.png\n/kaggle/input/aptos2019/train_images/train_images/d911dd40c63b.png\n/kaggle/input/aptos2019/train_images/train_images/aebe87a423c8.png\n/kaggle/input/aptos2019/train_images/train_images/2700754f71e9.png\n/kaggle/input/aptos2019/train_images/train_images/437900a99871.png\n/kaggle/input/aptos2019/train_images/train_images/6bb30ec3231a.png\n/kaggle/input/aptos2019/train_images/train_images/ab724603ee93.png\n/kaggle/input/aptos2019/train_images/train_images/50915e2329a1.png\n/kaggle/input/aptos2019/train_images/train_images/e16fc934069f.png\n/kaggle/input/aptos2019/train_images/train_images/d38cf0f4a9af.png\n/kaggle/input/aptos2019/train_images/train_images/a32886cb31ab.png\n/kaggle/input/aptos2019/train_images/train_images/4958bfcc9f38.png\n/kaggle/input/aptos2019/train_images/train_images/a015ce4f51ad.png\n/kaggle/input/aptos2019/train_images/train_images/d871895742b1.png\n/kaggle/input/aptos2019/train_images/train_images/8785b71238d8.png\n/kaggle/input/aptos2019/train_images/train_images/916915f01e17.png\n/kaggle/input/aptos2019/train_images/train_images/c365c598ad4e.png\n/kaggle/input/aptos2019/train_images/train_images/75a071608ea6.png\n/kaggle/input/aptos2019/train_images/train_images/5090917a2676.png\n/kaggle/input/aptos2019/train_images/train_images/b87f9c59748b.png\n/kaggle/input/aptos2019/train_images/train_images/a61723fc38c2.png\n/kaggle/input/aptos2019/train_images/train_images/837acf120946.png\n/kaggle/input/aptos2019/train_images/train_images/6bcce181be65.png\n/kaggle/input/aptos2019/train_images/train_images/7aabd768abff.png\n/kaggle/input/aptos2019/train_images/train_images/83038ca49b6d.png\n/kaggle/input/aptos2019/train_images/train_images/74eee788edee.png\n/kaggle/input/aptos2019/train_images/train_images/64678182d8a8.png\n/kaggle/input/aptos2019/train_images/train_images/82ac8463fadd.png\n/kaggle/input/aptos2019/train_images/train_images/7c2e852171c0.png\n/kaggle/input/aptos2019/train_images/train_images/27b68863349f.png\n/kaggle/input/aptos2019/train_images/train_images/992b9a07b25f.png\n/kaggle/input/aptos2019/train_images/train_images/2f8d14a7d390.png\n/kaggle/input/aptos2019/train_images/train_images/681c3c115684.png\n/kaggle/input/aptos2019/train_images/train_images/a9dc80cba9a4.png\n/kaggle/input/aptos2019/train_images/train_images/92d8a7c8e718.png\n/kaggle/input/aptos2019/train_images/train_images/613bacb35c05.png\n/kaggle/input/aptos2019/train_images/train_images/7cc4b7aabe04.png\n/kaggle/input/aptos2019/train_images/train_images/5b76117c4bcb.png\n/kaggle/input/aptos2019/train_images/train_images/af7a36454670.png\n/kaggle/input/aptos2019/train_images/train_images/57f5ad4b5b29.png\n/kaggle/input/aptos2019/train_images/train_images/26999ebc21de.png\n/kaggle/input/aptos2019/train_images/train_images/e265c870f9b3.png\n/kaggle/input/aptos2019/train_images/train_images/50d8a8fb7737.png\n/kaggle/input/aptos2019/train_images/train_images/2a3378bcfbcc.png\n/kaggle/input/aptos2019/train_images/train_images/c64c0966b4cf.png\n/kaggle/input/aptos2019/train_images/train_images/869bbd3170cc.png\n/kaggle/input/aptos2019/train_images/train_images/1fddd7c98fd2.png\n/kaggle/input/aptos2019/train_images/train_images/97c6cb55866d.png\n/kaggle/input/aptos2019/train_images/train_images/ceaa5803d780.png\n/kaggle/input/aptos2019/train_images/train_images/3f6c627e2ff2.png\n/kaggle/input/aptos2019/train_images/train_images/ba4e62c11cc0.png\n/kaggle/input/aptos2019/train_images/train_images/c7c0470bcf87.png\n/kaggle/input/aptos2019/train_images/train_images/9d98a0b585f2.png\n/kaggle/input/aptos2019/train_images/train_images/8714d17bb6da.png\n/kaggle/input/aptos2019/train_images/train_images/753b14c27c83.png\n/kaggle/input/aptos2019/train_images/train_images/ceb32a193eff.png\n/kaggle/input/aptos2019/train_images/train_images/4289af3afbd2.png\n/kaggle/input/aptos2019/train_images/train_images/bacfa2b8e706.png\n/kaggle/input/aptos2019/train_images/train_images/8a87dd2a784e.png\n/kaggle/input/aptos2019/train_images/train_images/1d14dd912671.png\n/kaggle/input/aptos2019/train_images/train_images/912fbe06407e.png\n/kaggle/input/aptos2019/train_images/train_images/3fe282197c1c.png\n/kaggle/input/aptos2019/train_images/train_images/bd9904495ccd.png\n/kaggle/input/aptos2019/train_images/train_images/4e231670b48c.png\n/kaggle/input/aptos2019/train_images/train_images/977e1ca77653.png\n/kaggle/input/aptos2019/train_images/train_images/a5a2a7003d60.png\n/kaggle/input/aptos2019/train_images/train_images/4c635a01593d.png\n/kaggle/input/aptos2019/train_images/train_images/bd269a1f0e4d.png\n/kaggle/input/aptos2019/train_images/train_images/c3cd0200df79.png\n/kaggle/input/aptos2019/train_images/train_images/5173d54fc214.png\n/kaggle/input/aptos2019/train_images/train_images/3710ff45299c.png\n/kaggle/input/aptos2019/train_images/train_images/98e8adcf085c.png\n/kaggle/input/aptos2019/train_images/train_images/42a67337fa8e.png\n/kaggle/input/aptos2019/train_images/train_images/6fe67fd7f5d1.png\n/kaggle/input/aptos2019/train_images/train_images/a7b03e58a6e1.png\n/kaggle/input/aptos2019/train_images/train_images/23148a40ecb0.png\n/kaggle/input/aptos2019/train_images/train_images/9a56cfb980ec.png\n/kaggle/input/aptos2019/train_images/train_images/54b322c66d01.png\n/kaggle/input/aptos2019/train_images/train_images/a06e41bd2634.png\n/kaggle/input/aptos2019/train_images/train_images/bacfb1029f6b.png\n/kaggle/input/aptos2019/train_images/train_images/a44345b27804.png\n/kaggle/input/aptos2019/train_images/train_images/85fce24084da.png\n/kaggle/input/aptos2019/train_images/train_images/4a7dc013e802.png\n/kaggle/input/aptos2019/train_images/train_images/5b72ff04333d.png\n/kaggle/input/aptos2019/train_images/train_images/c027e5482e8c.png\n/kaggle/input/aptos2019/train_images/train_images/69591ebb198d.png\n/kaggle/input/aptos2019/train_images/train_images/e26bcae6c67b.png\n/kaggle/input/aptos2019/train_images/train_images/6e68e742f5bc.png\n/kaggle/input/aptos2019/train_images/train_images/66bfec8d6bcd.png\n/kaggle/input/aptos2019/train_images/train_images/7ea756985353.png\n/kaggle/input/aptos2019/train_images/train_images/1ae8c165fd53.png\n/kaggle/input/aptos2019/train_images/train_images/dd3176bacfe2.png\n/kaggle/input/aptos2019/train_images/train_images/bb9a3d835a94.png\n/kaggle/input/aptos2019/train_images/train_images/bd06028eb7dd.png\n/kaggle/input/aptos2019/train_images/train_images/91b6ebaa3678.png\n/kaggle/input/aptos2019/train_images/train_images/e4a44f9158dc.png\n/kaggle/input/aptos2019/train_images/train_images/266fbefa58fb.png\n/kaggle/input/aptos2019/train_images/train_images/b033ab4fb723.png\n/kaggle/input/aptos2019/train_images/train_images/4cde86044ad1.png\n/kaggle/input/aptos2019/train_images/train_images/6d7d26025122.png\n/kaggle/input/aptos2019/train_images/train_images/2da82d14e1b7.png\n/kaggle/input/aptos2019/train_images/train_images/a721efb1e049.png\n/kaggle/input/aptos2019/train_images/train_images/9b4fc15df3c8.png\n/kaggle/input/aptos2019/train_images/train_images/1e7ccd4a1c87.png\n/kaggle/input/aptos2019/train_images/train_images/9c14ce27cbfc.png\n/kaggle/input/aptos2019/train_images/train_images/3cab32dd6ef9.png\n/kaggle/input/aptos2019/train_images/train_images/bcd503c726ba.png\n/kaggle/input/aptos2019/train_images/train_images/d0ffa0425ef1.png\n/kaggle/input/aptos2019/train_images/train_images/af5a0bc4e1fa.png\n/kaggle/input/aptos2019/train_images/train_images/a4359815f152.png\n/kaggle/input/aptos2019/train_images/train_images/42cc993f23a9.png\n/kaggle/input/aptos2019/train_images/train_images/d91635f380b4.png\n/kaggle/input/aptos2019/train_images/train_images/cc9270f06b65.png\n/kaggle/input/aptos2019/train_images/train_images/3e1f8fecb06f.png\n/kaggle/input/aptos2019/train_images/train_images/b90bc89ce8d8.png\n/kaggle/input/aptos2019/train_images/train_images/525d0dd8dc45.png\n/kaggle/input/aptos2019/train_images/train_images/8b26d3cd61e8.png\n/kaggle/input/aptos2019/train_images/train_images/a1822dd8d05d.png\n/kaggle/input/aptos2019/train_images/train_images/3f8d5c940ba4.png\n/kaggle/input/aptos2019/train_images/train_images/9a9b21215c55.png\n/kaggle/input/aptos2019/train_images/train_images/d06ccd0cf4b8.png\n/kaggle/input/aptos2019/train_images/train_images/1f07dae3cadb.png\n/kaggle/input/aptos2019/train_images/train_images/b3819a805dca.png\n/kaggle/input/aptos2019/train_images/train_images/6b3860e8f64f.png\n/kaggle/input/aptos2019/train_images/train_images/71e43b4f8ba6.png\n/kaggle/input/aptos2019/train_images/train_images/1e143fa3de57.png\n/kaggle/input/aptos2019/train_images/train_images/8ff863f8874f.png\n/kaggle/input/aptos2019/train_images/train_images/50ddd7d976df.png\n/kaggle/input/aptos2019/train_images/train_images/44a4d04162cc.png\n/kaggle/input/aptos2019/train_images/train_images/8a67f1efa315.png\n/kaggle/input/aptos2019/train_images/train_images/97a235367f9d.png\n/kaggle/input/aptos2019/train_images/train_images/6061f5b7378d.png\n/kaggle/input/aptos2019/train_images/train_images/7da558d92100.png\n/kaggle/input/aptos2019/train_images/train_images/78d53c82a23e.png\n/kaggle/input/aptos2019/train_images/train_images/5ba156a35ff2.png\n/kaggle/input/aptos2019/train_images/train_images/80a02014b418.png\n/kaggle/input/aptos2019/train_images/train_images/2d04cead4d3a.png\n/kaggle/input/aptos2019/train_images/train_images/73e83a07a16d.png\n/kaggle/input/aptos2019/train_images/train_images/2608e1dac5b1.png\n/kaggle/input/aptos2019/train_images/train_images/35d6c4c50072.png\n/kaggle/input/aptos2019/train_images/train_images/5777ef74c9ec.png\n/kaggle/input/aptos2019/train_images/train_images/dbee04ae6426.png\n/kaggle/input/aptos2019/train_images/train_images/d332d7b8a26e.png\n/kaggle/input/aptos2019/train_images/train_images/e29e54ff921e.png\n/kaggle/input/aptos2019/train_images/train_images/4dd4a4bf2421.png\n/kaggle/input/aptos2019/train_images/train_images/76e589911303.png\n/kaggle/input/aptos2019/train_images/train_images/8b8fe3fc8950.png\n/kaggle/input/aptos2019/train_images/train_images/9fefe2b44795.png\n/kaggle/input/aptos2019/train_images/train_images/82088c6734e6.png\n/kaggle/input/aptos2019/train_images/train_images/697538183db5.png\n/kaggle/input/aptos2019/train_images/train_images/807135cbc438.png\n/kaggle/input/aptos2019/train_images/train_images/43bc7c066dfb.png\n/kaggle/input/aptos2019/train_images/train_images/bca2bdc15fc5.png\n/kaggle/input/aptos2019/train_images/train_images/c5a0e84e955d.png\n/kaggle/input/aptos2019/train_images/train_images/72c31aa48e2c.png\n/kaggle/input/aptos2019/train_images/train_images/4e1e252317b5.png\n/kaggle/input/aptos2019/train_images/train_images/ad3fc5076852.png\n/kaggle/input/aptos2019/train_images/train_images/c9ea9d5eab65.png\n/kaggle/input/aptos2019/train_images/train_images/3c9529918097.png\n/kaggle/input/aptos2019/train_images/train_images/d7078e8b0349.png\n/kaggle/input/aptos2019/train_images/train_images/b98f77098b9d.png\n/kaggle/input/aptos2019/train_images/train_images/44c869174e3a.png\n/kaggle/input/aptos2019/train_images/train_images/d51c2153d151.png\n/kaggle/input/aptos2019/train_images/train_images/84b79243e430.png\n/kaggle/input/aptos2019/train_images/train_images/c5a6f432a1ec.png\n/kaggle/input/aptos2019/train_images/train_images/cd66754e1b3b.png\n/kaggle/input/aptos2019/train_images/train_images/5511f114e7ee.png\n/kaggle/input/aptos2019/train_images/train_images/c05b7b4c22fe.png\n/kaggle/input/aptos2019/train_images/train_images/c2d2b4f536da.png\n/kaggle/input/aptos2019/train_images/train_images/a19507501b40.png\n/kaggle/input/aptos2019/train_images/train_images/40e9b5630438.png\n/kaggle/input/aptos2019/train_images/train_images/bd375ba756b1.png\n/kaggle/input/aptos2019/train_images/train_images/d18aea8238a0.png\n/kaggle/input/aptos2019/train_images/train_images/df84e7113003.png\n/kaggle/input/aptos2019/train_images/train_images/21d18b022429.png\n/kaggle/input/aptos2019/train_images/train_images/7347bd23ba80.png\n/kaggle/input/aptos2019/train_images/train_images/cf0575534cec.png\n/kaggle/input/aptos2019/train_images/train_images/2bb3c492d6d3.png\n/kaggle/input/aptos2019/train_images/train_images/dea7538bb91a.png\n/kaggle/input/aptos2019/train_images/train_images/b3a994760537.png\n/kaggle/input/aptos2019/train_images/train_images/c102db7634d8.png\n/kaggle/input/aptos2019/train_images/train_images/541db13517e2.png\n/kaggle/input/aptos2019/train_images/train_images/7f39c36469b5.png\n/kaggle/input/aptos2019/train_images/train_images/3ee17aa12e46.png\n/kaggle/input/aptos2019/train_images/train_images/3f73c91b7e32.png\n/kaggle/input/aptos2019/train_images/train_images/a505981d1cab.png\n/kaggle/input/aptos2019/train_images/train_images/5d6239c0fd39.png\n/kaggle/input/aptos2019/train_images/train_images/73a07e2ea23e.png\n/kaggle/input/aptos2019/train_images/train_images/9785805af1b8.png\n/kaggle/input/aptos2019/train_images/train_images/bb5083fae98f.png\n/kaggle/input/aptos2019/train_images/train_images/8e3b79e1f1f7.png\n/kaggle/input/aptos2019/train_images/train_images/76cb010f7aa0.png\n/kaggle/input/aptos2019/train_images/train_images/8a25a080f28f.png\n/kaggle/input/aptos2019/train_images/train_images/7ba6b23c4b46.png\n/kaggle/input/aptos2019/train_images/train_images/76f3473df8a6.png\n/kaggle/input/aptos2019/train_images/train_images/222d0ac042b4.png\n/kaggle/input/aptos2019/train_images/train_images/7dee6bf8b9c1.png\n/kaggle/input/aptos2019/train_images/train_images/5ca73d28f17f.png\n/kaggle/input/aptos2019/train_images/train_images/3580a545016d.png\n/kaggle/input/aptos2019/train_images/train_images/e25ccfe38e44.png\n/kaggle/input/aptos2019/train_images/train_images/6155cf375354.png\n/kaggle/input/aptos2019/train_images/train_images/df4aec4a0eaf.png\n/kaggle/input/aptos2019/train_images/train_images/7569ac24762e.png\n/kaggle/input/aptos2019/train_images/train_images/b2aaa81cc8f0.png\n/kaggle/input/aptos2019/train_images/train_images/4ef0b485a7da.png\n/kaggle/input/aptos2019/train_images/train_images/a06a63d866b2.png\n/kaggle/input/aptos2019/train_images/train_images/cfed7c1172ec.png\n/kaggle/input/aptos2019/train_images/train_images/9ed6c2b25767.png\n/kaggle/input/aptos2019/train_images/train_images/b69c224edd6e.png\n/kaggle/input/aptos2019/train_images/train_images/e3ec668f6fad.png\n/kaggle/input/aptos2019/train_images/train_images/b5c80d0ed0ff.png\n/kaggle/input/aptos2019/train_images/train_images/daff5427c9b2.png\n/kaggle/input/aptos2019/train_images/train_images/c261b1aaa828.png\n/kaggle/input/aptos2019/train_images/train_images/a3d2a0c4cd17.png\n/kaggle/input/aptos2019/train_images/train_images/ab1c20a94f3f.png\n/kaggle/input/aptos2019/train_images/train_images/684dd88a0d49.png\n/kaggle/input/aptos2019/train_images/train_images/de50dfa745f8.png\n/kaggle/input/aptos2019/train_images/train_images/7e9458de5707.png\n/kaggle/input/aptos2019/train_images/train_images/82e5bc01f8a4.png\n/kaggle/input/aptos2019/train_images/train_images/35cd9832fc0a.png\n/kaggle/input/aptos2019/train_images/train_images/578109578b46.png\n/kaggle/input/aptos2019/train_images/train_images/1c4f3aa4df06.png\n/kaggle/input/aptos2019/train_images/train_images/c5e238aa18be.png\n/kaggle/input/aptos2019/train_images/train_images/20d5fdd450ae.png\n/kaggle/input/aptos2019/train_images/train_images/34723fae6475.png\n/kaggle/input/aptos2019/train_images/train_images/1b862fb6f65d.png\n/kaggle/input/aptos2019/train_images/train_images/9c893e16c055.png\n/kaggle/input/aptos2019/train_images/train_images/633fe9dbaf39.png\n/kaggle/input/aptos2019/train_images/train_images/6dfd80748e72.png\n/kaggle/input/aptos2019/train_images/train_images/9fa02dfb5553.png\n/kaggle/input/aptos2019/train_images/train_images/bb2f89488ecd.png\n/kaggle/input/aptos2019/train_images/train_images/8c2f0f04e1ed.png\n/kaggle/input/aptos2019/train_images/train_images/c334f8688b77.png\n/kaggle/input/aptos2019/train_images/train_images/baaca2f7e1f0.png\n/kaggle/input/aptos2019/train_images/train_images/4462fba1d2a1.png\n/kaggle/input/aptos2019/train_images/train_images/bda7ff3b1562.png\n/kaggle/input/aptos2019/train_images/train_images/7116128c65ab.png\n/kaggle/input/aptos2019/train_images/train_images/d2afca74cbc3.png\n/kaggle/input/aptos2019/train_images/train_images/2f4e81787d9b.png\n/kaggle/input/aptos2019/train_images/train_images/d78b7401096f.png\n/kaggle/input/aptos2019/train_images/train_images/ccea49708830.png\n/kaggle/input/aptos2019/train_images/train_images/3599029efeb3.png\n/kaggle/input/aptos2019/train_images/train_images/c597ef460944.png\n/kaggle/input/aptos2019/train_images/train_images/5e97cb2b0888.png\n/kaggle/input/aptos2019/train_images/train_images/5d024177e214.png\n/kaggle/input/aptos2019/train_images/train_images/ca05f7e7801b.png\n/kaggle/input/aptos2019/train_images/train_images/1dfbede13143.png\n/kaggle/input/aptos2019/train_images/train_images/315c1a0d87fd.png\n/kaggle/input/aptos2019/train_images/train_images/4e4a6224a04e.png\n/kaggle/input/aptos2019/train_images/train_images/80ca40196225.png\n/kaggle/input/aptos2019/train_images/train_images/3461dc601cc2.png\n/kaggle/input/aptos2019/train_images/train_images/a987aa7aac37.png\n/kaggle/input/aptos2019/train_images/train_images/2a2274bcb00a.png\n/kaggle/input/aptos2019/train_images/train_images/d774692d9919.png\n/kaggle/input/aptos2019/train_images/train_images/949710bead24.png\n/kaggle/input/aptos2019/train_images/train_images/b9bc81fcb075.png\n/kaggle/input/aptos2019/train_images/train_images/4d9fc85a8259.png\n/kaggle/input/aptos2019/train_images/train_images/c40976189f22.png\n/kaggle/input/aptos2019/train_images/train_images/a86128b601a7.png\n/kaggle/input/aptos2019/train_images/train_images/ce207b69ff37.png\n/kaggle/input/aptos2019/train_images/train_images/913490237ad4.png\n/kaggle/input/aptos2019/train_images/train_images/c947bb6cf9f6.png\n/kaggle/input/aptos2019/train_images/train_images/b6304c545f95.png\n/kaggle/input/aptos2019/train_images/train_images/525acfea47e8.png\n/kaggle/input/aptos2019/train_images/train_images/6d0c0531083f.png\n/kaggle/input/aptos2019/train_images/train_images/537e50fdf22e.png\n/kaggle/input/aptos2019/train_images/train_images/61f403fdb434.png\n/kaggle/input/aptos2019/train_images/train_images/9f1b14dfa14c.png\n/kaggle/input/aptos2019/train_images/train_images/a26f50218b84.png\n/kaggle/input/aptos2019/train_images/train_images/a0a0cd8af5a6.png\n/kaggle/input/aptos2019/train_images/train_images/51aa3361294c.png\n/kaggle/input/aptos2019/train_images/train_images/ca25745942b0.png\n/kaggle/input/aptos2019/train_images/train_images/360832d84ce0.png\n/kaggle/input/aptos2019/train_images/train_images/537e5c578f40.png\n/kaggle/input/aptos2019/train_images/train_images/b460ca9fa26f.png\n/kaggle/input/aptos2019/train_images/train_images/462937ece243.png\n/kaggle/input/aptos2019/train_images/train_images/cd5714db652d.png\n/kaggle/input/aptos2019/train_images/train_images/a7ec056502e7.png\n/kaggle/input/aptos2019/train_images/train_images/a01024054596.png\n/kaggle/input/aptos2019/train_images/train_images/cd972e5639e0.png\n/kaggle/input/aptos2019/train_images/train_images/3c326543fff6.png\n/kaggle/input/aptos2019/train_images/train_images/7526c59c36d3.png\n/kaggle/input/aptos2019/train_images/train_images/51d0034d177d.png\n/kaggle/input/aptos2019/train_images/train_images/b2b79b37d314.png\n/kaggle/input/aptos2019/train_images/train_images/7bc2e0fa3f72.png\n/kaggle/input/aptos2019/train_images/train_images/b13d72ceea26.png\n/kaggle/input/aptos2019/train_images/train_images/b65ff67743b2.png\n/kaggle/input/aptos2019/train_images/train_images/664b1f9a2087.png\n/kaggle/input/aptos2019/train_images/train_images/c56293f53191.png\n/kaggle/input/aptos2019/train_images/train_images/606daaf0bfc7.png\n/kaggle/input/aptos2019/train_images/train_images/afc744fad65e.png\n/kaggle/input/aptos2019/train_images/train_images/38f1901f214a.png\n/kaggle/input/aptos2019/train_images/train_images/a0adbe677508.png\n/kaggle/input/aptos2019/train_images/train_images/cd3fd04d72f5.png\n/kaggle/input/aptos2019/train_images/train_images/6e92b1c5ac8e.png\n/kaggle/input/aptos2019/train_images/train_images/cb602182cde3.png\n/kaggle/input/aptos2019/train_images/train_images/2408799a09b2.png\n/kaggle/input/aptos2019/train_images/train_images/38e111cac46f.png\n/kaggle/input/aptos2019/train_images/train_images/937bc1b924b1.png\n/kaggle/input/aptos2019/train_images/train_images/8958a4d17b7e.png\n/kaggle/input/aptos2019/train_images/train_images/add1d681d712.png\n/kaggle/input/aptos2019/train_images/train_images/46acc506fa61.png\n/kaggle/input/aptos2019/train_images/train_images/54cab3596214.png\n/kaggle/input/aptos2019/train_images/train_images/af6a1508cd95.png\n/kaggle/input/aptos2019/train_images/train_images/cb0cc98d7e35.png\n/kaggle/input/aptos2019/train_images/train_images/7c629b491d1a.png\n/kaggle/input/aptos2019/train_images/train_images/e0d229db881a.png\n/kaggle/input/aptos2019/train_images/train_images/a07d571bf7ba.png\n/kaggle/input/aptos2019/train_images/train_images/aa841de1ee82.png\n/kaggle/input/aptos2019/train_images/train_images/4926dea289f8.png\n/kaggle/input/aptos2019/train_images/train_images/be6cbf6e5b10.png\n/kaggle/input/aptos2019/train_images/train_images/a80dab8eddf4.png\n/kaggle/input/aptos2019/train_images/train_images/8d62ba9cb22a.png\n/kaggle/input/aptos2019/train_images/train_images/c26f98f58350.png\n/kaggle/input/aptos2019/train_images/train_images/7f6690fa390a.png\n/kaggle/input/aptos2019/train_images/train_images/2b21d293fdf2.png\n/kaggle/input/aptos2019/train_images/train_images/a8b637abd96b.png\n/kaggle/input/aptos2019/train_images/train_images/d81338217fc5.png\n/kaggle/input/aptos2019/train_images/train_images/7f6ce40f306b.png\n/kaggle/input/aptos2019/train_images/train_images/4242c0d87f57.png\n/kaggle/input/aptos2019/train_images/train_images/58a9e0d7f7af.png\n/kaggle/input/aptos2019/train_images/train_images/d26bb2ed6e71.png\n/kaggle/input/aptos2019/train_images/train_images/1df3e03a8f5f.png\n/kaggle/input/aptos2019/train_images/train_images/922586d86cd8.png\n/kaggle/input/aptos2019/train_images/train_images/b0acd3593310.png\n/kaggle/input/aptos2019/train_images/train_images/a763661f98a5.png\n/kaggle/input/aptos2019/train_images/train_images/a9a28c37c8c4.png\n/kaggle/input/aptos2019/train_images/train_images/7550966ef777.png\n/kaggle/input/aptos2019/train_images/train_images/478fc46eaa49.png\n/kaggle/input/aptos2019/train_images/train_images/42b9c1977681.png\n/kaggle/input/aptos2019/train_images/train_images/b759cbef90c5.png\n/kaggle/input/aptos2019/train_images/train_images/78a577c3e0bf.png\n/kaggle/input/aptos2019/train_images/train_images/a150ff5dfe07.png\n/kaggle/input/aptos2019/train_images/train_images/3c42512c81e0.png\n/kaggle/input/aptos2019/train_images/train_images/79be2ff796bf.png\n/kaggle/input/aptos2019/train_images/train_images/62318d514160.png\n/kaggle/input/aptos2019/train_images/train_images/d1cf31577a59.png\n/kaggle/input/aptos2019/train_images/train_images/b0b3b16fc305.png\n/kaggle/input/aptos2019/train_images/train_images/53327edb9e4d.png\n/kaggle/input/aptos2019/train_images/train_images/df3adfd6ba36.png\n/kaggle/input/aptos2019/train_images/train_images/27fca9f12b3c.png\n/kaggle/input/aptos2019/train_images/train_images/ab88081e5654.png\n/kaggle/input/aptos2019/train_images/train_images/803120c5d287.png\n/kaggle/input/aptos2019/train_images/train_images/e251bdf05b85.png\n/kaggle/input/aptos2019/train_images/train_images/34a7dbd3f05c.png\n/kaggle/input/aptos2019/train_images/train_images/58b866484a05.png\n/kaggle/input/aptos2019/train_images/train_images/838c87c63422.png\n/kaggle/input/aptos2019/train_images/train_images/84b4da14bc23.png\n/kaggle/input/aptos2019/train_images/train_images/b72a86d61959.png\n/kaggle/input/aptos2019/train_images/train_images/d6f6bdfd8011.png\n/kaggle/input/aptos2019/train_images/train_images/a821b6ecef33.png\n/kaggle/input/aptos2019/train_images/train_images/77543f66a84a.png\n/kaggle/input/aptos2019/train_images/train_images/3b5dffe159b6.png\n/kaggle/input/aptos2019/train_images/train_images/46c1548d730e.png\n/kaggle/input/aptos2019/train_images/train_images/43e9c66eb0f3.png\n/kaggle/input/aptos2019/train_images/train_images/36b5b3c9fb32.png\n/kaggle/input/aptos2019/train_images/train_images/5257cb536da2.png\n/kaggle/input/aptos2019/train_images/train_images/c280730cc211.png\n/kaggle/input/aptos2019/train_images/train_images/e0b5a982a018.png\n/kaggle/input/aptos2019/train_images/train_images/b7983cb3f270.png\n/kaggle/input/aptos2019/train_images/train_images/e39b627cf648.png\n/kaggle/input/aptos2019/train_images/train_images/5445255635f0.png\n/kaggle/input/aptos2019/train_images/train_images/6daef3e5ca22.png\n/kaggle/input/aptos2019/train_images/train_images/9e2058917304.png\n/kaggle/input/aptos2019/train_images/train_images/a7673ac44509.png\n/kaggle/input/aptos2019/train_images/train_images/da9574d35b82.png\n/kaggle/input/aptos2019/train_images/train_images/314862758acf.png\n/kaggle/input/aptos2019/train_images/train_images/8eb3337a54e9.png\n/kaggle/input/aptos2019/train_images/train_images/d5b4705ac2ee.png\n/kaggle/input/aptos2019/train_images/train_images/84b88e8d3bca.png\n/kaggle/input/aptos2019/train_images/train_images/5cf9127f251a.png\n/kaggle/input/aptos2019/train_images/train_images/840a06a9c690.png\n/kaggle/input/aptos2019/train_images/train_images/d952dbfb0fe4.png\n/kaggle/input/aptos2019/train_images/train_images/36677b70b1ef.png\n/kaggle/input/aptos2019/train_images/train_images/a19ecd0a706e.png\n/kaggle/input/aptos2019/train_images/train_images/4e6071b73120.png\n/kaggle/input/aptos2019/train_images/train_images/b762c29cf2f3.png\n/kaggle/input/aptos2019/train_images/train_images/e2c39ed0c941.png\n/kaggle/input/aptos2019/train_images/train_images/c546670d9684.png\n/kaggle/input/aptos2019/train_images/train_images/99240ee00485.png\n/kaggle/input/aptos2019/train_images/train_images/6cfb7b44ef6f.png\n/kaggle/input/aptos2019/train_images/train_images/2821998fc002.png\n/kaggle/input/aptos2019/train_images/train_images/42af7282349b.png\n/kaggle/input/aptos2019/train_images/train_images/99132193eaa0.png\n/kaggle/input/aptos2019/train_images/train_images/222f3ee3a1e8.png\n/kaggle/input/aptos2019/train_images/train_images/b95d4dd8e5e2.png\n/kaggle/input/aptos2019/train_images/train_images/b22cc1bf0b8a.png\n/kaggle/input/aptos2019/train_images/train_images/36ec36c301c1.png\n/kaggle/input/aptos2019/train_images/train_images/5069feccd866.png\n/kaggle/input/aptos2019/train_images/train_images/a9bc2f892cb3.png\n/kaggle/input/aptos2019/train_images/train_images/87b1938994b5.png\n/kaggle/input/aptos2019/train_images/train_images/8a8a251770cd.png\n/kaggle/input/aptos2019/train_images/train_images/7e4019ac7f5a.png\n/kaggle/input/aptos2019/train_images/train_images/47d1603a555b.png\n/kaggle/input/aptos2019/train_images/train_images/7d8f67cadc29.png\n/kaggle/input/aptos2019/train_images/train_images/74418f620068.png\n/kaggle/input/aptos2019/train_images/train_images/20c883d3bd38.png\n/kaggle/input/aptos2019/train_images/train_images/2fb3a8606a77.png\n/kaggle/input/aptos2019/train_images/train_images/891329021e12.png\n/kaggle/input/aptos2019/train_images/train_images/ae975c43bd8b.png\n/kaggle/input/aptos2019/train_images/train_images/4704dbb59536.png\n/kaggle/input/aptos2019/train_images/train_images/29f9e1ac9507.png\n/kaggle/input/aptos2019/train_images/train_images/76e5b50f95a7.png\n/kaggle/input/aptos2019/train_images/train_images/494fc9c745a3.png\n/kaggle/input/aptos2019/train_images/train_images/cb75210abebe.png\n/kaggle/input/aptos2019/train_images/train_images/d994203deb64.png\n/kaggle/input/aptos2019/train_images/train_images/97fdee242fea.png\n/kaggle/input/aptos2019/train_images/train_images/8ceff4c4c860.png\n/kaggle/input/aptos2019/train_images/train_images/2cfe8703f265.png\n/kaggle/input/aptos2019/train_images/train_images/9f5a8665cf2e.png\n/kaggle/input/aptos2019/train_images/train_images/e3a7671f787b.png\n/kaggle/input/aptos2019/train_images/train_images/6b128e648646.png\n/kaggle/input/aptos2019/train_images/train_images/ac1667fac512.png\n/kaggle/input/aptos2019/train_images/train_images/8e20b8fac7c3.png\n/kaggle/input/aptos2019/train_images/train_images/31360e44ac64.png\n/kaggle/input/aptos2019/train_images/train_images/86d58f850a0c.png\n/kaggle/input/aptos2019/train_images/train_images/5de4615a5161.png\n/kaggle/input/aptos2019/train_images/train_images/2fdfb80ea53c.png\n/kaggle/input/aptos2019/train_images/train_images/de730033c683.png\n/kaggle/input/aptos2019/train_images/train_images/5486da4273d7.png\n/kaggle/input/aptos2019/train_images/train_images/2665f72e2dd3.png\n/kaggle/input/aptos2019/train_images/train_images/81d79d53ed7b.png\n/kaggle/input/aptos2019/train_images/train_images/b2b7ccd34cbd.png\n/kaggle/input/aptos2019/train_images/train_images/8bf05909e1e1.png\n/kaggle/input/aptos2019/train_images/train_images/cbd0870aa933.png\n/kaggle/input/aptos2019/train_images/train_images/8b568d47a1fd.png\n/kaggle/input/aptos2019/train_images/train_images/39b5b05d6cd9.png\n/kaggle/input/aptos2019/train_images/train_images/b2ffa3e18559.png\n/kaggle/input/aptos2019/train_images/train_images/7ccb267fd394.png\n/kaggle/input/aptos2019/train_images/train_images/9033f1493da1.png\n/kaggle/input/aptos2019/train_images/train_images/a6c9e96a10d7.png\n/kaggle/input/aptos2019/train_images/train_images/dc0f6e5b489b.png\n/kaggle/input/aptos2019/train_images/train_images/9a326446c431.png\n/kaggle/input/aptos2019/train_images/train_images/2a47e5b21791.png\n/kaggle/input/aptos2019/train_images/train_images/7e9081e95bf6.png\n/kaggle/input/aptos2019/train_images/train_images/55968f0e63c4.png\n/kaggle/input/aptos2019/train_images/train_images/6735931000ec.png\n/kaggle/input/aptos2019/train_images/train_images/d9c9b9786da3.png\n/kaggle/input/aptos2019/train_images/train_images/a4ee03ecff60.png\n/kaggle/input/aptos2019/train_images/train_images/39f8935185e6.png\n/kaggle/input/aptos2019/train_images/train_images/96a9706b8534.png\n/kaggle/input/aptos2019/train_images/train_images/891392c9683c.png\n/kaggle/input/aptos2019/train_images/train_images/9ed666e982cd.png\n/kaggle/input/aptos2019/train_images/train_images/9ab18a4a957f.png\n/kaggle/input/aptos2019/train_images/train_images/a86c6283fd78.png\n/kaggle/input/aptos2019/train_images/train_images/c3d12a23f451.png\n/kaggle/input/aptos2019/train_images/train_images/69f43381317b.png\n/kaggle/input/aptos2019/train_images/train_images/82d364726a58.png\n/kaggle/input/aptos2019/train_images/train_images/c87493ed320c.png\n/kaggle/input/aptos2019/train_images/train_images/28a4d00927b7.png\n/kaggle/input/aptos2019/train_images/train_images/e38f3a65b02b.png\n/kaggle/input/aptos2019/train_images/train_images/81b0a2651c45.png\n/kaggle/input/aptos2019/train_images/train_images/d7e5fe5245e0.png\n/kaggle/input/aptos2019/train_images/train_images/2dc647e00ad3.png\n/kaggle/input/aptos2019/train_images/train_images/218c822a3dd9.png\n/kaggle/input/aptos2019/train_images/train_images/8ead17dfb6a6.png\n/kaggle/input/aptos2019/train_images/train_images/98441214557f.png\n/kaggle/input/aptos2019/train_images/train_images/ca7140ecf389.png\n/kaggle/input/aptos2019/train_images/train_images/b402b18d99a5.png\n/kaggle/input/aptos2019/train_images/train_images/57469423a012.png\n/kaggle/input/aptos2019/train_images/train_images/289a47dcbb82.png\n/kaggle/input/aptos2019/train_images/train_images/a8aed92940fb.png\n/kaggle/input/aptos2019/train_images/train_images/1df0431bfa73.png\n/kaggle/input/aptos2019/train_images/train_images/83d6e40c869f.png\n/kaggle/input/aptos2019/train_images/train_images/3f0d3629d69e.png\n/kaggle/input/aptos2019/train_images/train_images/2c8101f14723.png\n/kaggle/input/aptos2019/train_images/train_images/5a93c0f783c4.png\n/kaggle/input/aptos2019/train_images/train_images/842d697884f6.png\n/kaggle/input/aptos2019/train_images/train_images/359bab5d784b.png\n/kaggle/input/aptos2019/train_images/train_images/904b03ad5594.png\n/kaggle/input/aptos2019/train_images/train_images/b9519abce0c1.png\n/kaggle/input/aptos2019/train_images/train_images/53c874dbc594.png\n/kaggle/input/aptos2019/train_images/train_images/98277aeb96a7.png\n/kaggle/input/aptos2019/train_images/train_images/61ac9b0dc6b9.png\n/kaggle/input/aptos2019/train_images/train_images/92b0d27fc0ec.png\n/kaggle/input/aptos2019/train_images/train_images/36865bbc64d6.png\n/kaggle/input/aptos2019/train_images/train_images/bebb3f167654.png\n/kaggle/input/aptos2019/train_images/train_images/3dec415b188a.png\n/kaggle/input/aptos2019/train_images/train_images/9c6512166557.png\n/kaggle/input/aptos2019/train_images/train_images/b99afe7137fb.png\n/kaggle/input/aptos2019/train_images/train_images/a6d45de20e4d.png\n/kaggle/input/aptos2019/train_images/train_images/7f2cce721e19.png\n/kaggle/input/aptos2019/train_images/train_images/1b8ad0afe9fb.png\n/kaggle/input/aptos2019/train_images/train_images/dd110d2b8c21.png\n/kaggle/input/aptos2019/train_images/train_images/8aa3c4681542.png\n/kaggle/input/aptos2019/train_images/train_images/39923b29988a.png\n/kaggle/input/aptos2019/train_images/train_images/a77dbec966d4.png\n/kaggle/input/aptos2019/train_images/train_images/bebfbd907cac.png\n/kaggle/input/aptos2019/train_images/train_images/60f15dd68d30.png\n/kaggle/input/aptos2019/train_images/train_images/b0d6417bad3e.png\n/kaggle/input/aptos2019/train_images/train_images/2221cf5c7935.png\n/kaggle/input/aptos2019/train_images/train_images/a8b3c0961d42.png\n/kaggle/input/aptos2019/train_images/train_images/9039cbfcbb2f.png\n/kaggle/input/aptos2019/train_images/train_images/3b2b91590590.png\n/kaggle/input/aptos2019/train_images/train_images/abbb8791785e.png\n/kaggle/input/aptos2019/train_images/train_images/c85b79d70079.png\n/kaggle/input/aptos2019/train_images/train_images/780f9c237c56.png\n/kaggle/input/aptos2019/train_images/train_images/9b57e43b44e7.png\n/kaggle/input/aptos2019/train_images/train_images/a3802934bad7.png\n/kaggle/input/aptos2019/train_images/train_images/4276b82e4489.png\n/kaggle/input/aptos2019/train_images/train_images/57db4781e7ec.png\n/kaggle/input/aptos2019/train_images/train_images/9d75de31f1b8.png\n/kaggle/input/aptos2019/train_images/train_images/318eb706a134.png\n/kaggle/input/aptos2019/train_images/train_images/35beb47fe159.png\n/kaggle/input/aptos2019/train_images/train_images/5321ab64f9ea.png\n/kaggle/input/aptos2019/train_images/train_images/435414ccccf7.png\n/kaggle/input/aptos2019/train_images/train_images/50f5201fd18a.png\n/kaggle/input/aptos2019/train_images/train_images/79059d0592c4.png\n/kaggle/input/aptos2019/train_images/train_images/683023cda6a5.png\n/kaggle/input/aptos2019/train_images/train_images/1eee55494271.png\n/kaggle/input/aptos2019/train_images/train_images/b35cad8fe2d7.png\n/kaggle/input/aptos2019/train_images/train_images/5b3e7197ac1c.png\n/kaggle/input/aptos2019/train_images/train_images/5a11d21c2828.png\n/kaggle/input/aptos2019/train_images/train_images/4ab8c0cece7f.png\n/kaggle/input/aptos2019/train_images/train_images/6d3d1fe6c32a.png\n/kaggle/input/aptos2019/train_images/train_images/8dba09a4e5ed.png\n/kaggle/input/aptos2019/train_images/train_images/a14bbd9a583e.png\n/kaggle/input/aptos2019/train_images/train_images/2d558de2cabe.png\n/kaggle/input/aptos2019/train_images/train_images/2cf18033da31.png\n/kaggle/input/aptos2019/train_images/train_images/e387311a840e.png\n/kaggle/input/aptos2019/train_images/train_images/7179f85bfd6f.png\n/kaggle/input/aptos2019/train_images/train_images/4eabad7948cf.png\n/kaggle/input/aptos2019/train_images/train_images/1e036f2e7095.png\n/kaggle/input/aptos2019/train_images/train_images/dd90c321d7bc.png\n/kaggle/input/aptos2019/train_images/train_images/5728b8aa98ef.png\n/kaggle/input/aptos2019/train_images/train_images/c97472ef2c66.png\n/kaggle/input/aptos2019/train_images/train_images/40c24aded50c.png\n/kaggle/input/aptos2019/train_images/train_images/7a06ea127e02.png\n/kaggle/input/aptos2019/train_images/train_images/d97911a32918.png\n/kaggle/input/aptos2019/train_images/train_images/8564b7aa3c1a.png\n/kaggle/input/aptos2019/train_images/train_images/3d3e288d490e.png\n/kaggle/input/aptos2019/train_images/train_images/49a4765f8822.png\n/kaggle/input/aptos2019/train_images/train_images/d74ccc796517.png\n/kaggle/input/aptos2019/train_images/train_images/3e3a3955b9c5.png\n/kaggle/input/aptos2019/train_images/train_images/3f6bccf21ce8.png\n/kaggle/input/aptos2019/train_images/train_images/4ec7796df40e.png\n/kaggle/input/aptos2019/train_images/train_images/d1cad012a254.png\n/kaggle/input/aptos2019/train_images/train_images/9be71d6d7e59.png\n/kaggle/input/aptos2019/train_images/train_images/1bf30c84bbad.png\n/kaggle/input/aptos2019/train_images/train_images/4c389d033cb0.png\n/kaggle/input/aptos2019/train_images/train_images/c3a82acb7d7a.png\n/kaggle/input/aptos2019/train_images/train_images/a62ea0043aa7.png\n/kaggle/input/aptos2019/train_images/train_images/5f70ad48a525.png\n/kaggle/input/aptos2019/train_images/train_images/415d5c5e785f.png\n/kaggle/input/aptos2019/train_images/train_images/2f5c9cdfb333.png\n/kaggle/input/aptos2019/train_images/train_images/81914ceb4e74.png\n/kaggle/input/aptos2019/train_images/train_images/306c841af3fc.png\n/kaggle/input/aptos2019/train_images/train_images/7e77b61e1639.png\n/kaggle/input/aptos2019/train_images/train_images/848e66b9e199.png\n/kaggle/input/aptos2019/train_images/train_images/8fbb2ca39911.png\n/kaggle/input/aptos2019/train_images/train_images/45c39ab9e797.png\n/kaggle/input/aptos2019/train_images/train_images/999115d9386b.png\n/kaggle/input/aptos2019/train_images/train_images/bdf47b9f10c4.png\n/kaggle/input/aptos2019/train_images/train_images/511fd66b2df8.png\n/kaggle/input/aptos2019/train_images/train_images/69df7ade0575.png\n/kaggle/input/aptos2019/train_images/train_images/5f6db235c04d.png\n/kaggle/input/aptos2019/train_images/train_images/cd8da43e3069.png\n/kaggle/input/aptos2019/train_images/train_images/840527bc6628.png\n/kaggle/input/aptos2019/train_images/train_images/66a0bf258013.png\n/kaggle/input/aptos2019/train_images/train_images/a1e236fbc863.png\n/kaggle/input/aptos2019/train_images/train_images/94111ed3d276.png\n/kaggle/input/aptos2019/train_images/train_images/b8297a2291f5.png\n/kaggle/input/aptos2019/train_images/train_images/ad1f7445b1a8.png\n/kaggle/input/aptos2019/train_images/train_images/aa0afc41ed19.png\n/kaggle/input/aptos2019/train_images/train_images/2d07162a13b1.png\n/kaggle/input/aptos2019/train_images/train_images/6733544ae7a6.png\n/kaggle/input/aptos2019/train_images/train_images/a0e635689259.png\n/kaggle/input/aptos2019/train_images/train_images/e150935f66a6.png\n/kaggle/input/aptos2019/train_images/train_images/ba735b286d62.png\n/kaggle/input/aptos2019/train_images/train_images/55fd453001cc.png\n/kaggle/input/aptos2019/train_images/train_images/875d2ffcbf47.png\n/kaggle/input/aptos2019/train_images/train_images/aa9cfe639ef1.png\n/kaggle/input/aptos2019/train_images/train_images/3b018e8b7303.png\n/kaggle/input/aptos2019/train_images/train_images/5eb8fb1aad41.png\n/kaggle/input/aptos2019/train_images/train_images/d25b8a8ad3c4.png\n/kaggle/input/aptos2019/train_images/train_images/ae5d31979f19.png\n/kaggle/input/aptos2019/train_images/train_images/405085b53d7b.png\n/kaggle/input/aptos2019/train_images/train_images/e23add229074.png\n/kaggle/input/aptos2019/train_images/train_images/527bea76116c.png\n/kaggle/input/aptos2019/train_images/train_images/94dcb491143f.png\n/kaggle/input/aptos2019/train_images/train_images/e037643244b7.png\n/kaggle/input/aptos2019/train_images/train_images/687759336b0d.png\n/kaggle/input/aptos2019/train_images/train_images/b50b30aa6e6c.png\n/kaggle/input/aptos2019/train_images/train_images/51d780864365.png\n/kaggle/input/aptos2019/train_images/train_images/63d217b059b6.png\n/kaggle/input/aptos2019/train_images/train_images/1ee1eb7943db.png\n/kaggle/input/aptos2019/train_images/train_images/48543037d0b3.png\n/kaggle/input/aptos2019/train_images/train_images/a11c62cb3f86.png\n/kaggle/input/aptos2019/train_images/train_images/df5ce3ea7820.png\n/kaggle/input/aptos2019/train_images/train_images/24b943fe725e.png\n/kaggle/input/aptos2019/train_images/train_images/4beeca5cc859.png\n/kaggle/input/aptos2019/train_images/train_images/26453eb7e989.png\n/kaggle/input/aptos2019/train_images/train_images/3f98be586fe3.png\n/kaggle/input/aptos2019/train_images/train_images/5299a532f0e0.png\n/kaggle/input/aptos2019/train_images/train_images/201f882365d3.png\n/kaggle/input/aptos2019/train_images/train_images/c21eb81de9fc.png\n/kaggle/input/aptos2019/train_images/train_images/d264396d8d1a.png\n/kaggle/input/aptos2019/train_images/train_images/a1872f9c0cba.png\n/kaggle/input/aptos2019/train_images/train_images/8ab3faa3701f.png\n/kaggle/input/aptos2019/train_images/train_images/910bfd38e2f5.png\n/kaggle/input/aptos2019/train_images/train_images/83df53d58f28.png\n/kaggle/input/aptos2019/train_images/train_images/404ede327e98.png\n/kaggle/input/aptos2019/train_images/train_images/780f9daaa24b.png\n/kaggle/input/aptos2019/train_images/train_images/cb2f3c5d71a7.png\n/kaggle/input/aptos2019/train_images/train_images/1b32e1d775ea.png\n/kaggle/input/aptos2019/train_images/train_images/857230f64a2e.png\n/kaggle/input/aptos2019/train_images/train_images/a96ff96bbae5.png\n/kaggle/input/aptos2019/train_images/train_images/2a93334f663a.png\n/kaggle/input/aptos2019/train_images/train_images/4faf4063db8c.png\n/kaggle/input/aptos2019/train_images/train_images/c4a8f2fcf6e8.png\n/kaggle/input/aptos2019/train_images/train_images/5152bf091152.png\n/kaggle/input/aptos2019/train_images/train_images/94145d1f42cf.png\n/kaggle/input/aptos2019/train_images/train_images/6d5a8362dd1e.png\n/kaggle/input/aptos2019/train_images/train_images/29580bed2f7d.png\n/kaggle/input/aptos2019/train_images/train_images/5723d0ec895e.png\n/kaggle/input/aptos2019/train_images/train_images/702de9dcde32.png\n/kaggle/input/aptos2019/train_images/train_images/aa4407aab872.png\n/kaggle/input/aptos2019/train_images/train_images/295fdc964f6e.png\n/kaggle/input/aptos2019/train_images/train_images/8cb6b0efaaac.png\n/kaggle/input/aptos2019/train_images/train_images/79d44db3da2d.png\n/kaggle/input/aptos2019/train_images/train_images/c406325360b1.png\n/kaggle/input/aptos2019/train_images/train_images/4cae247d9909.png\n/kaggle/input/aptos2019/train_images/train_images/4294a14c656a.png\n/kaggle/input/aptos2019/train_images/train_images/240b25a7debe.png\n/kaggle/input/aptos2019/train_images/train_images/7635921c5efb.png\n/kaggle/input/aptos2019/train_images/train_images/5d74f98d62be.png\n/kaggle/input/aptos2019/train_images/train_images/3b73a3a4a734.png\n/kaggle/input/aptos2019/train_images/train_images/6d6fcf49e515.png\n/kaggle/input/aptos2019/train_images/train_images/7d261f986bef.png\n/kaggle/input/aptos2019/train_images/train_images/b3f31c371e59.png\n/kaggle/input/aptos2019/train_images/train_images/1c13a1483f4a.png\n/kaggle/input/aptos2019/train_images/train_images/cd9e2190c73f.png\n/kaggle/input/aptos2019/train_images/train_images/59928f999ae7.png\n/kaggle/input/aptos2019/train_images/train_images/88e5051f65bd.png\n/kaggle/input/aptos2019/train_images/train_images/5d5b5da5f939.png\n/kaggle/input/aptos2019/train_images/train_images/9ac2e3e9fca5.png\n/kaggle/input/aptos2019/train_images/train_images/7ef5ff774a48.png\n/kaggle/input/aptos2019/train_images/train_images/2463bb04ebc3.png\n/kaggle/input/aptos2019/train_images/train_images/99c6a123ed6a.png\n/kaggle/input/aptos2019/train_images/train_images/48fda42bd5d4.png\n/kaggle/input/aptos2019/train_images/train_images/d2dc86021c67.png\n/kaggle/input/aptos2019/train_images/train_images/acf976efd7ce.png\n/kaggle/input/aptos2019/train_images/train_images/a476fd984005.png\n/kaggle/input/aptos2019/train_images/train_images/d881c04f01fe.png\n/kaggle/input/aptos2019/train_images/train_images/86410aa13b3e.png\n/kaggle/input/aptos2019/train_images/train_images/5b32ece9c627.png\n/kaggle/input/aptos2019/train_images/train_images/2585bbc91909.png\n/kaggle/input/aptos2019/train_images/train_images/c1e6fa1ad314.png\n/kaggle/input/aptos2019/train_images/train_images/cd01f4f83336.png\n/kaggle/input/aptos2019/train_images/train_images/60edda7b4871.png\n/kaggle/input/aptos2019/train_images/train_images/3232b34cbe99.png\n/kaggle/input/aptos2019/train_images/train_images/bda91b76095b.png\n/kaggle/input/aptos2019/train_images/train_images/8f10e41a2f02.png\n/kaggle/input/aptos2019/train_images/train_images/e2265c383348.png\n/kaggle/input/aptos2019/train_images/train_images/6f923b60934b.png\n/kaggle/input/aptos2019/train_images/train_images/7a46cfa69bae.png\n/kaggle/input/aptos2019/train_images/train_images/64c6c6ee0d98.png\n/kaggle/input/aptos2019/train_images/train_images/dccdf750c962.png\n/kaggle/input/aptos2019/train_images/train_images/66366a90d1ef.png\n/kaggle/input/aptos2019/train_images/train_images/ca30a97e9d13.png\n/kaggle/input/aptos2019/train_images/train_images/4a0bba3b7d83.png\n/kaggle/input/aptos2019/train_images/train_images/ac81fc200162.png\n/kaggle/input/aptos2019/train_images/train_images/269f0792f11f.png\n/kaggle/input/aptos2019/train_images/train_images/3e86335bc2fd.png\n/kaggle/input/aptos2019/train_images/train_images/af345c68e836.png\n/kaggle/input/aptos2019/train_images/train_images/bf9cba745efc.png\n/kaggle/input/aptos2019/train_images/train_images/682312e82ee3.png\n/kaggle/input/aptos2019/train_images/train_images/b0f0fa677d5f.png\n/kaggle/input/aptos2019/train_images/train_images/6cee2e148520.png\n/kaggle/input/aptos2019/train_images/train_images/b11dcdcbc8c8.png\n/kaggle/input/aptos2019/train_images/train_images/da2bdf4236ac.png\n/kaggle/input/aptos2019/train_images/train_images/8d8aca52c07b.png\n/kaggle/input/aptos2019/train_images/train_images/bb752b179751.png\n/kaggle/input/aptos2019/train_images/train_images/c06024f05a16.png\n/kaggle/input/aptos2019/train_images/train_images/76fe19ff64fb.png\n/kaggle/input/aptos2019/train_images/train_images/bab776139279.png\n/kaggle/input/aptos2019/train_images/train_images/7fc3a8bb40de.png\n/kaggle/input/aptos2019/train_images/train_images/c01eae4b4939.png\n/kaggle/input/aptos2019/train_images/train_images/d0926ed2c8e5.png\n/kaggle/input/aptos2019/train_images/train_images/4df6a81b476e.png\n/kaggle/input/aptos2019/train_images/train_images/e3ab63dc9a60.png\n/kaggle/input/aptos2019/train_images/train_images/b5e6ae31493c.png\n/kaggle/input/aptos2019/train_images/train_images/e19936582c61.png\n/kaggle/input/aptos2019/train_images/train_images/9f1efb799b7b.png\n/kaggle/input/aptos2019/train_images/train_images/b5834ee64541.png\n/kaggle/input/aptos2019/train_images/train_images/8ae049175db6.png\n/kaggle/input/aptos2019/train_images/train_images/c18a006f7f1d.png\n/kaggle/input/aptos2019/train_images/train_images/da1fb35f5df9.png\n/kaggle/input/aptos2019/train_images/train_images/cad5b1a82e60.png\n/kaggle/input/aptos2019/train_images/train_images/96c3e3db68bc.png\n/kaggle/input/aptos2019/train_images/train_images/54bbe3da103e.png\n/kaggle/input/aptos2019/train_images/train_images/2bb063318cf1.png\n/kaggle/input/aptos2019/train_images/train_images/5e7630f8438e.png\n/kaggle/input/aptos2019/train_images/train_images/3486f7096276.png\n/kaggle/input/aptos2019/train_images/train_images/b99c825b93c5.png\n/kaggle/input/aptos2019/train_images/train_images/8e76054f0831.png\n/kaggle/input/aptos2019/train_images/train_images/a4012932e18d.png\n/kaggle/input/aptos2019/train_images/train_images/8dc22e65c06f.png\n/kaggle/input/aptos2019/train_images/train_images/7b87b0015282.png\n/kaggle/input/aptos2019/train_images/train_images/510aa0a898fa.png\n/kaggle/input/aptos2019/train_images/train_images/46f56c38051f.png\n/kaggle/input/aptos2019/train_images/train_images/8bc6716c2238.png\n/kaggle/input/aptos2019/train_images/train_images/80e6e425f966.png\n/kaggle/input/aptos2019/train_images/train_images/b665041e1633.png\n/kaggle/input/aptos2019/train_images/train_images/e17507a4a1f5.png\n/kaggle/input/aptos2019/train_images/train_images/917f76f360b6.png\n/kaggle/input/aptos2019/train_images/train_images/1faf8664816c.png\n/kaggle/input/aptos2019/train_images/train_images/7d11dbc1e738.png\n/kaggle/input/aptos2019/train_images/train_images/7ad0c4975890.png\n/kaggle/input/aptos2019/train_images/train_images/db6207e62c7b.png\n/kaggle/input/aptos2019/train_images/train_images/7e980424868e.png\n/kaggle/input/aptos2019/train_images/train_images/9a4f370d341b.png\n/kaggle/input/aptos2019/train_images/train_images/a95858e052d6.png\n/kaggle/input/aptos2019/train_images/train_images/8ac0c44bbf24.png\n/kaggle/input/aptos2019/train_images/train_images/a14fcf84bfe1.png\n/kaggle/input/aptos2019/train_images/train_images/96d48b073f18.png\n/kaggle/input/aptos2019/train_images/train_images/6e1db8711879.png\n/kaggle/input/aptos2019/train_images/train_images/8c7c26c52a6c.png\n/kaggle/input/aptos2019/train_images/train_images/5eb311bcb5f9.png\n/kaggle/input/aptos2019/train_images/train_images/658ad9f09f5d.png\n/kaggle/input/aptos2019/train_images/train_images/b8e9a8f4617d.png\n/kaggle/input/aptos2019/train_images/train_images/2399d68d407f.png\n/kaggle/input/aptos2019/train_images/train_images/72595230840c.png\n/kaggle/input/aptos2019/train_images/train_images/28f98cfe3858.png\n/kaggle/input/aptos2019/train_images/train_images/4fa26d065ad3.png\n/kaggle/input/aptos2019/train_images/train_images/7c2f820a6425.png\n/kaggle/input/aptos2019/train_images/train_images/c81c6911f5e0.png\n/kaggle/input/aptos2019/train_images/train_images/45693d027798.png\n/kaggle/input/aptos2019/train_images/train_images/d271d3a2b552.png\n/kaggle/input/aptos2019/train_images/train_images/500aad15b7c8.png\n/kaggle/input/aptos2019/train_images/train_images/d1f7ea924a01.png\n/kaggle/input/aptos2019/train_images/train_images/ce754234d760.png\n/kaggle/input/aptos2019/train_images/train_images/711d1480d2e3.png\n/kaggle/input/aptos2019/train_images/train_images/50a2aef380c8.png\n/kaggle/input/aptos2019/train_images/train_images/5b994ff78547.png\n/kaggle/input/aptos2019/train_images/train_images/2628305cbb29.png\n/kaggle/input/aptos2019/train_images/train_images/9f37c98b8187.png\n/kaggle/input/aptos2019/train_images/train_images/b66f23ffa730.png\n/kaggle/input/aptos2019/train_images/train_images/7e5a76c4e103.png\n/kaggle/input/aptos2019/train_images/train_images/9a3c03a5ad0f.png\n/kaggle/input/aptos2019/train_images/train_images/571bbdbf585e.png\n/kaggle/input/aptos2019/train_images/train_images/93be637084a2.png\n/kaggle/input/aptos2019/train_images/train_images/4b1001050f1d.png\n/kaggle/input/aptos2019/train_images/train_images/e0313be77035.png\n/kaggle/input/aptos2019/train_images/train_images/475c7ded0f7a.png\n/kaggle/input/aptos2019/train_images/train_images/65e530ee2e79.png\n/kaggle/input/aptos2019/train_images/train_images/d3dfd0a2dee6.png\n/kaggle/input/aptos2019/train_images/train_images/94ef1d14597f.png\n/kaggle/input/aptos2019/train_images/train_images/668a319c2d23.png\n/kaggle/input/aptos2019/train_images/train_images/4ad6109706e8.png\n/kaggle/input/aptos2019/train_images/train_images/cbf0394039f8.png\n/kaggle/input/aptos2019/train_images/train_images/9878db94d9f3.png\n/kaggle/input/aptos2019/train_images/train_images/a15470303941.png\n/kaggle/input/aptos2019/train_images/train_images/785777558f05.png\n/kaggle/input/aptos2019/train_images/train_images/555d0bef3c5b.png\n/kaggle/input/aptos2019/train_images/train_images/436e1793d240.png\n/kaggle/input/aptos2019/train_images/train_images/ad1aa75d5630.png\n/kaggle/input/aptos2019/train_images/train_images/b310bd564329.png\n/kaggle/input/aptos2019/train_images/train_images/c7c3d363bc86.png\n/kaggle/input/aptos2019/train_images/train_images/4b5ffea77373.png\n/kaggle/input/aptos2019/train_images/train_images/53f6c1c65c04.png\n/kaggle/input/aptos2019/train_images/train_images/6d4f6c9a8406.png\n/kaggle/input/aptos2019/train_images/train_images/7fdb177b8f7d.png\n/kaggle/input/aptos2019/train_images/train_images/8d4ff745a409.png\n/kaggle/input/aptos2019/train_images/train_images/4da6e2089d57.png\n/kaggle/input/aptos2019/train_images/train_images/7356dd08b0ae.png\n/kaggle/input/aptos2019/train_images/train_images/bc23f74e14dd.png\n/kaggle/input/aptos2019/train_images/train_images/7c3747c0b2c3.png\n/kaggle/input/aptos2019/train_images/train_images/a47432cd41e7.png\n/kaggle/input/aptos2019/train_images/train_images/d51e5d7484ea.png\n/kaggle/input/aptos2019/train_images/train_images/810ed108f5b7.png\n/kaggle/input/aptos2019/train_images/train_images/76df141d966b.png\n/kaggle/input/aptos2019/train_images/train_images/6c4ec95dd8ba.png\n/kaggle/input/aptos2019/train_images/train_images/b6fd109b1bc9.png\n/kaggle/input/aptos2019/train_images/train_images/b019a49787c1.png\n/kaggle/input/aptos2019/train_images/train_images/67c03349bb31.png\n/kaggle/input/aptos2019/train_images/train_images/aa5ce75edcf5.png\n/kaggle/input/aptos2019/train_images/train_images/461fa5292fda.png\n/kaggle/input/aptos2019/train_images/train_images/43823561c3f0.png\n/kaggle/input/aptos2019/train_images/train_images/9b0eb9f41da4.png\n/kaggle/input/aptos2019/train_images/train_images/9a496b1e20f9.png\n/kaggle/input/aptos2019/train_images/train_images/3fd7df6099e3.png\n/kaggle/input/aptos2019/train_images/train_images/3a4cfea0a766.png\n/kaggle/input/aptos2019/train_images/train_images/80ed04a84a16.png\n/kaggle/input/aptos2019/train_images/train_images/6028a575dc27.png\n/kaggle/input/aptos2019/train_images/train_images/65e51e18242b.png\n/kaggle/input/aptos2019/train_images/train_images/1b4625877527.png\n/kaggle/input/aptos2019/train_images/train_images/a6b6d27c1b32.png\n/kaggle/input/aptos2019/train_images/train_images/39134907127a.png\n/kaggle/input/aptos2019/train_images/train_images/e03a74e7d74f.png\n/kaggle/input/aptos2019/train_images/train_images/ad944bd56bb6.png\n/kaggle/input/aptos2019/train_images/train_images/959dc602febc.png\n/kaggle/input/aptos2019/train_images/train_images/a386ec9aabde.png\n/kaggle/input/aptos2019/train_images/train_images/e03e70bc8bba.png\n/kaggle/input/aptos2019/train_images/train_images/720b5f62ce80.png\n/kaggle/input/aptos2019/train_images/train_images/3ffa14d60b24.png\n/kaggle/input/aptos2019/train_images/train_images/523ff163211b.png\n/kaggle/input/aptos2019/train_images/train_images/3a1ecf5e2839.png\n/kaggle/input/aptos2019/train_images/train_images/8273fdb4405e.png\n/kaggle/input/aptos2019/train_images/train_images/7877be80901c.png\n/kaggle/input/aptos2019/train_images/train_images/7ee6de71c140.png\n/kaggle/input/aptos2019/train_images/train_images/af828dab3ffc.png\n/kaggle/input/aptos2019/train_images/train_images/c48ae5da188e.png\n/kaggle/input/aptos2019/train_images/train_images/9bf060db8376.png\n/kaggle/input/aptos2019/train_images/train_images/5712e2aa73a2.png\n/kaggle/input/aptos2019/train_images/train_images/8d4d14a4ab07.png\n/kaggle/input/aptos2019/train_images/train_images/7b20210d9120.png\n/kaggle/input/aptos2019/train_images/train_images/b82dfa63a75f.png\n/kaggle/input/aptos2019/train_images/train_images/e06d3d4733f0.png\n/kaggle/input/aptos2019/train_images/train_images/387138ddf43d.png\n/kaggle/input/aptos2019/train_images/train_images/b1f4122fd36a.png\n/kaggle/input/aptos2019/train_images/train_images/956765d5f46d.png\n/kaggle/input/aptos2019/train_images/train_images/5a03fe3ed15c.png\n/kaggle/input/aptos2019/train_images/train_images/d160ebef4117.png\n/kaggle/input/aptos2019/train_images/train_images/789c60cba801.png\n/kaggle/input/aptos2019/train_images/train_images/d16e59a2b33a.png\n/kaggle/input/aptos2019/train_images/train_images/5b0e53f53ef3.png\n/kaggle/input/aptos2019/train_images/train_images/67f5d89da548.png\n/kaggle/input/aptos2019/train_images/train_images/a2ddabee14e9.png\n/kaggle/input/aptos2019/train_images/train_images/30cab14951ac.png\n/kaggle/input/aptos2019/train_images/train_images/6d6be4cfc73f.png\n/kaggle/input/aptos2019/train_images/train_images/72d98188648f.png\n/kaggle/input/aptos2019/train_images/train_images/259d30f693b6.png\n/kaggle/input/aptos2019/train_images/train_images/4036471a1bb7.png\n/kaggle/input/aptos2019/train_images/train_images/9ae54843c69a.png\n/kaggle/input/aptos2019/train_images/train_images/83a63c4a3e4a.png\n/kaggle/input/aptos2019/train_images/train_images/25dc1b41ed9c.png\n/kaggle/input/aptos2019/train_images/train_images/3c53198519f7.png\n/kaggle/input/aptos2019/train_images/train_images/38e0e28d35d3.png\n/kaggle/input/aptos2019/train_images/train_images/da6bbb76d562.png\n/kaggle/input/aptos2019/train_images/train_images/2d552318eb07.png\n/kaggle/input/aptos2019/train_images/train_images/61bbc11fe503.png\n/kaggle/input/aptos2019/train_images/train_images/1d2472849dce.png\n/kaggle/input/aptos2019/train_images/train_images/90a9a41eec6d.png\n/kaggle/input/aptos2019/train_images/train_images/5e7cc6ab4ac4.png\n/kaggle/input/aptos2019/train_images/train_images/b6bfe9db60e5.png\n/kaggle/input/aptos2019/train_images/train_images/8ab8d9b3ce3f.png\n/kaggle/input/aptos2019/train_images/train_images/2c77bf969079.png\n/kaggle/input/aptos2019/train_images/train_images/b71428739d4e.png\n/kaggle/input/aptos2019/train_images/train_images/3178559fbf57.png\n/kaggle/input/aptos2019/train_images/train_images/87295c5fa1cc.png\n/kaggle/input/aptos2019/train_images/train_images/b3d135bd3bb5.png\n/kaggle/input/aptos2019/train_images/train_images/441848e0f308.png\n/kaggle/input/aptos2019/train_images/train_images/e2856afe62c5.png\n/kaggle/input/aptos2019/train_images/train_images/331121c65e88.png\n/kaggle/input/aptos2019/train_images/train_images/a88365134c3c.png\n/kaggle/input/aptos2019/train_images/train_images/af133a85ea0c.png\n/kaggle/input/aptos2019/train_images/train_images/acc9f29538c4.png\n/kaggle/input/aptos2019/train_images/train_images/4b618537d52f.png\n/kaggle/input/aptos2019/train_images/train_images/4b237b958555.png\n/kaggle/input/aptos2019/train_images/train_images/67844c46bc61.png\n/kaggle/input/aptos2019/train_images/train_images/a00b4cb250a7.png\n/kaggle/input/aptos2019/train_images/train_images/b8dab47a260e.png\n/kaggle/input/aptos2019/train_images/train_images/b3c0c3330278.png\n/kaggle/input/aptos2019/train_images/train_images/ab3c505b624f.png\n/kaggle/input/aptos2019/train_images/train_images/da0a1043abf7.png\n/kaggle/input/aptos2019/train_images/train_images/7831ce1d895e.png\n/kaggle/input/aptos2019/train_images/train_images/addf66a50f42.png\n/kaggle/input/aptos2019/train_images/train_images/b7f0bc7d399e.png\n/kaggle/input/aptos2019/train_images/train_images/7b9d519cbd66.png\n/kaggle/input/aptos2019/train_images/train_images/70d0392397de.png\n/kaggle/input/aptos2019/train_images/train_images/a47878630dc2.png\n/kaggle/input/aptos2019/train_images/train_images/936299166bea.png\n/kaggle/input/aptos2019/train_images/train_images/6b91e99c9408.png\n/kaggle/input/aptos2019/train_images/train_images/4a0890b08532.png\n/kaggle/input/aptos2019/train_images/train_images/780be525036d.png\n/kaggle/input/aptos2019/train_images/train_images/b7e0f95353f2.png\n/kaggle/input/aptos2019/train_images/train_images/d2cd47ed2c1d.png\n/kaggle/input/aptos2019/train_images/train_images/6efa36d59ada.png\n/kaggle/input/aptos2019/train_images/train_images/a2d349f567a6.png\n/kaggle/input/aptos2019/train_images/train_images/de4cdabbce6d.png\n/kaggle/input/aptos2019/train_images/train_images/929cd3867815.png\n/kaggle/input/aptos2019/train_images/train_images/98f7136d2e7a.png\n/kaggle/input/aptos2019/train_images/train_images/df4913ca3712.png\n/kaggle/input/aptos2019/train_images/train_images/668e853258cd.png\n/kaggle/input/aptos2019/train_images/train_images/dc6fa1b38b83.png\n/kaggle/input/aptos2019/train_images/train_images/cca626a0e19a.png\n/kaggle/input/aptos2019/train_images/train_images/6df8b7b6e837.png\n/kaggle/input/aptos2019/train_images/train_images/3128eb593012.png\n/kaggle/input/aptos2019/train_images/train_images/e42d9a94a66d.png\n/kaggle/input/aptos2019/train_images/train_images/29bc0e721cfe.png\n/kaggle/input/aptos2019/train_images/train_images/b77b88926843.png\n/kaggle/input/aptos2019/train_images/train_images/a790a3b36390.png\n/kaggle/input/aptos2019/train_images/train_images/d85a842d20bd.png\n/kaggle/input/aptos2019/train_images/train_images/b8f1b30877db.png\n/kaggle/input/aptos2019/train_images/train_images/486e852a3b4d.png\n/kaggle/input/aptos2019/train_images/train_images/dfc7ec7db0e0.png\n/kaggle/input/aptos2019/train_images/train_images/ac0a48ccbf70.png\n/kaggle/input/aptos2019/train_images/train_images/4210809074c1.png\n/kaggle/input/aptos2019/train_images/train_images/4cddfc22b0ad.png\n/kaggle/input/aptos2019/train_images/train_images/76cfe8967f7d.png\n/kaggle/input/aptos2019/train_images/train_images/1da4a17c18c9.png\n/kaggle/input/aptos2019/train_images/train_images/e2c3b037413b.png\n/kaggle/input/aptos2019/train_images/train_images/aec51513cf45.png\n/kaggle/input/aptos2019/train_images/train_images/92889b863ae6.png\n/kaggle/input/aptos2019/train_images/train_images/dde43aa22ae6.png\n/kaggle/input/aptos2019/train_images/train_images/c1437a7a52c9.png\n/kaggle/input/aptos2019/train_images/train_images/dee31065f8fe.png\n/kaggle/input/aptos2019/train_images/train_images/5293576816aa.png\n/kaggle/input/aptos2019/train_images/train_images/a3132c8828e4.png\n/kaggle/input/aptos2019/train_images/train_images/c613db1cab27.png\n/kaggle/input/aptos2019/train_images/train_images/4dd7b322f342.png\n/kaggle/input/aptos2019/train_images/train_images/ac5b5dddf91b.png\n/kaggle/input/aptos2019/train_images/train_images/3bf2deaa5ef0.png\n/kaggle/input/aptos2019/train_images/train_images/35ac70c0d08f.png\n/kaggle/input/aptos2019/train_images/train_images/4478b870e549.png\n/kaggle/input/aptos2019/train_images/train_images/9ce46d400cd6.png\n/kaggle/input/aptos2019/train_images/train_images/8c4ceddeb1c6.png\n/kaggle/input/aptos2019/train_images/train_images/be197b663520.png\n/kaggle/input/aptos2019/train_images/train_images/ae1344610ebe.png\n/kaggle/input/aptos2019/train_images/train_images/bdff5d8bddf8.png\n/kaggle/input/aptos2019/train_images/train_images/941d874c8afb.png\n/kaggle/input/aptos2019/train_images/train_images/3cd9713c0ecb.png\n/kaggle/input/aptos2019/train_images/train_images/677f087cd697.png\n/kaggle/input/aptos2019/train_images/train_images/81704925f759.png\n/kaggle/input/aptos2019/train_images/train_images/a93f1ea3ff4a.png\n/kaggle/input/aptos2019/train_images/train_images/1c5ad36fb799.png\n/kaggle/input/aptos2019/train_images/train_images/c0968d41eb93.png\n/kaggle/input/aptos2019/train_images/train_images/a94da3d3b5c0.png\n/kaggle/input/aptos2019/train_images/train_images/8693ab1fd2be.png\n/kaggle/input/aptos2019/train_images/train_images/51cfeccaf40d.png\n/kaggle/input/aptos2019/train_images/train_images/d6803e467592.png\n/kaggle/input/aptos2019/train_images/train_images/e32dc722eca5.png\n/kaggle/input/aptos2019/train_images/train_images/8c29a76fa08c.png\n/kaggle/input/aptos2019/train_images/train_images/a9d0c900b6a9.png\n/kaggle/input/aptos2019/train_images/train_images/53ddae6a619e.png\n/kaggle/input/aptos2019/train_images/train_images/6107a2e9f60e.png\n/kaggle/input/aptos2019/train_images/train_images/d6b109c82067.png\n/kaggle/input/aptos2019/train_images/train_images/5b3d41626ec5.png\n/kaggle/input/aptos2019/train_images/train_images/92587e494d51.png\n/kaggle/input/aptos2019/train_images/train_images/8650d32f4a9e.png\n/kaggle/input/aptos2019/train_images/train_images/217dad18a5ed.png\n/kaggle/input/aptos2019/train_images/train_images/3ac3fbfca7d4.png\n/kaggle/input/aptos2019/train_images/train_images/dec5595e6154.png\n/kaggle/input/aptos2019/train_images/train_images/d5c63a8d9e94.png\n/kaggle/input/aptos2019/train_images/train_images/838b3e4d0bb4.png\n/kaggle/input/aptos2019/train_images/train_images/ad12cde115ab.png\n/kaggle/input/aptos2019/train_images/train_images/3cdef7c591cc.png\n/kaggle/input/aptos2019/train_images/train_images/4c52922f3bfd.png\n/kaggle/input/aptos2019/train_images/train_images/5264a54e1830.png\n/kaggle/input/aptos2019/train_images/train_images/653534ded339.png\n/kaggle/input/aptos2019/train_images/train_images/3f47f83217b5.png\n/kaggle/input/aptos2019/train_images/train_images/4661006f3ba6.png\n/kaggle/input/aptos2019/train_images/train_images/1b495ac025b7.png\n/kaggle/input/aptos2019/train_images/train_images/bf7221a016b5.png\n/kaggle/input/aptos2019/train_images/train_images/ad2f0b9d059c.png\n/kaggle/input/aptos2019/train_images/train_images/6cdd0f985270.png\n/kaggle/input/aptos2019/train_images/train_images/cd29c88c9e36.png\n/kaggle/input/aptos2019/train_images/train_images/b9c7c5182075.png\n/kaggle/input/aptos2019/train_images/train_images/bfdee9be1f1d.png\n/kaggle/input/aptos2019/train_images/train_images/9858cc2ae073.png\n/kaggle/input/aptos2019/train_images/train_images/bb45257258cc.png\n/kaggle/input/aptos2019/train_images/train_images/bf18ff30a8f6.png\n/kaggle/input/aptos2019/train_images/train_images/281d7b7c7676.png\n/kaggle/input/aptos2019/train_images/train_images/62e6f814c8f5.png\n/kaggle/input/aptos2019/train_images/train_images/de2eb5c8aa83.png\n/kaggle/input/aptos2019/train_images/train_images/c6e1e9fbf39b.png\n/kaggle/input/aptos2019/train_images/train_images/7c6594b50690.png\n/kaggle/input/aptos2019/train_images/train_images/93421787f520.png\n/kaggle/input/aptos2019/train_images/train_images/5a179c123fd8.png\n/kaggle/input/aptos2019/train_images/train_images/6baafa56895c.png\n/kaggle/input/aptos2019/train_images/train_images/1e742358e0b9.png\n/kaggle/input/aptos2019/train_images/train_images/7a6495a39d87.png\n/kaggle/input/aptos2019/train_images/train_images/9e99ae6ee7af.png\n/kaggle/input/aptos2019/train_images/train_images/d6dbb0820ea5.png\n/kaggle/input/aptos2019/train_images/train_images/8fc09fecd22f.png\n/kaggle/input/aptos2019/train_images/train_images/4e43d05cc2ef.png\n/kaggle/input/aptos2019/train_images/train_images/5cc6dea19614.png\n/kaggle/input/aptos2019/train_images/train_images/c3aa424eff9a.png\n/kaggle/input/aptos2019/train_images/train_images/bc8c6a778cde.png\n/kaggle/input/aptos2019/train_images/train_images/daad7b617f21.png\n/kaggle/input/aptos2019/train_images/train_images/de38adaae009.png\n/kaggle/input/aptos2019/train_images/train_images/c6c2bad91f23.png\n/kaggle/input/aptos2019/train_images/train_images/6e44f6d04fc9.png\n/kaggle/input/aptos2019/train_images/train_images/6194e0fff071.png\n/kaggle/input/aptos2019/train_images/train_images/8aab201c0691.png\n/kaggle/input/aptos2019/train_images/train_images/c1896142a20a.png\n/kaggle/input/aptos2019/train_images/train_images/3e6bfc4d5c65.png\n/kaggle/input/aptos2019/train_images/train_images/59bd19c1c5bb.png\n/kaggle/input/aptos2019/train_images/train_images/5d3c8c1f57da.png\n/kaggle/input/aptos2019/train_images/train_images/29f44aea93a4.png\n/kaggle/input/aptos2019/train_images/train_images/cc964bf04dbc.png\n/kaggle/input/aptos2019/train_images/train_images/cffc50047828.png\n/kaggle/input/aptos2019/train_images/train_images/8114d6a160df.png\n/kaggle/input/aptos2019/train_images/train_images/66b88a4bc474.png\n/kaggle/input/aptos2019/train_images/train_images/879744b9dc65.png\n/kaggle/input/aptos2019/train_images/train_images/a0fd94e2ad76.png\n/kaggle/input/aptos2019/train_images/train_images/c6a8f8f998a2.png\n/kaggle/input/aptos2019/train_images/train_images/2c2aa057afc5.png\n/kaggle/input/aptos2019/train_images/train_images/1ca62b3e4fd3.png\n/kaggle/input/aptos2019/train_images/train_images/bc34f52c37c7.png\n/kaggle/input/aptos2019/train_images/train_images/cd93a472e5cd.png\n/kaggle/input/aptos2019/train_images/train_images/a15652b22ab8.png\n/kaggle/input/aptos2019/train_images/train_images/523b3f0fc646.png\n/kaggle/input/aptos2019/train_images/train_images/42b93b574f23.png\n/kaggle/input/aptos2019/train_images/train_images/2a099b247b10.png\n/kaggle/input/aptos2019/train_images/train_images/384e6c915722.png\n/kaggle/input/aptos2019/train_images/train_images/599b89048034.png\n/kaggle/input/aptos2019/train_images/train_images/96b5474ae604.png\n/kaggle/input/aptos2019/train_images/train_images/ab78a66dee6a.png\n/kaggle/input/aptos2019/train_images/train_images/32d7d360d891.png\n/kaggle/input/aptos2019/train_images/train_images/51269b77d312.png\n/kaggle/input/aptos2019/train_images/train_images/8e2a3978c244.png\n/kaggle/input/aptos2019/train_images/train_images/5bf3357a2823.png\n/kaggle/input/aptos2019/train_images/train_images/a528be013a04.png\n/kaggle/input/aptos2019/train_images/train_images/7b211d8bd249.png\n/kaggle/input/aptos2019/train_images/train_images/9e2ba2b979f1.png\n/kaggle/input/aptos2019/train_images/train_images/3c72f580d4ba.png\n/kaggle/input/aptos2019/train_images/train_images/bb733062f494.png\n/kaggle/input/aptos2019/train_images/train_images/d67374d3fa2a.png\n/kaggle/input/aptos2019/train_images/train_images/32a3eb37ff40.png\n/kaggle/input/aptos2019/train_images/train_images/a07efb1ecfc0.png\n/kaggle/input/aptos2019/train_images/train_images/1d0b93317aa8.png\n/kaggle/input/aptos2019/train_images/train_images/3b4a5fcbe5e0.png\n/kaggle/input/aptos2019/train_images/train_images/9232dc06cfdc.png\n/kaggle/input/aptos2019/train_images/train_images/d9e58e4d8689.png\n/kaggle/input/aptos2019/train_images/train_images/d4583e9525dc.png\n/kaggle/input/aptos2019/train_images/train_images/9688c6ef5dc5.png\n/kaggle/input/aptos2019/train_images/train_images/4fecf87184e6.png\n/kaggle/input/aptos2019/train_images/train_images/2b2f5a0f880d.png\n/kaggle/input/aptos2019/train_images/train_images/237c078d00fc.png\n/kaggle/input/aptos2019/train_images/train_images/384631079d1e.png\n/kaggle/input/aptos2019/train_images/train_images/af831c158744.png\n/kaggle/input/aptos2019/train_images/train_images/357f02a779d7.png\n/kaggle/input/aptos2019/train_images/train_images/4464bb62bf20.png\n/kaggle/input/aptos2019/train_images/train_images/aea59ebec445.png\n/kaggle/input/aptos2019/train_images/train_images/bf7b4eae7ad0.png\n/kaggle/input/aptos2019/train_images/train_images/1e1fb019710d.png\n/kaggle/input/aptos2019/train_images/train_images/2a5a8b744f08.png\n/kaggle/input/aptos2019/train_images/train_images/757572337fd0.png\n/kaggle/input/aptos2019/train_images/train_images/d48178e4a49b.png\n/kaggle/input/aptos2019/train_images/train_images/4f0866b90c27.png\n/kaggle/input/aptos2019/train_images/train_images/35df2bc6ae95.png\n/kaggle/input/aptos2019/train_images/train_images/9568eb7e9c08.png\n/kaggle/input/aptos2019/train_images/train_images/c561bcd519e9.png\n/kaggle/input/aptos2019/train_images/train_images/bd5013540a13.png\n/kaggle/input/aptos2019/train_images/train_images/b1b3e7d0a5f3.png\n/kaggle/input/aptos2019/train_images/train_images/67ed8cc78b97.png\n/kaggle/input/aptos2019/train_images/train_images/c5b58cc992af.png\n/kaggle/input/aptos2019/train_images/train_images/665ce639a331.png\n/kaggle/input/aptos2019/train_images/train_images/4d1cf360b2d7.png\n/kaggle/input/aptos2019/train_images/train_images/4aa07d720638.png\n/kaggle/input/aptos2019/train_images/train_images/686ed1dbae20.png\n/kaggle/input/aptos2019/train_images/train_images/8db2ce991101.png\n/kaggle/input/aptos2019/train_images/train_images/83fda7c0500b.png\n/kaggle/input/aptos2019/train_images/train_images/6a91eb157f47.png\n/kaggle/input/aptos2019/train_images/train_images/4c9f0fdaaef7.png\n/kaggle/input/aptos2019/train_images/train_images/d1fb4efb117c.png\n/kaggle/input/aptos2019/train_images/train_images/6f0463c1ff18.png\n/kaggle/input/aptos2019/train_images/train_images/94f9ecf4b8d2.png\n/kaggle/input/aptos2019/train_images/train_images/54dc6e8107cd.png\n/kaggle/input/aptos2019/train_images/train_images/7214fc7cbe03.png\n/kaggle/input/aptos2019/train_images/train_images/5c817060c0ed.png\n/kaggle/input/aptos2019/train_images/train_images/b085caa513a8.png\n/kaggle/input/aptos2019/train_images/train_images/962cf85e4f6d.png\n/kaggle/input/aptos2019/train_images/train_images/2f2e1949ad56.png\n/kaggle/input/aptos2019/train_images/train_images/8bad12d70368.png\n/kaggle/input/aptos2019/train_images/train_images/8a7765e785fb.png\n/kaggle/input/aptos2019/train_images/train_images/674057ab250c.png\n/kaggle/input/aptos2019/train_images/train_images/5baed382f062.png\n/kaggle/input/aptos2019/train_images/train_images/83e529e95b0e.png\n/kaggle/input/aptos2019/train_images/train_images/6de39b94f634.png\n/kaggle/input/aptos2019/train_images/train_images/9b95d6203406.png\n/kaggle/input/aptos2019/train_images/train_images/cb2201c226d6.png\n/kaggle/input/aptos2019/train_images/train_images/65f69234c8a7.png\n/kaggle/input/aptos2019/train_images/train_images/d844a7252f4e.png\n/kaggle/input/aptos2019/train_images/train_images/bff51afc76d4.png\n/kaggle/input/aptos2019/train_images/train_images/69fff98cb32a.png\n/kaggle/input/aptos2019/train_images/train_images/c80b0f27541a.png\n/kaggle/input/aptos2019/train_images/train_images/cfb17a7cc8d4.png\n/kaggle/input/aptos2019/train_images/train_images/c1799a6f5c65.png\n/kaggle/input/aptos2019/train_images/train_images/594f69b503ad.png\n/kaggle/input/aptos2019/train_images/train_images/1da25637859b.png\n/kaggle/input/aptos2019/train_images/train_images/291e2ff3d834.png\n/kaggle/input/aptos2019/train_images/train_images/1cc58b15f466.png\n/kaggle/input/aptos2019/train_images/train_images/b22354b5f94b.png\n/kaggle/input/aptos2019/train_images/train_images/3c311c9109b0.png\n/kaggle/input/aptos2019/train_images/train_images/498f143c0374.png\n/kaggle/input/aptos2019/train_images/train_images/bb08949dd70a.png\n/kaggle/input/aptos2019/train_images/train_images/3ee4841936ef.png\n/kaggle/input/aptos2019/train_images/train_images/384db24ebbd7.png\n/kaggle/input/aptos2019/train_images/train_images/aafe980edd0c.png\n/kaggle/input/aptos2019/train_images/train_images/5f51192841f7.png\n/kaggle/input/aptos2019/train_images/train_images/70f5caf5f305.png\n/kaggle/input/aptos2019/train_images/train_images/a247961a5cd9.png\n/kaggle/input/aptos2019/train_images/train_images/d141728fa392.png\n/kaggle/input/aptos2019/train_images/train_images/6e3526053de0.png\n/kaggle/input/aptos2019/train_images/train_images/29d059522fa1.png\n/kaggle/input/aptos2019/train_images/train_images/38c7153457e2.png\n/kaggle/input/aptos2019/train_images/train_images/6a2642131e4a.png\n/kaggle/input/aptos2019/train_images/train_images/b74de20d73de.png\n/kaggle/input/aptos2019/train_images/train_images/28f73575e1f2.png\n/kaggle/input/aptos2019/train_images/train_images/8ef2eb8c51c4.png\n/kaggle/input/aptos2019/train_images/train_images/38fe9f854046.png\n/kaggle/input/aptos2019/train_images/train_images/8d7bb0649a02.png\n/kaggle/input/aptos2019/train_images/train_images/e4210e7fe587.png\n/kaggle/input/aptos2019/train_images/train_images/7005be54cab1.png\n/kaggle/input/aptos2019/train_images/train_images/4c78d9d18da9.png\n/kaggle/input/aptos2019/train_images/train_images/51a078d6d43a.png\n/kaggle/input/aptos2019/train_images/train_images/9c514d2d5b3f.png\n/kaggle/input/aptos2019/train_images/train_images/7c52fe73e748.png\n/kaggle/input/aptos2019/train_images/train_images/22ce8ef69357.png\n/kaggle/input/aptos2019/train_images/train_images/26cd40b57ad1.png\n/kaggle/input/aptos2019/train_images/train_images/4f5dd7660b17.png\n/kaggle/input/aptos2019/train_images/train_images/aad0c0ee9268.png\n/kaggle/input/aptos2019/train_images/train_images/966c07831334.png\n/kaggle/input/aptos2019/train_images/train_images/b3d12069e1c5.png\n/kaggle/input/aptos2019/train_images/train_images/7335a2d43ada.png\n/kaggle/input/aptos2019/train_images/train_images/cff262ed8f4c.png\n/kaggle/input/aptos2019/train_images/train_images/9837048b85dc.png\n/kaggle/input/aptos2019/train_images/train_images/887c26fc0e1f.png\n/kaggle/input/aptos2019/train_images/train_images/8191ae701985.png\n/kaggle/input/aptos2019/train_images/train_images/a1edf0e66592.png\n/kaggle/input/aptos2019/train_images/train_images/4fd5ec0dca09.png\n/kaggle/input/aptos2019/train_images/train_images/5a2c27b95c7c.png\n/kaggle/input/aptos2019/train_images/train_images/5188a8afa879.png\n/kaggle/input/aptos2019/train_images/train_images/77f69c7ff324.png\n/kaggle/input/aptos2019/train_images/train_images/8be6629a6039.png\n/kaggle/input/aptos2019/train_images/train_images/484dbeb9bf2a.png\n/kaggle/input/aptos2019/train_images/train_images/ce887b196c23.png\n/kaggle/input/aptos2019/train_images/train_images/63b4d030b016.png\n/kaggle/input/aptos2019/train_images/train_images/599498e9e4bc.png\n/kaggle/input/aptos2019/train_images/train_images/d473f6fafba0.png\n/kaggle/input/aptos2019/train_images/train_images/3a6e9730b298.png\n/kaggle/input/aptos2019/train_images/train_images/4860f7813654.png\n/kaggle/input/aptos2019/train_images/train_images/77e7c7a160c8.png\n/kaggle/input/aptos2019/train_images/train_images/9095d43fb132.png\n/kaggle/input/aptos2019/train_images/train_images/a3b2e93d058b.png\n/kaggle/input/aptos2019/train_images/train_images/84e8c62165b5.png\n/kaggle/input/aptos2019/train_images/train_images/d838d5b9f571.png\n/kaggle/input/aptos2019/train_images/train_images/a06e5ac695ce.png\n/kaggle/input/aptos2019/train_images/train_images/d8404680bba6.png\n/kaggle/input/aptos2019/train_images/train_images/71c1a3cdbe47.png\n/kaggle/input/aptos2019/train_images/train_images/98fbe56dcc2c.png\n/kaggle/input/aptos2019/train_images/train_images/8688f3d0fcaf.png\n/kaggle/input/aptos2019/train_images/train_images/66d2ca47aa44.png\n/kaggle/input/aptos2019/train_images/train_images/6d9effbcde78.png\n/kaggle/input/aptos2019/train_images/train_images/ad93d88c87ea.png\n/kaggle/input/aptos2019/train_images/train_images/a9e3d186cd1b.png\n/kaggle/input/aptos2019/train_images/train_images/cf603a9ef2d5.png\n/kaggle/input/aptos2019/train_images/train_images/d3de0d313d61.png\n/kaggle/input/aptos2019/train_images/train_images/44f4ae58990e.png\n/kaggle/input/aptos2019/train_images/train_images/35777eb7859d.png\n/kaggle/input/aptos2019/train_images/train_images/7be1b9aa78aa.png\n/kaggle/input/aptos2019/train_images/train_images/5db895d3f1fc.png\n/kaggle/input/aptos2019/train_images/train_images/2f42e20db938.png\n/kaggle/input/aptos2019/train_images/train_images/45ae04cfde5d.png\n/kaggle/input/aptos2019/train_images/train_images/da3a2275c850.png\n/kaggle/input/aptos2019/train_images/train_images/8860c7b11530.png\n/kaggle/input/aptos2019/train_images/train_images/6c00dd8bf708.png\n/kaggle/input/aptos2019/train_images/train_images/2ecbc2e3f239.png\n/kaggle/input/aptos2019/train_images/train_images/a443c4fd489c.png\n/kaggle/input/aptos2019/train_images/train_images/495255c7492f.png\n/kaggle/input/aptos2019/train_images/train_images/6e092b306fe1.png\n/kaggle/input/aptos2019/train_images/train_images/6762b2b48ea5.png\n/kaggle/input/aptos2019/train_images/train_images/d28bd830c171.png\n/kaggle/input/aptos2019/train_images/train_images/5b5b80a3edee.png\n/kaggle/input/aptos2019/train_images/train_images/d18f6431ebce.png\n/kaggle/input/aptos2019/train_images/train_images/aae8f9f3ef8c.png\n/kaggle/input/aptos2019/train_images/train_images/a34fc5376669.png\n/kaggle/input/aptos2019/train_images/train_images/57a5e4274275.png\n/kaggle/input/aptos2019/train_images/train_images/650104ede84c.png\n/kaggle/input/aptos2019/train_images/train_images/260a455692b5.png\n/kaggle/input/aptos2019/train_images/train_images/75a4343b12f9.png\n/kaggle/input/aptos2019/train_images/train_images/8543a801dce0.png\n/kaggle/input/aptos2019/train_images/train_images/95e732e043a1.png\n/kaggle/input/aptos2019/train_images/train_images/87b671c6d4c5.png\n/kaggle/input/aptos2019/train_images/train_images/33d72035c27a.png\n/kaggle/input/aptos2019/train_images/train_images/89b725411cee.png\n/kaggle/input/aptos2019/train_images/train_images/234399352d36.png\n/kaggle/input/aptos2019/train_images/train_images/612f2df37a1d.png\n/kaggle/input/aptos2019/train_images/train_images/33105f9b3a04.png\n/kaggle/input/aptos2019/train_images/train_images/3428230bf1bd.png\n/kaggle/input/aptos2019/train_images/train_images/8b58f9a338e8.png\n/kaggle/input/aptos2019/train_images/train_images/6a2c3f4ef329.png\n/kaggle/input/aptos2019/train_images/train_images/4a4cb731f91a.png\n/kaggle/input/aptos2019/train_images/train_images/94372043d55b.png\n/kaggle/input/aptos2019/train_images/train_images/99c626e58464.png\n/kaggle/input/aptos2019/train_images/train_images/c5bec7f1e5f3.png\n/kaggle/input/aptos2019/train_images/train_images/9782c0489eca.png\n/kaggle/input/aptos2019/train_images/train_images/2241b7e90782.png\n/kaggle/input/aptos2019/train_images/train_images/3dfc50108072.png\n/kaggle/input/aptos2019/train_images/train_images/39fd8ef3a45c.png\n/kaggle/input/aptos2019/train_images/train_images/496155f71d0a.png\n/kaggle/input/aptos2019/train_images/train_images/bfaa0080ab61.png\n/kaggle/input/aptos2019/train_images/train_images/76b950c6ed5e.png\n/kaggle/input/aptos2019/train_images/train_images/b963a11638f2.png\n/kaggle/input/aptos2019/train_images/train_images/996f57c86ba5.png\n/kaggle/input/aptos2019/train_images/train_images/247e98aba610.png\n/kaggle/input/aptos2019/train_images/train_images/a01c590c444f.png\n/kaggle/input/aptos2019/train_images/train_images/4029d70e9d8a.png\n/kaggle/input/aptos2019/train_images/train_images/6165081b9021.png\n/kaggle/input/aptos2019/train_images/train_images/4ad8d3ec8789.png\n/kaggle/input/aptos2019/train_images/train_images/2cacdb0dffae.png\n/kaggle/input/aptos2019/train_images/train_images/d803598dabda.png\n/kaggle/input/aptos2019/train_images/train_images/4384fa687afa.png\n/kaggle/input/aptos2019/train_images/train_images/47b756014447.png\n/kaggle/input/aptos2019/train_images/train_images/c5ad60521f8c.png\n/kaggle/input/aptos2019/train_images/train_images/870fbe6eaa68.png\n/kaggle/input/aptos2019/train_images/train_images/44a86263117b.png\n/kaggle/input/aptos2019/train_images/train_images/4927945ecfed.png\n/kaggle/input/aptos2019/train_images/train_images/7131bf4c9e6f.png\n/kaggle/input/aptos2019/train_images/train_images/d6e26fe51dce.png\n/kaggle/input/aptos2019/train_images/train_images/70ed3ec68b94.png\n/kaggle/input/aptos2019/train_images/train_images/cd4e7f9fa1a9.png\n/kaggle/input/aptos2019/train_images/train_images/d3e56584a481.png\n/kaggle/input/aptos2019/train_images/train_images/a9a3225cf4b5.png\n/kaggle/input/aptos2019/train_images/train_images/e1900014dabf.png\n/kaggle/input/aptos2019/train_images/train_images/ca9c912ebad7.png\n/kaggle/input/aptos2019/train_images/train_images/2776d70724d3.png\n/kaggle/input/aptos2019/train_images/train_images/1dfe599d12a9.png\n/kaggle/input/aptos2019/train_images/train_images/c1c8550508e0.png\n/kaggle/input/aptos2019/train_images/train_images/a646c084928c.png\n/kaggle/input/aptos2019/train_images/train_images/a8e08e7fe016.png\n/kaggle/input/aptos2019/train_images/train_images/1caba2fb38f6.png\n/kaggle/input/aptos2019/train_images/train_images/1f31701dd61b.png\n/kaggle/input/aptos2019/train_images/train_images/beeca5f14618.png\n/kaggle/input/aptos2019/train_images/train_images/2f81ee5f2926.png\n/kaggle/input/aptos2019/train_images/train_images/58529a8638d0.png\n/kaggle/input/aptos2019/train_images/train_images/51d574513bcb.png\n/kaggle/input/aptos2019/train_images/train_images/8329e80c10ac.png\n/kaggle/input/aptos2019/train_images/train_images/6653ad026901.png\n/kaggle/input/aptos2019/train_images/train_images/6180920bc224.png\n/kaggle/input/aptos2019/train_images/train_images/3b9817a39adf.png\n/kaggle/input/aptos2019/train_images/train_images/78b3f819dcc5.png\n/kaggle/input/aptos2019/train_images/train_images/3823acc4e464.png\n/kaggle/input/aptos2019/train_images/train_images/3b10191dfd25.png\n/kaggle/input/aptos2019/train_images/train_images/d2c2f02bb313.png\n/kaggle/input/aptos2019/train_images/train_images/46d3316c4857.png\n/kaggle/input/aptos2019/train_images/train_images/c0e509786f7f.png\n/kaggle/input/aptos2019/train_images/train_images/b60dbf9f0744.png\n/kaggle/input/aptos2019/train_images/train_images/7350c50667c5.png\n/kaggle/input/aptos2019/train_images/train_images/bf6cbccacf39.png\n/kaggle/input/aptos2019/train_images/train_images/b06dabab4f09.png\n/kaggle/input/aptos2019/train_images/train_images/e087bd4b88f2.png\n/kaggle/input/aptos2019/train_images/train_images/b4f41b5bf0ef.png\n/kaggle/input/aptos2019/train_images/train_images/b086c7cd3868.png\n/kaggle/input/aptos2019/train_images/train_images/352e4a939242.png\n/kaggle/input/aptos2019/train_images/train_images/85cbb84ac8e0.png\n/kaggle/input/aptos2019/train_images/train_images/b16dd4483ca5.png\n/kaggle/input/aptos2019/train_images/train_images/5b804948e35f.png\n/kaggle/input/aptos2019/train_images/train_images/b89938407ee6.png\n/kaggle/input/aptos2019/train_images/train_images/5cbe88914a72.png\n/kaggle/input/aptos2019/train_images/train_images/d2d523e9f669.png\n/kaggle/input/aptos2019/train_images/train_images/e06cccc08c59.png\n/kaggle/input/aptos2019/train_images/train_images/22325552a4e3.png\n/kaggle/input/aptos2019/train_images/train_images/96793edb1003.png\n/kaggle/input/aptos2019/train_images/train_images/57a5f1015504.png\n/kaggle/input/aptos2019/train_images/train_images/962c0fc85e13.png\n/kaggle/input/aptos2019/train_images/train_images/73ba798fee25.png\n/kaggle/input/aptos2019/train_images/train_images/1df1530b9b8d.png\n/kaggle/input/aptos2019/train_images/train_images/31cb39681f6a.png\n/kaggle/input/aptos2019/train_images/train_images/daeaa5d8cf70.png\n/kaggle/input/aptos2019/train_images/train_images/5dc23e440de3.png\n/kaggle/input/aptos2019/train_images/train_images/a2ad3da4c7d6.png\n/kaggle/input/aptos2019/train_images/train_images/91cbe1c775ef.png\n/kaggle/input/aptos2019/train_images/train_images/48a45619d1a3.png\n/kaggle/input/aptos2019/train_images/train_images/cd314653a4d8.png\n/kaggle/input/aptos2019/train_images/train_images/6fe4751a3b42.png\n/kaggle/input/aptos2019/train_images/train_images/cd941e5bc659.png\n/kaggle/input/aptos2019/train_images/train_images/33e7bf536fc5.png\n/kaggle/input/aptos2019/train_images/train_images/c62cef02efa2.png\n/kaggle/input/aptos2019/train_images/train_images/3a1d3ce00f0c.png\n/kaggle/input/aptos2019/train_images/train_images/ac17cc18a994.png\n/kaggle/input/aptos2019/train_images/train_images/4a213b405ee4.png\n/kaggle/input/aptos2019/train_images/train_images/7f0ffeb0a333.png\n/kaggle/input/aptos2019/train_images/train_images/57a710de68a4.png\n/kaggle/input/aptos2019/train_images/train_images/e1b8acb1cea1.png\n/kaggle/input/aptos2019/train_images/train_images/89d2a7403a06.png\n/kaggle/input/aptos2019/train_images/train_images/454a944eb557.png\n/kaggle/input/aptos2019/train_images/train_images/abe940882578.png\n/kaggle/input/aptos2019/train_images/train_images/90960ddf4d14.png\n/kaggle/input/aptos2019/train_images/train_images/a45c30da0c72.png\n/kaggle/input/aptos2019/train_images/train_images/cf0824f53dd9.png\n/kaggle/input/aptos2019/train_images/train_images/d39752cb6e57.png\n/kaggle/input/aptos2019/train_images/train_images/9859e2a6cc24.png\n/kaggle/input/aptos2019/train_images/train_images/d83d0695e215.png\n/kaggle/input/aptos2019/train_images/train_images/dee687c6e88a.png\n/kaggle/input/aptos2019/train_images/train_images/25e9fd872182.png\n/kaggle/input/aptos2019/train_images/train_images/453d553b0a94.png\n/kaggle/input/aptos2019/train_images/train_images/1bb0ddfe753a.png\n/kaggle/input/aptos2019/train_images/train_images/7663aba8d762.png\n/kaggle/input/aptos2019/train_images/train_images/d866c26d76f0.png\n/kaggle/input/aptos2019/train_images/train_images/2a08ed6bbcbc.png\n/kaggle/input/aptos2019/train_images/train_images/cac80797770f.png\n/kaggle/input/aptos2019/train_images/train_images/7270367410a1.png\n/kaggle/input/aptos2019/train_images/train_images/4fef9ed8a4c5.png\n/kaggle/input/aptos2019/train_images/train_images/a8eb35b3bcd2.png\n/kaggle/input/aptos2019/train_images/train_images/5ca779ace6e7.png\n/kaggle/input/aptos2019/train_images/train_images/974c7d7b9c64.png\n/kaggle/input/aptos2019/train_images/train_images/6298468d7d75.png\n/kaggle/input/aptos2019/train_images/train_images/5cde55f745af.png\n/kaggle/input/aptos2019/train_images/train_images/4c6c5a1bf5ab.png\n/kaggle/input/aptos2019/train_images/train_images/482088e6be44.png\n/kaggle/input/aptos2019/train_images/train_images/4246ed634f25.png\n/kaggle/input/aptos2019/train_images/train_images/94a67ec0714f.png\n/kaggle/input/aptos2019/train_images/train_images/aa6673241154.png\n/kaggle/input/aptos2019/train_images/train_images/9041eb43456e.png\n/kaggle/input/aptos2019/train_images/train_images/27bab1432f61.png\n/kaggle/input/aptos2019/train_images/train_images/9a7bd084395e.png\n/kaggle/input/aptos2019/train_images/train_images/b7ce561a7328.png\n/kaggle/input/aptos2019/train_images/train_images/8f9819752ca0.png\n/kaggle/input/aptos2019/train_images/train_images/b92eacd1392a.png\n/kaggle/input/aptos2019/train_images/train_images/d9ad2a0ec026.png\n/kaggle/input/aptos2019/train_images/train_images/2cceb07ff706.png\n/kaggle/input/aptos2019/train_images/train_images/4dbce359d0e1.png\n/kaggle/input/aptos2019/train_images/train_images/5a0fe0ee4301.png\n/kaggle/input/aptos2019/train_images/train_images/4a44cc840ebe.png\n/kaggle/input/aptos2019/train_images/train_images/535682537302.png\n/kaggle/input/aptos2019/train_images/train_images/4d009cebabc9.png\n/kaggle/input/aptos2019/train_images/train_images/405b4f78658f.png\n/kaggle/input/aptos2019/train_images/train_images/d30d079e6f9a.png\n/kaggle/input/aptos2019/train_images/train_images/5a5d3798c357.png\n/kaggle/input/aptos2019/train_images/train_images/1ee355480567.png\n/kaggle/input/aptos2019/train_images/train_images/c6a2975228af.png\n/kaggle/input/aptos2019/train_images/train_images/276b14f72328.png\n/kaggle/input/aptos2019/train_images/train_images/210bfe0127c6.png\n/kaggle/input/aptos2019/train_images/train_images/86e7f98f73f1.png\n/kaggle/input/aptos2019/train_images/train_images/b77b8a1f09f1.png\n/kaggle/input/aptos2019/train_images/train_images/37de05ef12a5.png\n/kaggle/input/aptos2019/train_images/train_images/91e8af9ceee9.png\n/kaggle/input/aptos2019/train_images/train_images/4c53cc97ea13.png\n/kaggle/input/aptos2019/train_images/train_images/b187b3c93afb.png\n/kaggle/input/aptos2019/train_images/train_images/c9d42d7534e0.png\n/kaggle/input/aptos2019/train_images/train_images/71f6a6e4620a.png\n/kaggle/input/aptos2019/train_images/train_images/44855f666225.png\n/kaggle/input/aptos2019/train_images/train_images/7fe7309d0b4f.png\n/kaggle/input/aptos2019/train_images/train_images/bc73ce76ec43.png\n/kaggle/input/aptos2019/train_images/train_images/300305ce82d2.png\n/kaggle/input/aptos2019/train_images/train_images/253e96488cfb.png\n/kaggle/input/aptos2019/train_images/train_images/6c6505a0c637.png\n/kaggle/input/aptos2019/train_images/train_images/e4151feb8443.png\n/kaggle/input/aptos2019/train_images/train_images/6c9c902a97de.png\n/kaggle/input/aptos2019/train_images/train_images/a02dfd67a925.png\n/kaggle/input/aptos2019/train_images/train_images/5c6194562ed2.png\n/kaggle/input/aptos2019/train_images/train_images/7a12f49e29df.png\n/kaggle/input/aptos2019/train_images/train_images/b99794a0beed.png\n/kaggle/input/aptos2019/train_images/train_images/e3e490babc0c.png\n/kaggle/input/aptos2019/train_images/train_images/b55d2ddb3e75.png\n/kaggle/input/aptos2019/train_images/train_images/42985aa2e32f.png\n/kaggle/input/aptos2019/train_images/train_images/23175b7ef453.png\n/kaggle/input/aptos2019/train_images/train_images/bde1063a5dd7.png\n/kaggle/input/aptos2019/train_images/train_images/c013e869acce.png\n/kaggle/input/aptos2019/train_images/train_images/4eaf2f81819d.png\n/kaggle/input/aptos2019/train_images/train_images/e04f3c6619a3.png\n/kaggle/input/aptos2019/train_images/train_images/8a81f62320d6.png\n/kaggle/input/aptos2019/train_images/train_images/2a7373eeb352.png\n/kaggle/input/aptos2019/train_images/train_images/54bdcdecd8f3.png\n/kaggle/input/aptos2019/train_images/train_images/5633ced07d8e.png\n/kaggle/input/aptos2019/train_images/train_images/4bd5d0b30198.png\n/kaggle/input/aptos2019/train_images/train_images/90a786abe58e.png\n/kaggle/input/aptos2019/train_images/train_images/d26bc6e1230d.png\n/kaggle/input/aptos2019/train_images/train_images/ab03d50bba2f.png\n/kaggle/input/aptos2019/train_images/train_images/6a57a3db3eff.png\n/kaggle/input/aptos2019/train_images/train_images/93802d1e3c41.png\n/kaggle/input/aptos2019/train_images/train_images/91e82fe4e434.png\n/kaggle/input/aptos2019/train_images/train_images/aa10a4b2e709.png\n/kaggle/input/aptos2019/train_images/train_images/7f84284598f5.png\n/kaggle/input/aptos2019/train_images/train_images/5ce5eeaf757a.png\n/kaggle/input/aptos2019/train_images/train_images/4a96c28f3f07.png\n/kaggle/input/aptos2019/train_images/train_images/94b1d8ad35ec.png\n/kaggle/input/aptos2019/train_images/train_images/6089fa333013.png\n/kaggle/input/aptos2019/train_images/train_images/de6210f88536.png\n/kaggle/input/aptos2019/train_images/train_images/2b3a4a81d748.png\n/kaggle/input/aptos2019/train_images/train_images/e31c42a8652b.png\n/kaggle/input/aptos2019/train_images/train_images/873dcc0b468f.png\n/kaggle/input/aptos2019/train_images/train_images/7bf981d9c7fe.png\n/kaggle/input/aptos2019/train_images/train_images/dce73d90c00c.png\n/kaggle/input/aptos2019/train_images/train_images/1f4fb37e0854.png\n/kaggle/input/aptos2019/train_images/train_images/80964d8e0863.png\n/kaggle/input/aptos2019/train_images/train_images/ae49cc60f251.png\n/kaggle/input/aptos2019/train_images/train_images/a76b69e443ce.png\n/kaggle/input/aptos2019/train_images/train_images/25b4080f598b.png\n/kaggle/input/aptos2019/train_images/train_images/8871e6a26596.png\n/kaggle/input/aptos2019/train_images/train_images/2b074afdf626.png\n/kaggle/input/aptos2019/train_images/train_images/94076a9fb9b5.png\n/kaggle/input/aptos2019/train_images/train_images/d5ad3362424c.png\n/kaggle/input/aptos2019/train_images/train_images/97f290d31813.png\n/kaggle/input/aptos2019/train_images/train_images/de18071c36e6.png\n/kaggle/input/aptos2019/train_images/train_images/1ffaa51a6245.png\n/kaggle/input/aptos2019/train_images/train_images/dd3dad6ca78f.png\n/kaggle/input/aptos2019/train_images/train_images/784d6d302f98.png\n/kaggle/input/aptos2019/train_images/train_images/be521870a0ea.png\n/kaggle/input/aptos2019/train_images/train_images/40527a5e95dd.png\n/kaggle/input/aptos2019/train_images/train_images/d66ccb75ada1.png\n/kaggle/input/aptos2019/train_images/train_images/5ead17e894ae.png\n/kaggle/input/aptos2019/train_images/train_images/789434d095d1.png\n/kaggle/input/aptos2019/train_images/train_images/c70d09370109.png\n/kaggle/input/aptos2019/train_images/train_images/851e40a21f81.png\n/kaggle/input/aptos2019/train_images/train_images/b46b09a45f39.png\n/kaggle/input/aptos2019/train_images/train_images/aa94cc4bfd84.png\n/kaggle/input/aptos2019/train_images/train_images/2f143453bb71.png\n/kaggle/input/aptos2019/train_images/train_images/9c088d2d1559.png\n/kaggle/input/aptos2019/train_images/train_images/38487e1a5b1f.png\n/kaggle/input/aptos2019/train_images/train_images/84a72e15b23c.png\n/kaggle/input/aptos2019/train_images/train_images/274f4de2a59d.png\n/kaggle/input/aptos2019/train_images/train_images/9b093fe95d6b.png\n/kaggle/input/aptos2019/train_images/train_images/bfd5c0e55420.png\n/kaggle/input/aptos2019/train_images/train_images/de55ed25e0e8.png\n/kaggle/input/aptos2019/train_images/train_images/6b30767595d8.png\n/kaggle/input/aptos2019/train_images/train_images/65e6f1bd9875.png\n/kaggle/input/aptos2019/train_images/train_images/8af6a4e5396f.png\n/kaggle/input/aptos2019/train_images/train_images/c7b622ec8104.png\n/kaggle/input/aptos2019/train_images/train_images/613028ede6a0.png\n/kaggle/input/aptos2019/train_images/train_images/393fa5a023a5.png\n/kaggle/input/aptos2019/train_images/train_images/457c7c927e27.png\n/kaggle/input/aptos2019/train_images/train_images/beb00fa6e7c9.png\n/kaggle/input/aptos2019/train_images/train_images/24b87f744598.png\n/kaggle/input/aptos2019/train_images/train_images/3a61e690f4bb.png\n/kaggle/input/aptos2019/train_images/train_images/91e2c2890c9f.png\n/kaggle/input/aptos2019/train_images/train_images/d667af5742f6.png\n/kaggle/input/aptos2019/train_images/train_images/8676427e4625.png\n/kaggle/input/aptos2019/train_images/train_images/1f3f32efaf20.png\n/kaggle/input/aptos2019/train_images/train_images/66375b3c64db.png\n/kaggle/input/aptos2019/train_images/train_images/70d657f8f503.png\n/kaggle/input/aptos2019/train_images/train_images/26fc2358a38d.png\n/kaggle/input/aptos2019/train_images/train_images/232549883508.png\n/kaggle/input/aptos2019/train_images/train_images/e3b47ed5b511.png\n/kaggle/input/aptos2019/train_images/train_images/21037f5c7790.png\n/kaggle/input/aptos2019/train_images/train_images/cac40227d3b2.png\n/kaggle/input/aptos2019/train_images/train_images/d10ef306996b.png\n/kaggle/input/aptos2019/train_images/train_images/76c0c7e1b6cb.png\n/kaggle/input/aptos2019/train_images/train_images/8c87bd748996.png\n/kaggle/input/aptos2019/train_images/train_images/6c315ad3d07f.png\n/kaggle/input/aptos2019/train_images/train_images/9e2a8135f471.png\n/kaggle/input/aptos2019/train_images/train_images/4a693dd3921a.png\n/kaggle/input/aptos2019/train_images/train_images/b0c9a492e068.png\n/kaggle/input/aptos2019/train_images/train_images/99e8bf998285.png\n/kaggle/input/aptos2019/train_images/train_images/5056fa7d505f.png\n/kaggle/input/aptos2019/train_images/train_images/4205e9deb058.png\n/kaggle/input/aptos2019/train_images/train_images/4ce74e5eb51d.png\n/kaggle/input/aptos2019/train_images/train_images/bcdc8db5423b.png\n/kaggle/input/aptos2019/train_images/train_images/a6731dd737af.png\n/kaggle/input/aptos2019/train_images/train_images/763ad1236efe.png\n/kaggle/input/aptos2019/train_images/train_images/9e3510963315.png\n/kaggle/input/aptos2019/train_images/train_images/b7aca95b97b9.png\n/kaggle/input/aptos2019/train_images/train_images/3c1efa38d0da.png\n/kaggle/input/aptos2019/train_images/train_images/a8e88d4891c4.png\n/kaggle/input/aptos2019/train_images/train_images/b43440c6ebe4.png\n/kaggle/input/aptos2019/train_images/train_images/24f271c87e73.png\n/kaggle/input/aptos2019/train_images/train_images/6d10709053ae.png\n/kaggle/input/aptos2019/train_images/train_images/d2c5fb82fe5f.png\n/kaggle/input/aptos2019/train_images/train_images/d88c4843aec3.png\n/kaggle/input/aptos2019/train_images/train_images/43f22d1be8dd.png\n/kaggle/input/aptos2019/train_images/train_images/bed8296c8dfe.png\n/kaggle/input/aptos2019/train_images/train_images/4c60b10a3a6a.png\n/kaggle/input/aptos2019/train_images/train_images/7a0cff4c24b2.png\n/kaggle/input/aptos2019/train_images/train_images/c8905b8d5cf1.png\n/kaggle/input/aptos2019/train_images/train_images/b17f0b81dab3.png\n/kaggle/input/aptos2019/train_images/train_images/6a905a7202d2.png\n/kaggle/input/aptos2019/train_images/train_images/50840c36f0b4.png\n/kaggle/input/aptos2019/train_images/train_images/465c618f7b23.png\n/kaggle/input/aptos2019/train_images/train_images/89b044cbaf85.png\n/kaggle/input/aptos2019/train_images/train_images/5995321563b7.png\n/kaggle/input/aptos2019/train_images/train_images/3694e8c8e09a.png\n/kaggle/input/aptos2019/train_images/train_images/d56d32a1d62d.png\n/kaggle/input/aptos2019/train_images/train_images/57ce57a8cfb0.png\n/kaggle/input/aptos2019/train_images/train_images/a0267206d51e.png\n/kaggle/input/aptos2019/train_images/train_images/65a7fe9482fe.png\n/kaggle/input/aptos2019/train_images/train_images/e13412678eff.png\n/kaggle/input/aptos2019/train_images/train_images/2cbfc6182ba2.png\n/kaggle/input/aptos2019/train_images/train_images/675de69373f8.png\n/kaggle/input/aptos2019/train_images/train_images/d18e5b68f6d2.png\n/kaggle/input/aptos2019/train_images/train_images/76095c338728.png\n/kaggle/input/aptos2019/train_images/train_images/52edbe29d655.png\n/kaggle/input/aptos2019/train_images/train_images/898f0bc8acfa.png\n/kaggle/input/aptos2019/train_images/train_images/db52626d450c.png\n/kaggle/input/aptos2019/train_images/train_images/312694ea8e6a.png\n/kaggle/input/aptos2019/train_images/train_images/870f433e8f37.png\n/kaggle/input/aptos2019/train_images/train_images/4f46d7ee61ed.png\n/kaggle/input/aptos2019/train_images/train_images/d99dd99be001.png\n/kaggle/input/aptos2019/train_images/train_images/6b66b0e86f7e.png\n/kaggle/input/aptos2019/train_images/train_images/378963f9df22.png\n/kaggle/input/aptos2019/train_images/train_images/b70e7c26f51e.png\n/kaggle/input/aptos2019/train_images/train_images/51131b48f9d4.png\n/kaggle/input/aptos2019/train_images/train_images/db690e2d02f8.png\n/kaggle/input/aptos2019/train_images/train_images/a188c60b93fb.png\n/kaggle/input/aptos2019/train_images/train_images/274f5029189b.png\n/kaggle/input/aptos2019/train_images/train_images/dbd062558b81.png\n/kaggle/input/aptos2019/train_images/train_images/248dec89b3a2.png\n/kaggle/input/aptos2019/train_images/train_images/881ec6186e68.png\n/kaggle/input/aptos2019/train_images/train_images/2d870833c0c9.png\n/kaggle/input/aptos2019/train_images/train_images/3246f07e65b4.png\n/kaggle/input/aptos2019/train_images/train_images/ca0f1a17c8e5.png\n/kaggle/input/aptos2019/train_images/train_images/518e880613de.png\n/kaggle/input/aptos2019/train_images/train_images/a70d0f12a641.png\n/kaggle/input/aptos2019/train_images/train_images/8f1e7433a95d.png\n/kaggle/input/aptos2019/train_images/train_images/a963ac561580.png\n/kaggle/input/aptos2019/train_images/train_images/80d24897669f.png\n/kaggle/input/aptos2019/train_images/train_images/92d9e9f08709.png\n/kaggle/input/aptos2019/train_images/train_images/a182b5b191de.png\n/kaggle/input/aptos2019/train_images/train_images/67d8f94f04e0.png\n/kaggle/input/aptos2019/train_images/train_images/4689b739d240.png\n/kaggle/input/aptos2019/train_images/train_images/e12b67835e03.png\n/kaggle/input/aptos2019/train_images/train_images/61e301bd3c25.png\n/kaggle/input/aptos2019/train_images/train_images/3206171db5be.png\n/kaggle/input/aptos2019/train_images/train_images/49419f8d5cb4.png\n/kaggle/input/aptos2019/train_images/train_images/b294927b14b0.png\n/kaggle/input/aptos2019/train_images/train_images/21abd36095a1.png\n/kaggle/input/aptos2019/train_images/train_images/e12f9f19d1be.png\n/kaggle/input/aptos2019/train_images/train_images/a8dea22ef903.png\n/kaggle/input/aptos2019/train_images/train_images/86fbac86ed3e.png\n/kaggle/input/aptos2019/train_images/train_images/215d2b7c3fde.png\n/kaggle/input/aptos2019/train_images/train_images/8b079e79035f.png\n/kaggle/input/aptos2019/train_images/train_images/c38dec54a9f7.png\n/kaggle/input/aptos2019/train_images/train_images/501c319f7a9f.png\n/kaggle/input/aptos2019/train_images/train_images/60eeae3ba23d.png\n/kaggle/input/aptos2019/test_images/test_images/ef476be214d4.png\n/kaggle/input/aptos2019/test_images/test_images/ec363f48867b.png\n/kaggle/input/aptos2019/test_images/test_images/f481f76a6b75.png\n/kaggle/input/aptos2019/test_images/test_images/fa7fa797c650.png\n/kaggle/input/aptos2019/test_images/test_images/e7578d8dba72.png\n/kaggle/input/aptos2019/test_images/test_images/eda29a9d78f3.png\n/kaggle/input/aptos2019/test_images/test_images/fe0e2dee1834.png\n/kaggle/input/aptos2019/test_images/test_images/e933923aab15.png\n/kaggle/input/aptos2019/test_images/test_images/ef99c499d665.png\n/kaggle/input/aptos2019/test_images/test_images/fc8fce67fbf8.png\n/kaggle/input/aptos2019/test_images/test_images/e9286ddf6ffe.png\n/kaggle/input/aptos2019/test_images/test_images/f0098e9d4aee.png\n/kaggle/input/aptos2019/test_images/test_images/ea1d045f9fea.png\n/kaggle/input/aptos2019/test_images/test_images/e7291472109b.png\n/kaggle/input/aptos2019/test_images/test_images/fd48cf452e9d.png\n/kaggle/input/aptos2019/test_images/test_images/eedae6b28f96.png\n/kaggle/input/aptos2019/test_images/test_images/ef81cd8854cb.png\n/kaggle/input/aptos2019/test_images/test_images/f366fb1cc475.png\n/kaggle/input/aptos2019/test_images/test_images/f7e9fa75c7c1.png\n/kaggle/input/aptos2019/test_images/test_images/e5de79795c1d.png\n/kaggle/input/aptos2019/test_images/test_images/eae70f527755.png\n/kaggle/input/aptos2019/test_images/test_images/f7116e7b2f4e.png\n/kaggle/input/aptos2019/test_images/test_images/fb696a8e055a.png\n/kaggle/input/aptos2019/test_images/test_images/e6a6acf7fca1.png\n/kaggle/input/aptos2019/test_images/test_images/f9aa35187bf3.png\n/kaggle/input/aptos2019/test_images/test_images/ea15a290eb96.png\n/kaggle/input/aptos2019/test_images/test_images/ed6bd9293a89.png\n/kaggle/input/aptos2019/test_images/test_images/fc898dfeb24f.png\n/kaggle/input/aptos2019/test_images/test_images/f6f433f3306f.png\n/kaggle/input/aptos2019/test_images/test_images/e60e4edb3ca9.png\n/kaggle/input/aptos2019/test_images/test_images/fa3e544a7401.png\n/kaggle/input/aptos2019/test_images/test_images/f56ff0440ed1.png\n/kaggle/input/aptos2019/test_images/test_images/f09fd9433dff.png\n/kaggle/input/aptos2019/test_images/test_images/ef8c39eb9157.png\n/kaggle/input/aptos2019/test_images/test_images/fdd18ccbbdc5.png\n/kaggle/input/aptos2019/test_images/test_images/f09cfc6a4dbd.png\n/kaggle/input/aptos2019/test_images/test_images/e9f3c85a2a02.png\n/kaggle/input/aptos2019/test_images/test_images/ecad6845f630.png\n/kaggle/input/aptos2019/test_images/test_images/e62490b7d0e9.png\n/kaggle/input/aptos2019/test_images/test_images/eb32a815f78c.png\n/kaggle/input/aptos2019/test_images/test_images/ef247f28004f.png\n/kaggle/input/aptos2019/test_images/test_images/e8ddfc9709ce.png\n/kaggle/input/aptos2019/test_images/test_images/fe06dad6851c.png\n/kaggle/input/aptos2019/test_images/test_images/f850cb51fdba.png\n/kaggle/input/aptos2019/test_images/test_images/fa9f1bc03f21.png\n/kaggle/input/aptos2019/test_images/test_images/fd62bd0db4f1.png\n/kaggle/input/aptos2019/test_images/test_images/f62b8a076833.png\n/kaggle/input/aptos2019/test_images/test_images/f0546a45ef10.png\n/kaggle/input/aptos2019/test_images/test_images/f6d760566a51.png\n/kaggle/input/aptos2019/test_images/test_images/f6f3ea0d2693.png\n/kaggle/input/aptos2019/test_images/test_images/e77a93c3d9a9.png\n/kaggle/input/aptos2019/test_images/test_images/fba493e17448.png\n/kaggle/input/aptos2019/test_images/test_images/e50b0174690d.png\n/kaggle/input/aptos2019/test_images/test_images/f0a2dc580009.png\n/kaggle/input/aptos2019/test_images/test_images/e4f12411fd85.png\n/kaggle/input/aptos2019/test_images/test_images/e8e44b3160e3.png\n/kaggle/input/aptos2019/test_images/test_images/ee3fe7809e6a.png\n/kaggle/input/aptos2019/test_images/test_images/f9ecf1795804.png\n/kaggle/input/aptos2019/test_images/test_images/f69835dc7c50.png\n/kaggle/input/aptos2019/test_images/test_images/f633c474e8b8.png\n/kaggle/input/aptos2019/test_images/test_images/f0860c21533b.png\n/kaggle/input/aptos2019/test_images/test_images/f4e68b61f480.png\n/kaggle/input/aptos2019/test_images/test_images/e82232a3c28b.png\n/kaggle/input/aptos2019/test_images/test_images/eed4afc8ec83.png\n/kaggle/input/aptos2019/test_images/test_images/eadfc8809ec8.png\n/kaggle/input/aptos2019/test_images/test_images/fe3b0e50be78.png\n/kaggle/input/aptos2019/test_images/test_images/eabc7c716255.png\n/kaggle/input/aptos2019/test_images/test_images/e632e38fd2d4.png\n/kaggle/input/aptos2019/test_images/test_images/ee2c2a5f7d0e.png\n/kaggle/input/aptos2019/test_images/test_images/fcc6aa6755e6.png\n/kaggle/input/aptos2019/test_images/test_images/e893e86dde94.png\n/kaggle/input/aptos2019/test_images/test_images/ed648b9bcd95.png\n/kaggle/input/aptos2019/test_images/test_images/e96bd80a8a53.png\n/kaggle/input/aptos2019/test_images/test_images/e5f73f2855c0.png\n/kaggle/input/aptos2019/test_images/test_images/ea5c42a78979.png\n/kaggle/input/aptos2019/test_images/test_images/fda39982a810.png\n/kaggle/input/aptos2019/test_images/test_images/ed88faaa325a.png\n/kaggle/input/aptos2019/test_images/test_images/ee77763a6afb.png\n/kaggle/input/aptos2019/test_images/test_images/fea14b3d44b0.png\n/kaggle/input/aptos2019/test_images/test_images/f580566e27f5.png\n/kaggle/input/aptos2019/test_images/test_images/fbfa925506f6.png\n/kaggle/input/aptos2019/test_images/test_images/e68746d426b2.png\n/kaggle/input/aptos2019/test_images/test_images/fe674c2f73f5.png\n/kaggle/input/aptos2019/test_images/test_images/ff77e8e5b5f3.png\n/kaggle/input/aptos2019/test_images/test_images/e7a372a1c3a4.png\n/kaggle/input/aptos2019/test_images/test_images/e66855a5c583.png\n/kaggle/input/aptos2019/test_images/test_images/ed246ae1ed08.png\n/kaggle/input/aptos2019/test_images/test_images/fa6f3d8bb1d5.png\n/kaggle/input/aptos2019/test_images/test_images/e724866f5084.png\n/kaggle/input/aptos2019/test_images/test_images/eb6b1f1c09db.png\n/kaggle/input/aptos2019/test_images/test_images/f0267c42907c.png\n/kaggle/input/aptos2019/test_images/test_images/e79e10907295.png\n/kaggle/input/aptos2019/test_images/test_images/f762c272c522.png\n/kaggle/input/aptos2019/test_images/test_images/ed2c06fcc573.png\n/kaggle/input/aptos2019/test_images/test_images/ed2c52c14493.png\n/kaggle/input/aptos2019/test_images/test_images/ea68b58a6e8f.png\n/kaggle/input/aptos2019/test_images/test_images/f71aca5a7dc3.png\n/kaggle/input/aptos2019/test_images/test_images/fb61230b99dd.png\n/kaggle/input/aptos2019/test_images/test_images/ff8a0b45c789.png\n/kaggle/input/aptos2019/test_images/test_images/fed5bb685832.png\n/kaggle/input/aptos2019/test_images/test_images/f26b02ead915.png\n/kaggle/input/aptos2019/test_images/test_images/e68bdd36e589.png\n/kaggle/input/aptos2019/test_images/test_images/e663c6627a95.png\n/kaggle/input/aptos2019/test_images/test_images/f9d8ff3e6592.png\n/kaggle/input/aptos2019/test_images/test_images/f3a268d2726d.png\n/kaggle/input/aptos2019/test_images/test_images/ff4955e76894.png\n/kaggle/input/aptos2019/test_images/test_images/f0c0f7b5e820.png\n/kaggle/input/aptos2019/test_images/test_images/f36cb007a1ef.png\n/kaggle/input/aptos2019/test_images/test_images/edceb0657d77.png\n/kaggle/input/aptos2019/test_images/test_images/f85fd4fac887.png\n/kaggle/input/aptos2019/test_images/test_images/f0e1201b5c1f.png\n/kaggle/input/aptos2019/test_images/test_images/e7fc93ac5b6d.png\n/kaggle/input/aptos2019/test_images/test_images/f66c4ee86629.png\n/kaggle/input/aptos2019/test_images/test_images/e66ad813a508.png\n/kaggle/input/aptos2019/test_images/test_images/ff344e5c9341.png\n/kaggle/input/aptos2019/test_images/test_images/fc782722a50c.png\n/kaggle/input/aptos2019/test_images/test_images/f5c953bee7cd.png\n/kaggle/input/aptos2019/test_images/test_images/e580676516b0.png\n/kaggle/input/aptos2019/test_images/test_images/f4d3777f2710.png\n/kaggle/input/aptos2019/test_images/test_images/fb88d23fc5fe.png\n/kaggle/input/aptos2019/test_images/test_images/e7a7187066ad.png\n/kaggle/input/aptos2019/test_images/test_images/ef7a4ed8d5d1.png\n/kaggle/input/aptos2019/test_images/test_images/e594c19e2e1d.png\n/kaggle/input/aptos2019/test_images/test_images/f1979147aad4.png\n/kaggle/input/aptos2019/test_images/test_images/fecf4c5ae84b.png\n/kaggle/input/aptos2019/test_images/test_images/e811f39a1243.png\n/kaggle/input/aptos2019/test_images/test_images/ff631653374e.png\n/kaggle/input/aptos2019/test_images/test_images/fcc55ae641ae.png\n/kaggle/input/aptos2019/test_images/test_images/e540d2e35d15.png\n/kaggle/input/aptos2019/test_images/test_images/f1a761c68559.png\n/kaggle/input/aptos2019/test_images/test_images/f58cdfa968be.png\n/kaggle/input/aptos2019/test_images/test_images/f3b27ac2d371.png\n/kaggle/input/aptos2019/test_images/test_images/f549294e12e1.png\n/kaggle/input/aptos2019/test_images/test_images/e7defafeb957.png\n/kaggle/input/aptos2019/test_images/test_images/e9faf0296643.png\n/kaggle/input/aptos2019/test_images/test_images/f35d80bb1a22.png\n/kaggle/input/aptos2019/test_images/test_images/f1d719c97838.png\n/kaggle/input/aptos2019/test_images/test_images/ee3f5cf52188.png\n/kaggle/input/aptos2019/test_images/test_images/febfb20dc311.png\n/kaggle/input/aptos2019/test_images/test_images/f7edc074f06b.png\n/kaggle/input/aptos2019/test_images/test_images/f71bea807c96.png\n/kaggle/input/aptos2019/test_images/test_images/e5f332efcbc7.png\n/kaggle/input/aptos2019/test_images/test_images/f819c65b803c.png\n/kaggle/input/aptos2019/test_images/test_images/fc1b1841eadf.png\n/kaggle/input/aptos2019/test_images/test_images/e9678824215d.png\n/kaggle/input/aptos2019/test_images/test_images/ffec9a18a3ce.png\n/kaggle/input/aptos2019/test_images/test_images/e9ab8413e771.png\n/kaggle/input/aptos2019/test_images/test_images/f48241b0c995.png\n/kaggle/input/aptos2019/test_images/test_images/ef8109305128.png\n/kaggle/input/aptos2019/test_images/test_images/e97ecf4355cb.png\n/kaggle/input/aptos2019/test_images/test_images/e69b48516577.png\n/kaggle/input/aptos2019/test_images/test_images/f64b6e85f1c9.png\n/kaggle/input/aptos2019/test_images/test_images/e868c3da340b.png\n/kaggle/input/aptos2019/test_images/test_images/f69400b316a7.png\n/kaggle/input/aptos2019/test_images/test_images/f64214bed40e.png\n/kaggle/input/aptos2019/test_images/test_images/f252046c0fe6.png\n/kaggle/input/aptos2019/test_images/test_images/f02057c41256.png\n/kaggle/input/aptos2019/test_images/test_images/f9d52509c571.png\n/kaggle/input/aptos2019/test_images/test_images/e4dcca36ceb4.png\n/kaggle/input/aptos2019/test_images/test_images/ea588d1e5d96.png\n/kaggle/input/aptos2019/test_images/test_images/fefded6bf135.png\n/kaggle/input/aptos2019/test_images/test_images/f47a2a4a0411.png\n/kaggle/input/aptos2019/test_images/test_images/e9129ce55fd7.png\n/kaggle/input/aptos2019/test_images/test_images/e93394175a19.png\n/kaggle/input/aptos2019/test_images/test_images/ea05c22d92e9.png\n/kaggle/input/aptos2019/test_images/test_images/e821c1b6417a.png\n/kaggle/input/aptos2019/test_images/test_images/ead23cc922ed.png\n/kaggle/input/aptos2019/test_images/test_images/ea6a53e54d0f.png\n/kaggle/input/aptos2019/test_images/test_images/f86d1c404acb.png\n/kaggle/input/aptos2019/test_images/test_images/fcc32dffd24d.png\n/kaggle/input/aptos2019/test_images/test_images/fa9bece586fc.png\n/kaggle/input/aptos2019/test_images/test_images/f994a3b07935.png\n/kaggle/input/aptos2019/test_images/test_images/e529c5757d64.png\n/kaggle/input/aptos2019/test_images/test_images/f4de9620e3f2.png\n/kaggle/input/aptos2019/test_images/test_images/ff59d44a70a7.png\n/kaggle/input/aptos2019/test_images/test_images/fd0a70082e7c.png\n/kaggle/input/aptos2019/test_images/test_images/f61bf44c677c.png\n/kaggle/input/aptos2019/test_images/test_images/eeaea2c5ff34.png\n/kaggle/input/aptos2019/test_images/test_images/ed3a0fc5b546.png\n/kaggle/input/aptos2019/test_images/test_images/eaa0dfbd5024.png\n/kaggle/input/aptos2019/test_images/test_images/f80118bbda18.png\n/kaggle/input/aptos2019/test_images/test_images/ec6659926105.png\n/kaggle/input/aptos2019/test_images/test_images/fbcbc81cf9be.png\n/kaggle/input/aptos2019/test_images/test_images/f4df3d86688d.png\n/kaggle/input/aptos2019/test_images/test_images/f06e7a9df795.png\n/kaggle/input/aptos2019/test_images/test_images/f23902998c21.png\n/kaggle/input/aptos2019/test_images/test_images/fce93caa4758.png\n/kaggle/input/aptos2019/test_images/test_images/eae901557a84.png\n/kaggle/input/aptos2019/test_images/test_images/f02babb3a023.png\n/kaggle/input/aptos2019/test_images/test_images/f71333204618.png\n/kaggle/input/aptos2019/test_images/test_images/f8fc411092c7.png\n/kaggle/input/aptos2019/test_images/test_images/f3a4751af42e.png\n/kaggle/input/aptos2019/test_images/test_images/f02956bd7c50.png\n/kaggle/input/aptos2019/test_images/test_images/ff1e940105f9.png\n/kaggle/input/aptos2019/test_images/test_images/ee059945b08a.png\n/kaggle/input/aptos2019/test_images/test_images/ed6704e3b72e.png\n/kaggle/input/aptos2019/test_images/test_images/fac399455195.png\n/kaggle/input/aptos2019/test_images/test_images/e6a58edc5b42.png\n/kaggle/input/aptos2019/test_images/test_images/e6a5e4718873.png\n/kaggle/input/aptos2019/test_images/test_images/f9156aeffc5e.png\n/kaggle/input/aptos2019/test_images/test_images/ef4121e9bb67.png\n/kaggle/input/aptos2019/test_images/test_images/f1dc26c4bfa3.png\n/kaggle/input/aptos2019/test_images/test_images/fe37f4492920.png\n/kaggle/input/aptos2019/test_images/test_images/f55e1d2a19e4.png\n/kaggle/input/aptos2019/test_images/test_images/f58d37d48e42.png\n/kaggle/input/aptos2019/test_images/test_images/ffa47f6a7bf4.png\n/kaggle/input/aptos2019/test_images/test_images/f0800723bc63.png\n/kaggle/input/aptos2019/test_images/test_images/f361060eda3e.png\n/kaggle/input/aptos2019/test_images/test_images/ec57cc20d776.png\n/kaggle/input/aptos2019/test_images/test_images/e9ce5bf645ab.png\n/kaggle/input/aptos2019/test_images/test_images/e582e56e7942.png\n/kaggle/input/aptos2019/test_images/test_images/e6552b7432b3.png\n/kaggle/input/aptos2019/test_images/test_images/ee02294cc3d9.png\n/kaggle/input/aptos2019/test_images/test_images/f91cfa82b9d4.png\n/kaggle/input/aptos2019/test_images/test_images/f233638e0e90.png\n/kaggle/input/aptos2019/test_images/test_images/eda1d75cbcf0.png\n/kaggle/input/aptos2019/test_images/test_images/f3a88d3026dc.png\n/kaggle/input/aptos2019/test_images/test_images/e7d2c2c3b30f.png\n/kaggle/input/aptos2019/test_images/test_images/f30f203ef51e.png\n/kaggle/input/aptos2019/test_images/test_images/ed3ce1674761.png\n/kaggle/input/aptos2019/test_images/test_images/f5e9a307288c.png\n/kaggle/input/aptos2019/test_images/test_images/f0c13be90519.png\n/kaggle/input/aptos2019/test_images/test_images/f4874247ede6.png\n/kaggle/input/aptos2019/test_images/test_images/e59c5f345bb0.png\n/kaggle/input/aptos2019/test_images/test_images/e9f82b5bbaf4.png\n/kaggle/input/aptos2019/test_images/test_images/f5a8c6426a71.png\n/kaggle/input/aptos2019/test_images/test_images/ef5155990874.png\n/kaggle/input/aptos2019/test_images/test_images/eb1ad14dd281.png\n/kaggle/input/aptos2019/test_images/test_images/ffcf7b45f213.png\n/kaggle/input/aptos2019/test_images/test_images/ec0c9f817b03.png\n/kaggle/input/aptos2019/test_images/test_images/e4e343eaae2a.png\n/kaggle/input/aptos2019/test_images/test_images/e966850247f4.png\n/kaggle/input/aptos2019/test_images/test_images/e96099b961b4.png\n/kaggle/input/aptos2019/test_images/test_images/f8d62557ad0c.png\n/kaggle/input/aptos2019/test_images/test_images/f2c0b41acd05.png\n/kaggle/input/aptos2019/test_images/test_images/ea9e0fb6fb0b.png\n/kaggle/input/aptos2019/test_images/test_images/eb175669d789.png\n/kaggle/input/aptos2019/test_images/test_images/e85d410d6836.png\n/kaggle/input/aptos2019/test_images/test_images/f85c78201a50.png\n/kaggle/input/aptos2019/test_images/test_images/ff4cd992667b.png\n/kaggle/input/aptos2019/test_images/test_images/f2d2a0c92034.png\n/kaggle/input/aptos2019/test_images/test_images/f3b6b7ca1eb1.png\n/kaggle/input/aptos2019/test_images/test_images/f7735b6d47f7.png\n/kaggle/input/aptos2019/test_images/test_images/eba3acc42197.png\n/kaggle/input/aptos2019/test_images/test_images/fb6b8200b7f8.png\n/kaggle/input/aptos2019/test_images/test_images/ec4649213ccf.png\n/kaggle/input/aptos2019/test_images/test_images/f7508f14dd7b.png\n/kaggle/input/aptos2019/test_images/test_images/fc603cbedb41.png\n/kaggle/input/aptos2019/test_images/test_images/f4c7ae514c54.png\n/kaggle/input/aptos2019/test_images/test_images/f531232ecb55.png\n/kaggle/input/aptos2019/test_images/test_images/f025f33b2c9b.png\n/kaggle/input/aptos2019/test_images/test_images/f9e1c439d4c8.png\n/kaggle/input/aptos2019/test_images/test_images/ea9c41e1ced0.png\n/kaggle/input/aptos2019/test_images/test_images/e81f4a2fbbdc.png\n/kaggle/input/aptos2019/test_images/test_images/e907d23cce3d.png\n/kaggle/input/aptos2019/test_images/test_images/ff4832d55461.png\n/kaggle/input/aptos2019/test_images/test_images/f460608cf4cc.png\n/kaggle/input/aptos2019/test_images/test_images/fca1a8738b8a.png\n/kaggle/input/aptos2019/test_images/test_images/fd87b6b2e664.png\n/kaggle/input/aptos2019/test_images/test_images/eb1d37b71fd1.png\n/kaggle/input/aptos2019/test_images/test_images/ff52392372d3.png\n/kaggle/input/aptos2019/test_images/test_images/fbdc796290d4.png\n/kaggle/input/aptos2019/test_images/test_images/f451eee2b66b.png\n/kaggle/input/aptos2019/test_images/test_images/ff0740cb484a.png\n/kaggle/input/aptos2019/test_images/test_images/fa0c87bd75ce.png\n/kaggle/input/aptos2019/test_images/test_images/ea4ce9516144.png\n/kaggle/input/aptos2019/test_images/test_images/f092febbf5c0.png\n/kaggle/input/aptos2019/test_images/test_images/ebe0175e530c.png\n/kaggle/input/aptos2019/test_images/test_images/e740af6ac6ea.png\n/kaggle/input/aptos2019/test_images/test_images/e52ed5c29c5e.png\n/kaggle/input/aptos2019/test_images/test_images/fca931da5c5e.png\n/kaggle/input/aptos2019/test_images/test_images/f080a22008be.png\n/kaggle/input/aptos2019/test_images/test_images/f3cd489acbee.png\n/kaggle/input/aptos2019/test_images/test_images/f999c6921e6d.png\n/kaggle/input/aptos2019/test_images/test_images/fd4c946c52bf.png\n/kaggle/input/aptos2019/test_images/test_images/f7defe70afc3.png\n/kaggle/input/aptos2019/test_images/test_images/fb767cea406c.png\n/kaggle/input/aptos2019/test_images/test_images/e5d56f4f359b.png\n/kaggle/input/aptos2019/test_images/test_images/ef7eb85b75fc.png\n/kaggle/input/aptos2019/test_images/test_images/ebd96d853918.png\n/kaggle/input/aptos2019/test_images/test_images/f2094a20b275.png\n/kaggle/input/aptos2019/test_images/test_images/efff2f1a35f5.png\n/kaggle/input/aptos2019/test_images/test_images/f90f8931a9bc.png\n/kaggle/input/aptos2019/test_images/test_images/e65a2ff90494.png\n/kaggle/input/aptos2019/test_images/test_images/f42b693a9414.png\n/kaggle/input/aptos2019/test_images/test_images/ebf4b22240f4.png\n/kaggle/input/aptos2019/test_images/test_images/e65f94ad9be3.png\n/kaggle/input/aptos2019/test_images/test_images/fdc685055659.png\n/kaggle/input/aptos2019/test_images/test_images/eadc57064154.png\n/kaggle/input/aptos2019/test_images/test_images/fe0fc67c7980.png\n/kaggle/input/aptos2019/test_images/test_images/ea7e21bab610.png\n/kaggle/input/aptos2019/test_images/test_images/e8d1c6c07cf2.png\n/kaggle/input/aptos2019/test_images/test_images/ee74c3b177e0.png\n/kaggle/input/aptos2019/test_images/test_images/f952ad2e4356.png\n/kaggle/input/aptos2019/test_images/test_images/f00ce9b9d6f4.png\n/kaggle/input/aptos2019/test_images/test_images/fb88783de055.png\n/kaggle/input/aptos2019/test_images/test_images/ef26625121b3.png\n/kaggle/input/aptos2019/test_images/test_images/ef48780f5d5f.png\n/kaggle/input/aptos2019/test_images/test_images/f8372e80f731.png\n/kaggle/input/aptos2019/test_images/test_images/f0f89314e860.png\n/kaggle/input/aptos2019/test_images/test_images/e76a9cbb2a8c.png\n/kaggle/input/aptos2019/test_images/test_images/f58f0b2fd718.png\n/kaggle/input/aptos2019/test_images/test_images/f5e6226bd2e0.png\n/kaggle/input/aptos2019/test_images/test_images/eabf421f94d0.png\n/kaggle/input/aptos2019/test_images/test_images/ffd97f8cd5aa.png\n/kaggle/input/aptos2019/test_images/test_images/fb1b8771c70a.png\n/kaggle/input/aptos2019/test_images/test_images/ffc04fed30e6.png\n/kaggle/input/aptos2019/test_images/test_images/ee1ec90b980f.png\n/kaggle/input/aptos2019/test_images/test_images/f2ee81781411.png\n/kaggle/input/aptos2019/test_images/test_images/ec6f1797a25a.png\n/kaggle/input/aptos2019/test_images/test_images/fce73678f650.png\n/kaggle/input/aptos2019/test_images/test_images/fe3f62695b2d.png\n/kaggle/input/aptos2019/test_images/test_images/ed2ef440d22c.png\n/kaggle/input/aptos2019/test_images/test_images/f72ef9ceeaa8.png\n/kaggle/input/aptos2019/test_images/test_images/e55188915f9d.png\n/kaggle/input/aptos2019/test_images/test_images/f4d3169b468a.png\n/kaggle/input/aptos2019/test_images/test_images/f576e45d1da2.png\n/kaggle/input/aptos2019/test_images/test_images/e6f0ce5bf282.png\n/kaggle/input/aptos2019/test_images/test_images/f5650eb52640.png\n/kaggle/input/aptos2019/test_images/test_images/fc4c2d35c6f8.png\n/kaggle/input/aptos2019/test_images/test_images/fdbc252813b1.png\n/kaggle/input/aptos2019/test_images/test_images/fd079d2e93a2.png\n/kaggle/input/aptos2019/test_images/test_images/f57cf3b6f48e.png\n/kaggle/input/aptos2019/test_images/test_images/f920ccd926db.png\n/kaggle/input/aptos2019/test_images/test_images/f002ce614c59.png\n/kaggle/input/aptos2019/test_images/test_images/f03d3c4ce7fb.png\n/kaggle/input/aptos2019/test_images/test_images/f5733f77273d.png\n/kaggle/input/aptos2019/test_images/test_images/fdd534271f3d.png\n/kaggle/input/aptos2019/test_images/test_images/e83d315d8f98.png\n/kaggle/input/aptos2019/test_images/test_images/f9e779a13204.png\n/kaggle/input/aptos2019/test_images/test_images/f8f5942b690e.png\n/kaggle/input/aptos2019/test_images/test_images/fa748b57262b.png\n/kaggle/input/aptos2019/test_images/test_images/f8cf7ed8ef00.png\n/kaggle/input/aptos2019/test_images/test_images/eb050765b323.png\n/kaggle/input/aptos2019/test_images/test_images/ea4dcb055139.png\n/kaggle/input/aptos2019/test_images/test_images/f7fec8935126.png\n/kaggle/input/aptos2019/test_images/test_images/fc4d69128e7c.png\n/kaggle/input/aptos2019/test_images/test_images/e5197d77ec68.png\n/kaggle/input/aptos2019/test_images/test_images/eeb231c3ef1f.png\n/kaggle/input/aptos2019/test_images/test_images/fe2df69676cf.png\n/kaggle/input/aptos2019/test_images/test_images/e7b5dd5bab1f.png\n/kaggle/input/aptos2019/test_images/test_images/ec01f0862669.png\n/kaggle/input/aptos2019/test_images/test_images/ecb4500285ed.png\n/kaggle/input/aptos2019/test_images/test_images/f901d460517c.png\n/kaggle/input/aptos2019/test_images/test_images/fa573163dd8b.png\n/kaggle/input/aptos2019/test_images/test_images/f298b7d05958.png\n/kaggle/input/aptos2019/test_images/test_images/e599151ca14b.png\n/kaggle/input/aptos2019/test_images/test_images/ee36ca728641.png\n/kaggle/input/aptos2019/test_images/test_images/fa59221cf464.png\n/kaggle/input/aptos2019/test_images/test_images/f4ea2a2cfbb9.png\n/kaggle/input/aptos2019/test_images/test_images/ff03f74667df.png\n/kaggle/input/aptos2019/test_images/test_images/f18abfa690ab.png\n/kaggle/input/aptos2019/test_images/test_images/f583a722434c.png\n/kaggle/input/aptos2019/test_images/test_images/e9ff9352ccb3.png\n/kaggle/input/aptos2019/test_images/test_images/f6f7dba7104d.png\n/kaggle/input/aptos2019/test_images/test_images/e756495c11cb.png\n/kaggle/input/aptos2019/test_images/test_images/ee78ce914066.png\n/kaggle/input/aptos2019/test_images/test_images/f2f569a64949.png\n/kaggle/input/aptos2019/test_images/test_images/f68690db78d3.png\n/kaggle/input/aptos2019/test_images/test_images/eebd1e195952.png\n/kaggle/input/aptos2019/test_images/test_images/f431f2e119d7.png\n/kaggle/input/aptos2019/test_images/test_images/ee6e39319b39.png\n/kaggle/input/aptos2019/test_images/test_images/f3bb996b45ce.png\n/kaggle/input/aptos2019/test_images/test_images/f066db7a2efe.png\n/kaggle/input/aptos2019/test_images/test_images/f45f1485c940.png\n/kaggle/input/aptos2019/test_images/test_images/f72adcac5638.png\n/kaggle/input/hiiiiii/best_model_try2_stage1.pth\n/kaggle/input/hiiiiii/best_model_final.pth\n/kaggle/input/hiiiiii/best_model_stage1.pth\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"        BASE_PATH = '/kaggle/input/aptos2019/'\n        train_csv_path = os.path.join(BASE_PATH, 'train_1.csv')\n        val_csv_path = os.path.join(BASE_PATH, 'valid.csv')\n        train_img_dir = os.path.join(BASE_PATH, 'train_images', 'train_images')\n        val_img_dir = os.path.join(BASE_PATH, 'val_images', 'val_images')\n\n        # Load dataframes using the provided train/validation split\n        train_df = pd.read_csv(train_csv_path)\n        val_df = pd.read_csv(val_csv_path)\n        train_df['diagnosis'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T07:13:11.804665Z","iopub.status.idle":"2025-09-10T07:13:11.804976Z","shell.execute_reply.started":"2025-09-10T07:13:11.804798Z","shell.execute_reply":"2025-09-10T07:13:11.804810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image\nimport gc\nimport os\nimport timm\nimport cv2\n\n# =============================================================================\n# DATASET CLASS\n# =============================================================================\n\nclass DiabeticRetinopathyDataset(Dataset):\n    \"\"\"Custom Dataset for Diabetic Retinopathy images.\"\"\"\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.dataframe = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx]['id_code'] + '.png')\n        image = Image.open(img_name).convert('RGB')\n        label = torch.tensor(self.dataframe.iloc[idx]['diagnosis'], dtype=torch.long)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n\n# =============================================================================\n# ADVANCED PREPROCESSING TRANSFORM\n# =============================================================================\n\nclass AdvancedBenGrahamPreprocess(object):\n    \"\"\"Applies a series of robust preprocessing steps for fundus images.\"\"\"\n    def __init__(self, output_size=256):\n        assert isinstance(output_size, (int, tuple))\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        else:\n            assert len(output_size) == 2\n            self.output_size = output_size\n\n    def __call__(self, image):\n        # Convert PIL image to numpy array\n        img_np = np.array(image)\n\n        # 1. Crop black borders\n        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n        _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        if contours:\n            largest_contour = max(contours, key=cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(largest_contour)\n            img_np = img_np[y:y+h, x:x+w]\n\n        # 2. Apply CLAHE to the green channel for contrast enhancement\n        b, g, r = cv2.split(img_np)\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        g = clahe.apply(g)\n        img_clahe = cv2.merge((b, g, r))\n\n        # 3. Apply a gentle Gaussian blur to reduce noise\n        img_blur = cv2.GaussianBlur(img_clahe, (5, 5), 0)\n\n        # 4. Resize to target size\n        img_resized = cv2.resize(img_blur, self.output_size, interpolation=cv2.INTER_AREA)\n        \n        # Convert back to PIL Image\n        return Image.fromarray(img_resized)\n\n\n# =============================================================================\n# LOSS FUNCTIONS\n# =============================================================================\n\nclass OrdinalCrossEntropyLoss(nn.Module):\n    \"\"\"Cross Entropy Loss for Ordinal Regression.\"\"\"\n    def __init__(self, num_classes=5, class_weights=None):\n        super(OrdinalCrossEntropyLoss, self).__init__()\n        self.num_classes = num_classes\n        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n        self.class_weights = class_weights\n\n    def forward(self, outputs, targets):\n        \"\"\"\n        outputs: (batch_size, num_classes-1) ordinal logits\n        targets: (batch_size,) class labels 0 to num_classes-1\n        \"\"\"\n        # Create ordinal targets\n        ordinal_targets = torch.zeros_like(outputs)\n        for i, target in enumerate(targets):\n            if target > 0:\n                ordinal_targets[i, :target] = 1.0\n\n        losses = self.bce_loss(outputs, ordinal_targets)\n\n        if self.class_weights is not None:\n            weights = self.class_weights[targets]\n            return (losses.mean(dim=1) * weights).mean()\n        else:\n            return losses.mean()\n\nclass SmoothKappaLoss(nn.Module):\n    \"\"\"Smooth Quadratic Weighted Kappa Loss for Ordinal Regression.\"\"\"\n    def __init__(self, num_classes=5):\n        super(SmoothKappaLoss, self).__init__()\n        self.num_classes = num_classes\n\n        # Create quadratic weight matrix\n        weight_matrix = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes):\n                weight_matrix[i, j] = (i - j) ** 2\n        self.register_buffer('weight_matrix', weight_matrix)\n\n    def forward(self, outputs, targets):\n        \"\"\"\n        outputs: (batch_size, num_classes-1) ordinal logits\n        targets: (batch_size,) class labels\n        \"\"\"\n        batch_size = outputs.size(0)\n\n        # Convert ordinal outputs to class probabilities\n        probs = torch.sigmoid(outputs)\n        class_probs = torch.zeros(batch_size, self.num_classes, device=outputs.device)\n        class_probs[:, 0] = 1 - probs[:, 0]\n        for k in range(1, self.num_classes - 1):\n            class_probs[:, k] = probs[:, k-1] - probs[:, k]\n        class_probs[:, -1] = probs[:, -1]\n\n        # Ensure probabilities are valid and sum to 1\n        class_probs = torch.clamp(class_probs, min=1e-7, max=1.0)\n        class_probs = class_probs / class_probs.sum(dim=1, keepdim=True)\n\n        # One-hot encode targets\n        one_hot_targets = F.one_hot(targets, num_classes=self.num_classes).float()\n\n        # Calculate observed agreement\n        observed_agreement = torch.sum(one_hot_targets * class_probs * self.weight_matrix[targets, :])\n\n        # Calculate expected agreement\n        true_marginals = one_hot_targets.sum(dim=0)\n        pred_marginals = class_probs.sum(dim=0)\n        expected_outer = torch.outer(true_marginals, pred_marginals)\n        expected_agreement = torch.sum(expected_outer * self.weight_matrix)\n\n        # QWK is 1 - (observed / expected), so loss is observed / (expected + epsilon)\n        loss = observed_agreement / (expected_agreement + 1e-7)\n        return loss\n\n# =============================================================================\n# MODEL\n# =============================================================================\n\nclass EfficientNetOrdinal(nn.Module):\n    \"\"\"EfficientNet for Ordinal Regression.\"\"\"\n    def __init__(self, model_name='efficientnet_b2', num_classes=5, pretrained=True):\n        super(EfficientNetOrdinal, self).__init__()\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=pretrained,\n            num_classes=0,  # Remove classification head\n            global_pool='avg'\n        )\n        feature_dim = self.backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes - 1)\n        )\n\n    def forward(self, x):\n        features = self.backbone(x)\n        logits = self.classifier(features)\n        return logits\n\n# =============================================================================\n# UTILITY FUNCTIONS\n# =============================================================================\n\ndef ordinal_to_class(outputs):\n    \"\"\"Convert ordinal outputs to class predictions.\"\"\"\n    probs = torch.sigmoid(outputs)\n    return torch.sum(probs > 0.5, dim=1).long()\n\ndef calculate_metrics(outputs, targets):\n    \"\"\"Calculate accuracy, QWK, and within-1 accuracy.\"\"\"\n    preds = ordinal_to_class(outputs).cpu().numpy()\n    targets_np = targets.cpu().numpy()\n    accuracy = accuracy_score(targets_np, preds)\n    qwk = cohen_kappa_score(targets_np, preds, weights='quadratic')\n    within1 = np.mean(np.abs(targets_np - preds) <= 1)\n    return accuracy, qwk, within1\n\ndef clear_memory():\n    \"\"\"Clear GPU memory.\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    gc.collect()\n\n# =============================================================================\n# TRAINING & VALIDATION LOOPS\n# =============================================================================\n\ndef train_epoch(model, train_loader, optimizer, criterion, scaler, device):\n    \"\"\"Train one epoch.\"\"\"\n    model.train()\n    running_loss = 0.0\n    all_outputs, all_targets = [], []\n\n    for images, targets in train_loader:\n        images, targets = images.to(device), targets.to(device)\n        optimizer.zero_grad()\n\n        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n        all_outputs.append(outputs.detach())\n        all_targets.append(targets.detach())\n\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    accuracy, qwk, within1 = calculate_metrics(all_outputs, all_targets)\n    return running_loss / len(train_loader), accuracy, qwk, within1\n\ndef validate_epoch(model, val_loader, criterion, device):\n    \"\"\"Validate one epoch.\"\"\"\n    model.eval()\n    running_loss = 0.0\n    all_outputs, all_targets = [], []\n\n    with torch.no_grad():\n        for images, targets in val_loader:\n            images, targets = images.to(device), targets.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            all_outputs.append(outputs)\n            all_targets.append(targets)\n\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    accuracy, qwk, within1 = calculate_metrics(all_outputs, all_targets)\n    return running_loss / len(val_loader), accuracy, qwk, within1\n\n# =============================================================================\n# MAIN TRAINING PIPELINE\n# =============================================================================\n\ndef main_training_pipeline(train_loader, val_loader, train_df, device):\n    \"\"\"Complete 2-stage training pipeline.\"\"\"\n    print(\"--> STARTING ORDINAL REGRESSION TRAINING\")\n    print(\"=\" * 60)\n\n    # MODEL AND LOSSES\n    model = EfficientNetOrdinal('efficientnet_b2', num_classes=5).to(device)\n    print(f\"[INFO] Model created: EfficientNet-B2 with ordinal head\")\n\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_df['diagnosis']), y=train_df['diagnosis'])\n    class_weights = torch.FloatTensor(class_weights).to(device)\n    print(f\"Class weights: {class_weights.cpu().numpy().round(2)}\")\n\n    ce_loss = OrdinalCrossEntropyLoss(num_classes=5, class_weights=class_weights)\n    kappa_loss = SmoothKappaLoss(num_classes=5)\n    scaler = torch.amp.GradScaler('cuda')\n\n #   # STAGE 1: CROSS ENTROPY TRAINING\n #   print(\"\\n--> STAGE 1: CROSS ENTROPY TRAINING (30 EPOCHS)\")\n  #  print(\"=\" * 60)\n  #  optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n #   scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n  #  best_qwk_stage1 = 0\n  #  patience, patience_counter = 10, 0\n\n  #  for epoch in range(30):\n   #     clear_memory()\n  #      train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, optimizer, ce_loss, scaler, device)\n   #     val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, ce_loss, device)\n  #      scheduler.step()\n\n   #     print(f\"Epoch {epoch+1}/30:\")\n   #     print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}, QWK={train_qwk:.4f}, \\u00b11={train_within1:.4f}\")\n   #     print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.4f}, QWK={val_qwk:.4f}, \\u00b11={val_within1:.4f}\")\n\n   #     if val_qwk > best_qwk_stage1:\n     #       best_qwk_stage1 = val_qwk\n     #       torch.save(model.state_dict(), 'best_model_stage1.pth')\n     #       patience_counter = 0\n     #       print(f\"  [SAVE] New best QWK: {best_qwk_stage1:.4f}. Model saved!\")\n    #    else:\n     #       patience_counter += 1\n\n     #   if patience_counter >= patience:\n       #     print(f\"Early stopping at epoch {epoch+1}\")\n     #       break\n\n    print(f\"\\n[INFO] Stage 1 completed! Best QWK: {0.9051}\")\n    model.load_state_dict(torch.load('best_model_stage1.pth'))\n\n    # STAGE 2: KAPPA LOSS FINE-TUNING\n    print(\"\\n--> STAGE 2: KAPPA LOSS FINE-TUNING (30 EPOCHS)\")\n    print(\"=\" * 60)\n    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n    best_qwk_stage2 = 0.9051\n    patience_counter = 0\n\n    for epoch in range(30):\n        clear_memory()\n        train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, optimizer, kappa_loss, scaler, device)\n        val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, kappa_loss, device)\n        scheduler.step()\n\n        print(f\"Epoch {epoch+1}/30:\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}, QWK={train_qwk:.4f}, \\u00b11={train_within1:.4f}\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.4f}, QWK={val_qwk:.4f}, \\u00b11={val_within1:.4f}\")\n\n        if val_qwk > best_qwk_stage2:\n            best_qwk_stage2 = val_qwk\n            torch.save(model.state_dict(), 'best_model_final.pth')\n            patience_counter = 0\n            print(f\"  [SAVE] New best QWK: {best_qwk_stage2:.4f}. Model saved!\")\n        else:\n            patience_counter += 1\n\n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n    print(f\"\\n--> TRAINING COMPLETED!\")\n    print(\"=\" * 60)\n    print(f\"Stage 1 Best QWK: {best_qwk_stage1:.4f}\")\n    print(f\"Stage 2 Best QWK: {best_qwk_stage2:.4f}\")\n    print(f\"Improvement: {best_qwk_stage2 - best_qwk_stage1:.4f}\")\n\n    model.load_state_dict(torch.load('best_model_final.pth'))\n    return model\n\n# =============================================================================\n# RUN TRAINING\n# =============================================================================\n\nif __name__ == \"__main__\":\n    # --- CONFIGURATION ---\n    IMG_SIZE = 256\n    BATCH_SIZE = 16\n    NUM_WORKERS = 2 # On Kaggle, 2 is often a good choice\n\n    # Set device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n\n    # Enable memory management for PyTorch\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n    # --- DATA PREPARATION ---\n    # This is an example. Replace with your actual data paths and dataframe loading.\n    # On Kaggle, paths are typically like '/kaggle/input/aptos2019-blindness-detection/'\n\n    try:\n        # Define paths based on the screenshot\n        BASE_PATH = '/kaggle/input/aptos2019/'\n        train_csv_path = os.path.join(BASE_PATH, 'train_1.csv')\n        val_csv_path = os.path.join(BASE_PATH, 'valid.csv')\n        train_img_dir = os.path.join(BASE_PATH, 'train_images', 'train_images')\n        val_img_dir = os.path.join(BASE_PATH, 'val_images', 'val_images')\n\n        # Load dataframes using the provided train/validation split\n        train_df = pd.read_csv(train_csv_path)\n        val_df = pd.read_csv(val_csv_path)\n\n        print(f\"Training data: {len(train_df)} samples\")\n        print(f\"Validation data: {len(val_df)} samples\")\n        print(f\"Class distribution in training:\\n{train_df['diagnosis'].value_counts().sort_index()}\")\n\n        # --- DATA AUGMENTATION & LOADERS ---\n        train_transforms = transforms.Compose([\n            AdvancedBenGrahamPreprocess(output_size=IMG_SIZE),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        val_transforms = transforms.Compose([\n            AdvancedBenGrahamPreprocess(output_size=IMG_SIZE),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        # Create separate datasets for training and validation\n        train_dataset = DiabeticRetinopathyDataset(train_df, train_img_dir, transform=train_transforms)\n        val_dataset = DiabeticRetinopathyDataset(val_df, val_img_dir, transform=val_transforms)\n\n        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n        # --- RUN TRAINING ---\n        final_model = main_training_pipeline(train_loader, val_loader, train_df, device)\n\n        print(\"\\n[SUCCESS] Training pipeline completed successfully!\")\n        print(\"Models saved:\")\n        print(\" - best_model_stage1.pth (after cross-entropy training)\")\n        print(\" - best_model_final.pth (after kappa loss fine-tuning)\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        print(\"[NOTE] Please ensure your data paths are correct and you have run this in an environment with the data.\")\n\n    print(\"[INFO] To run the training, uncomment the code block in `if __name__ == '__main__':`\")\n    print(\"1. Set your BASE_PATH to the correct data directory.\")\n    print(\"2. Ensure your CSV file has 'id_code' and 'diagnosis' columns.\")\n    print(\"3. Run the script.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T07:13:11.805966Z","iopub.status.idle":"2025-09-10T07:13:11.806336Z","shell.execute_reply.started":"2025-09-10T07:13:11.806168Z","shell.execute_reply":"2025-09-10T07:13:11.806185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nprint(os.listdir(\"/kaggle/working\"))   # check working directory\nwith open(\"/kaggle/working/\") as f:\n    data = f.read()\n    print(data[:200])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T07:13:11.807085Z","iopub.status.idle":"2025-09-10T07:13:11.807347Z","shell.execute_reply.started":"2025-09-10T07:13:11.807235Z","shell.execute_reply":"2025-09-10T07:13:11.807249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image\nimport gc\nimport os\nimport timm\nimport cv2\n\n# =============================================================================\n# DATASET CLASS\n# =============================================================================\n\nclass DiabeticRetinopathyDataset(Dataset):\n    \"\"\"Custom Dataset for Diabetic Retinopathy images.\"\"\"\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.dataframe = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx]['id_code'] + '.png')\n        image = Image.open(img_name).convert('RGB')\n        label = torch.tensor(self.dataframe.iloc[idx]['diagnosis'], dtype=torch.long)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n\n# =============================================================================\n# ADVANCED PREPROCESSING TRANSFORM\n# =============================================================================\n\nclass AdvancedBenGrahamPreprocess(object):\n    \"\"\"Applies a series of robust preprocessing steps for fundus images.\"\"\"\n    def __init__(self, output_size=256):\n        assert isinstance(output_size, (int, tuple))\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        else:\n            assert len(output_size) == 2\n            self.output_size = output_size\n\n    def __call__(self, image):\n        # Convert PIL image to numpy array\n        img_np = np.array(image)\n\n        # 1. Crop black borders\n        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n        _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        if contours:\n            largest_contour = max(contours, key=cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(largest_contour)\n            img_np = img_np[y:y+h, x:x+w]\n\n        # 2. Apply CLAHE to the green channel for contrast enhancement\n        b, g, r = cv2.split(img_np)\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        g = clahe.apply(g)\n        img_clahe = cv2.merge((b, g, r))\n\n        # 3. Apply a gentle Gaussian blur to reduce noise\n        img_blur = cv2.GaussianBlur(img_clahe, (5, 5), 0)\n\n        # 4. Resize to target size\n        img_resized = cv2.resize(img_blur, self.output_size, interpolation=cv2.INTER_AREA)\n        \n        # Convert back to PIL Image\n        return Image.fromarray(img_resized)\n\n\n# =============================================================================\n# LOSS FUNCTIONS\n# =============================================================================\n\nclass OrdinalCrossEntropyLoss(nn.Module):\n    \"\"\"Cross Entropy Loss for Ordinal Regression.\"\"\"\n    def __init__(self, num_classes=5, class_weights=None):\n        super(OrdinalCrossEntropyLoss, self).__init__()\n        self.num_classes = num_classes\n        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n        self.class_weights = class_weights\n\n    def forward(self, outputs, targets):\n        \"\"\"\n        outputs: (batch_size, num_classes-1) ordinal logits\n        targets: (batch_size,) class labels 0 to num_classes-1\n        \"\"\"\n        # Create ordinal targets\n        ordinal_targets = torch.zeros_like(outputs)\n        for i, target in enumerate(targets):\n            if target > 0:\n                ordinal_targets[i, :target] = 1.0\n\n        losses = self.bce_loss(outputs, ordinal_targets)\n\n        if self.class_weights is not None:\n            weights = self.class_weights[targets]\n            return (losses.mean(dim=1) * weights).mean()\n        else:\n            return losses.mean()\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SmoothKappaLoss(nn.Module):\n    \"\"\"\n    Differentiable approximation of Quadratic Weighted Kappa (QWK) loss.\n    Works with ordinal regression outputs (num_classes - 1 logits).\n    \"\"\"\n    def __init__(self, num_classes=5, eps=1e-7):\n        super(SmoothKappaLoss, self).__init__()\n        self.num_classes = num_classes\n        self.eps = eps\n\n        # Precompute quadratic weights (normalized)\n        W = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes):\n                W[i, j] = ((i - j) ** 2) / ((num_classes - 1) ** 2)\n        self.register_buffer(\"W\", W)  # buffer ensures same device as model\n\n    def forward(self, outputs, targets):\n        \"\"\"\n        outputs: (batch_size, num_classes-1) ordinal logits\n        targets: (batch_size,) ground-truth labels\n        \"\"\"\n        device = outputs.device\n        B = outputs.size(0)\n\n        # Convert ordinal outputs -> class probabilities\n        probs = torch.sigmoid(outputs)\n        class_probs = torch.zeros(B, self.num_classes, device=device)\n        class_probs[:, 0] = 1 - probs[:, 0]\n        for k in range(1, self.num_classes - 1):\n            class_probs[:, k] = probs[:, k - 1] - probs[:, k]\n        class_probs[:, -1] = probs[:, -1]\n\n        class_probs = torch.clamp(class_probs, min=self.eps, max=1.0)\n        class_probs = class_probs / class_probs.sum(dim=1, keepdim=True)\n\n        # One-hot encode targets (make sure it's on the same device)\n        one_hot = F.one_hot(targets, num_classes=self.num_classes).float().to(device)\n\n        # Confusion matrix (soft)\n        conf_mat = torch.matmul(one_hot.T, class_probs)\n        conf_mat = conf_mat / (conf_mat.sum() + self.eps)\n\n        # Expected agreement\n        hist_true = one_hot.sum(dim=0)\n        hist_pred = class_probs.sum(dim=0)\n        expected = torch.outer(hist_true, hist_pred)\n        expected = expected / (expected.sum() + self.eps)\n\n        # Weighted observed & expected\n        W = self.W.to(device)  #  force on same device\n        obs = torch.sum(W * conf_mat)\n        exp = torch.sum(W * expected)\n\n        # Quadratic Kappa\n        kappa = 1.0 - obs / (exp + self.eps)\n\n        # Loss (want to maximize kappa, so minimize 1 - kappa)\n        return 1.0 - kappa\n\n\n\n# =============================================================================\n# MODEL\n# =============================================================================\n\nclass EfficientNetOrdinal(nn.Module):\n    \"\"\"EfficientNet for Ordinal Regression.\"\"\"\n    def __init__(self, model_name='efficientnet_b2', num_classes=5, pretrained=True):\n        super(EfficientNetOrdinal, self).__init__()\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=pretrained,\n            num_classes=0,  # Remove classification head\n            global_pool='avg'\n        )\n        feature_dim = self.backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes - 1)\n        )\n\n    def forward(self, x):\n        features = self.backbone(x)\n        logits = self.classifier(features)\n        return logits\n\n# =============================================================================\n# UTILITY FUNCTIONS\n# =============================================================================\n\ndef ordinal_to_class(outputs):\n    \"\"\"Convert ordinal outputs to class predictions.\"\"\"\n    probs = torch.sigmoid(outputs)\n    return torch.sum(probs > 0.5, dim=1).long()\n\ndef calculate_metrics(outputs, targets):\n    \"\"\"Calculate accuracy, QWK, and within-1 accuracy.\"\"\"\n    preds = ordinal_to_class(outputs).cpu().numpy()\n    targets_np = targets.cpu().numpy()\n    accuracy = accuracy_score(targets_np, preds)\n    qwk = cohen_kappa_score(targets_np, preds, weights='quadratic')\n    within1 = np.mean(np.abs(targets_np - preds) <= 1)\n    return accuracy, qwk, within1\n\ndef clear_memory():\n    \"\"\"Clear GPU memory.\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    gc.collect()\n\n# =============================================================================\n# TRAINING & VALIDATION LOOPS\n# =============================================================================\n\ndef train_epoch(model, train_loader, optimizer, criterion, scaler, device):\n    \"\"\"Train one epoch.\"\"\"\n    model.train()\n    running_loss = 0.0\n    all_outputs, all_targets = [], []\n\n    for images, targets in train_loader:\n        images, targets = images.to(device), targets.to(device)\n        optimizer.zero_grad()\n\n        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n        all_outputs.append(outputs.detach())\n        all_targets.append(targets.detach())\n\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    accuracy, qwk, within1 = calculate_metrics(all_outputs, all_targets)\n    return running_loss / len(train_loader), accuracy, qwk, within1\n\ndef validate_epoch(model, val_loader, criterion, device):\n    \"\"\"Validate one epoch.\"\"\"\n    model.eval()\n    running_loss = 0.0\n    all_outputs, all_targets = [], []\n\n    with torch.no_grad():\n        for images, targets in val_loader:\n            images, targets = images.to(device), targets.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            all_outputs.append(outputs)\n            all_targets.append(targets)\n\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    accuracy, qwk, within1 = calculate_metrics(all_outputs, all_targets)\n    return running_loss / len(val_loader), accuracy, qwk, within1\n\n# =============================================================================\n# MAIN TRAINING PIPELINE\n# =============================================================================\n\ndef main_training_pipeline(train_loader, val_loader, train_df, device):\n    \"\"\"Complete 2-stage training pipeline.\"\"\"\n    print(\"--> STARTING ORDINAL REGRESSION TRAINING\")\n    print(\"=\" * 60)\n\n    # MODEL AND LOSSES\n    model = EfficientNetOrdinal('efficientnet_b2', num_classes=5).to(device)\n    print(f\"[INFO] Model created: EfficientNet-B2 with ordinal head\")\n\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_df['diagnosis']), y=train_df['diagnosis'])\n    class_weights = torch.FloatTensor(class_weights).to(device)\n    print(f\"Class weights: {class_weights.cpu().numpy().round(2)}\")\n\n    ce_loss = OrdinalCrossEntropyLoss(num_classes=5, class_weights=class_weights)\n    kappa_loss = SmoothKappaLoss(num_classes=5)\n    scaler = torch.amp.GradScaler('cuda')\n\n    # STAGE 1: CROSS ENTROPY TRAINING\n    if (0) :\n        print(\"\\n--> STAGE 1: CROSS ENTROPY TRAINING (30 EPOCHS)\")\n        print(\"=\" * 60)\n        optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n        best_qwk_stage1 = 0\n        patience, patience_counter = 10, 0\n    \n        for epoch in range(30):\n            clear_memory()\n            train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, optimizer, ce_loss, scaler, device)\n            val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, ce_loss, device)\n            scheduler.step()\n    \n            print(f\"Epoch {epoch+1}/30:\")\n            print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}, QWK={train_qwk:.4f}, \\u00b11={train_within1:.4f}\")\n            print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.4f}, QWK={val_qwk:.4f}, \\u00b11={val_within1:.4f}\")\n    \n            if val_qwk > best_qwk_stage1:\n                best_qwk_stage1 = val_qwk\n                torch.save(model.state_dict(), 'best_model_stage1.pth')\n                patience_counter = 0\n                print(f\"  [SAVE] New best QWK: {best_qwk_stage1:.4f}. Model saved!\")\n            else:\n                patience_counter += 1\n    \n            if patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n\n    print(f\"\\n[INFO] Stage 1 completed! Best QWK: {0.9051}\")\n    model.load_state_dict(torch.load('best_model_stage1.pth'))\n\n    # STAGE 2: KAPPA LOSS FINE-TUNING\n    print(\"\\n--> STAGE 2: KAPPA LOSS FINE-TUNING (30 EPOCHS)\")\n    print(\"=\" * 60)\n    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n    best_qwk_stage2 = 0.9051\n    patience_counter = 0\n    patience=10\n\n    for epoch in range(30):\n        clear_memory()\n        train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, optimizer, kappa_loss, scaler, device)\n        val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, kappa_loss, device)\n        scheduler.step()\n\n        print(f\"Epoch {epoch+1}/30:\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}, QWK={train_qwk:.4f}, \\u00b11={train_within1:.4f}\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.4f}, QWK={val_qwk:.4f}, \\u00b11={val_within1:.4f}\")\n\n        if val_qwk > best_qwk_stage2:\n            best_qwk_stage2 = val_qwk\n            torch.save(model.state_dict(), 'best_model_final.pth')\n            patience_counter = 0\n            print(f\"  [SAVE] New best QWK: {best_qwk_stage2:.4f}. Model saved!\")\n        else:\n            patience_counter += 1\n\n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n    print(f\"\\n--> TRAINING COMPLETED!\")\n    print(\"=\" * 60)\n    print(f\"Stage 1 Best QWK: {best_qwk_stage1:.4f}\")\n    print(f\"Stage 2 Best QWK: {best_qwk_stage2:.4f}\")\n    print(f\"Improvement: {best_qwk_stage2 - best_qwk_stage1:.4f}\")\n\n    model.load_state_dict(torch.load('best_model_final.pth'))\n    return model\n\n# =============================================================================\n# RUN TRAINING\n# =============================================================================\n\nif __name__ == \"__main__\":\n    # --- CONFIGURATION ---\n    IMG_SIZE = 256\n    BATCH_SIZE = 16\n    NUM_WORKERS = 2 # On Kaggle, 2 is often a good choice\n\n    # Set device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n\n    # Enable memory management for PyTorch\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n    # --- DATA PREPARATION ---\n    # This is an example. Replace with your actual data paths and dataframe loading.\n    # On Kaggle, paths are typically like '/kaggle/input/aptos2019-blindness-detection/'\n\n    try:\n        # Define paths based on the screenshot\n        BASE_PATH = '/kaggle/input/aptos2019/'\n        train_csv_path = os.path.join(BASE_PATH, 'train_1.csv')\n        val_csv_path = os.path.join(BASE_PATH, 'valid.csv')\n        train_img_dir = os.path.join(BASE_PATH, 'train_images', 'train_images')\n        val_img_dir = os.path.join(BASE_PATH, 'val_images', 'val_images')\n\n        # Load dataframes using the provided train/validation split\n        train_df = pd.read_csv(train_csv_path)\n        val_df = pd.read_csv(val_csv_path)\n\n        print(f\"Training data: {len(train_df)} samples\")\n        print(f\"Validation data: {len(val_df)} samples\")\n        print(f\"Class distribution in training:\\n{train_df['diagnosis'].value_counts().sort_index()}\")\n\n        # --- DATA AUGMENTATION & LOADERS ---\n        train_transforms = transforms.Compose([\n            AdvancedBenGrahamPreprocess(output_size=IMG_SIZE),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        val_transforms = transforms.Compose([\n            AdvancedBenGrahamPreprocess(output_size=IMG_SIZE),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        # Create separate datasets for training and validation\n        train_dataset = DiabeticRetinopathyDataset(train_df, train_img_dir, transform=train_transforms)\n        val_dataset = DiabeticRetinopathyDataset(val_df, val_img_dir, transform=val_transforms)\n\n        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n        # --- RUN TRAINING ---\n        final_model = main_training_pipeline(train_loader, val_loader, train_df, device)\n\n        print(\"\\n[SUCCESS] Training pipeline completed successfully!\")\n        print(\"Models saved:\")\n        print(\" - best_model_stage1.pth (after cross-entropy training)\")\n        print(\" - best_model_final.pth (after kappa loss fine-tuning)\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        print(\"[NOTE] Please ensure your data paths are correct and you have run this in an environment with the data.\")\n\n    print(\"[INFO] To run the training, uncomment the code block in `if __name__ == '__main__':`\")\n    print(\"1. Set your BASE_PATH to the correct data directory.\")\n    print(\"2. Ensure your CSV file has 'id_code' and 'diagnosis' columns.\")\n    print(\"3. Run the script.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T07:13:11.808228Z","iopub.status.idle":"2025-09-10T07:13:11.808441Z","shell.execute_reply.started":"2025-09-10T07:13:11.808339Z","shell.execute_reply":"2025-09-10T07:13:11.808348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2nd try   \nstage 1=> BCE\nstage 2=> kappa loss\n\n+ extra preprocessing steps","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import WeightedRandomSampler\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image\nimport gc\nimport os\nimport timm\nimport cv2\n\n# =============================================================================\n# DATASET CLASS\n# =============================================================================\nclass DiabeticRetinopathyDataset(Dataset):\n    \"\"\"Custom Dataset for Diabetic Retinopathy images.\"\"\"\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.dataframe = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx]['id_code'] + '.png')\n        image = Image.open(img_name).convert('RGB')\n        label = torch.tensor(self.dataframe.iloc[idx]['diagnosis'], dtype=torch.long)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# =============================================================================\n# ADVANCED PREPROCESSING TRANSFORM\n# =============================================================================\nclass AdvancedBenGrahamPreprocess(object):\n    \"\"\"Applies a series of robust preprocessing steps for fundus images.\"\"\"\n    def __init__(self, output_size=256):\n        assert isinstance(output_size, (int, tuple))\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        else:\n            assert len(output_size) == 2\n            self.output_size = output_size\n\n    def __call__(self, image):\n        img_np = np.array(image)\n        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n        _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        if contours:\n            largest_contour = max(contours, key=cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(largest_contour)\n            img_np = img_np[y:y+h, x:x+w]\n        b, g, r = cv2.split(img_np)\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        g = clahe.apply(g)\n        img_clahe = cv2.merge((b, g, r))\n        img_blur = cv2.GaussianBlur(img_clahe, (5, 5), 0)\n        img_resized = cv2.resize(img_blur, self.output_size, interpolation=cv2.INTER_AREA)\n        return Image.fromarray(img_resized)\n\n# =============================================================================\n# LOSS FUNCTIONS\n# =============================================================================\nclass OrdinalCrossEntropyLoss(nn.Module):\n    \"\"\"Cross Entropy Loss for Ordinal Regression.\"\"\"\n    def __init__(self, num_classes=5, class_weights=None):\n        super(OrdinalCrossEntropyLoss, self).__init__()\n        self.num_classes = num_classes\n        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n        self.class_weights = class_weights\n\n    def forward(self, outputs, targets):\n        ordinal_targets = torch.zeros_like(outputs)\n        for i, target in enumerate(targets):\n            if target > 0:\n                ordinal_targets[i, :target] = 1.0\n        losses = self.bce_loss(outputs, ordinal_targets)\n        if self.class_weights is not None:\n            weights = self.class_weights[targets]\n            return (losses.mean(dim=1) * weights).mean()\n        else:\n            return losses.mean()\n            \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SmoothKappaLoss(nn.Module):\n    \"\"\"\n    Differentiable approximation of Quadratic Weighted Kappa (QWK) loss.\n    \"\"\"\n    def __init__(self, num_classes=5, eps=1e-7):\n        super(SmoothKappaLoss, self).__init__()\n        self.num_classes = num_classes\n        self.eps = eps\n        W = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes):\n                W[i, j] = ((i - j) ** 2) / ((num_classes - 1) ** 2)\n        self.register_buffer(\"W\", W)\n\n    def forward(self, outputs, targets):\n        device = outputs.device\n        B = outputs.size(0)\n        probs = torch.sigmoid(outputs)\n        class_probs = torch.zeros(B, self.num_classes, device=device)\n        class_probs[:, 0] = 1 - probs[:, 0]\n        for k in range(1, self.num_classes - 1):\n            class_probs[:, k] = probs[:, k - 1] - probs[:, k]\n        class_probs[:, -1] = probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=self.eps, max=1.0)\n        class_probs = class_probs / class_probs.sum(dim=1, keepdim=True)\n        one_hot = F.one_hot(targets, num_classes=self.num_classes).float().to(device)\n        conf_mat = torch.matmul(one_hot.T, class_probs)\n        conf_mat = conf_mat / (conf_mat.sum() + self.eps)\n        hist_true = one_hot.sum(dim=0)\n        hist_pred = class_probs.sum(dim=0)\n        expected = torch.outer(hist_true, hist_pred)\n        expected = expected / (expected.sum() + self.eps)\n        W = self.W.to(device)\n        obs = torch.sum(W * conf_mat)\n        exp = torch.sum(W * expected)\n        kappa = 1.0 - obs / (exp + self.eps)\n        return 1.0 - kappa\n\n# =============================================================================\n# MODEL\n# =============================================================================\nclass EfficientNetOrdinal(nn.Module):\n    \"\"\"EfficientNet for Ordinal Regression.\"\"\"\n    def __init__(self, model_name='efficientnet_b2', num_classes=5, pretrained=True):\n        super(EfficientNetOrdinal, self).__init__()\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=pretrained,\n            num_classes=0,\n            global_pool='avg'\n        )\n        feature_dim = self.backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.4), # Increased dropout for better regularization\n            nn.Linear(feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3), # Increased dropout for better regularization\n            nn.Linear(256, num_classes - 1)\n        )\n    def forward(self, x):\n        features = self.backbone(x)\n        logits = self.classifier(features)\n        return logits\n\n# =============================================================================\n# UTILITY FUNCTIONS\n# =============================================================================\ndef ordinal_to_class(outputs):\n    \"\"\"Convert ordinal outputs to class predictions.\"\"\"\n    probs = torch.sigmoid(outputs)\n    return torch.sum(probs > 0.5, dim=1).long()\n\ndef calculate_metrics(outputs, targets):\n    \"\"\"Calculate accuracy, QWK, and within-1 accuracy.\"\"\"\n    preds = ordinal_to_class(outputs).cpu().numpy()\n    targets_np = targets.cpu().numpy()\n    accuracy = accuracy_score(targets_np, preds)\n    qwk = cohen_kappa_score(targets_np, preds, weights='quadratic')\n    within1 = np.mean(np.abs(targets_np - preds) <= 1)\n    return accuracy, qwk, within1\n\ndef clear_memory():\n    \"\"\"Clear GPU memory.\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    gc.collect()\n    \ndef mixup_data(x, y, alpha=0.4):\n    '''Returns mixed inputs, targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n# =============================================================================\n# TRAINING & VALIDATION LOOPS - MODIFIED\n# =============================================================================\ndef train_epoch(model, train_loader, optimizer, criterion, scaler, device):\n    \"\"\"Train one epoch.\"\"\"\n    model.train()\n    running_loss = 0.0\n    all_outputs, all_targets = [], []\n    is_ce_loss = isinstance(criterion, OrdinalCrossEntropyLoss)\n\n    for images, targets in train_loader:\n        images, targets = images.to(device), targets.to(device)\n        optimizer.zero_grad()\n        if is_ce_loss:\n            images, targets_a, targets_b, lam = mixup_data(images, targets)\n        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = model(images)\n            if is_ce_loss:\n                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n            else:\n                loss = criterion(outputs, targets)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        running_loss += loss.item()\n        all_outputs.append(outputs.detach())\n        all_targets.append(targets.detach())\n\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    accuracy, qwk, within1 = calculate_metrics(all_outputs, all_targets)\n    return running_loss / len(train_loader), accuracy, qwk, within1\n\ndef validate_epoch(model, val_loader, criterion, device):\n    \"\"\"Validate one epoch.\"\"\"\n    model.eval()\n    running_loss = 0.0\n    all_outputs, all_targets = [], []\n    with torch.no_grad():\n        for images, targets in val_loader:\n            images, targets = images.to(device), targets.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            all_outputs.append(outputs)\n            all_targets.append(targets)\n    all_outputs = torch.cat(all_outputs)\n    all_targets = torch.cat(all_targets)\n    accuracy, qwk, within1 = calculate_metrics(all_outputs, all_targets)\n    return running_loss / len(val_loader), accuracy, qwk, within1\n\n# =============================================================================\n# MAIN TRAINING PIPELINE\n# =============================================================================\ndef main_training_pipeline(train_loader, val_loader, train_df, device):\n    \"\"\"Complete 2-stage training pipeline.\"\"\"\n    print(\"--> STARTING ORDINAL REGRESSION TRAINING\")\n    print(\"=\" * 60)\n    model = EfficientNetOrdinal('efficientnet_b2', num_classes=5).to(device)\n    print(f\"[INFO] Model created: EfficientNet-B2 with ordinal head\")\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_df['diagnosis']), y=train_df['diagnosis'])\n    class_weights = torch.FloatTensor(class_weights).to(device)\n    print(f\"Class weights: {class_weights.cpu().numpy().round(2)}\")\n    ce_loss = OrdinalCrossEntropyLoss(num_classes=5, class_weights=class_weights)\n    kappa_loss = SmoothKappaLoss(num_classes=5)\n    scaler = torch.amp.GradScaler('cuda')\n\n    # STAGE 1: CROSS ENTROPY TRAINING - **FIXED**\n    if (0):\n        print(\"\\n--> STAGE 1: CROSS ENTROPY TRAINING (30 EPOCHS)\")\n        print(\"=\" * 60)\n        optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n        scheduler = optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=1e-3,\n            steps_per_epoch=len(train_loader),\n            epochs=30\n        )\n        best_qwk_stage1 = 0\n        patience, patience_counter = 10, 0\n        \n        for epoch in range(30):\n            clear_memory()\n            train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, optimizer, ce_loss, scaler, device)\n            val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, ce_loss, device)\n            scheduler.step()\n            \n            print(f\"Epoch {epoch+1}/30:\")\n            print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}, QWK={train_qwk:.4f}, \\u00b11={train_within1:.4f}\")\n            print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.4f}, QWK={val_qwk:.4f}, \\u00b11={val_within1:.4f}\")\n            \n            if val_qwk > best_qwk_stage1:\n                best_qwk_stage1 = val_qwk\n                torch.save(model.state_dict(), 'best_model_try2_stage1.pth')\n                patience_counter = 0\n                print(f\"  [SAVE] New best QWK: {best_qwk_stage1:.4f}. Model saved!\")\n            else:\n                patience_counter += 1\n            \n            if patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n\n    print(f\"\\n[INFO] Stage 1 completed! Best QWK: {0.8984:.4f}\")\n    model.load_state_dict(torch.load('/kaggle/input/hiiiiii/best_model_try2_stage1.pth'))\n#######################################################\n    # STAGE 2: KAPPA LOSS FINE-TUNING\n    print(\"\\n--> STAGE 2: KAPPA LOSS FINE-TUNING (30 EPOCHS)\")\n    print(\"=\" * 60)\n    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=1e-4,\n        steps_per_epoch=len(train_loader),\n        epochs=30\n    )\n    best_qwk_stage2 = 0.8984\n    patience_counter = 0\n    patience=10\n\n    for epoch in range(30):\n        clear_memory()\n        train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, optimizer, kappa_loss, scaler, device)\n        val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, kappa_loss, device)\n        scheduler.step()\n\n        print(f\"Epoch {epoch+1}/30:\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}, QWK={train_qwk:.4f}, \\u00b11={train_within1:.4f}\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.4f}, QWK={val_qwk:.4f}, \\u00b11={val_within1:.4f}\")\n\n        if val_qwk > best_qwk_stage2:\n            best_qwk_stage2 = val_qwk\n            torch.save(model.state_dict(), 'best_model_final_try2.pth')\n            patience_counter = 0\n            print(f\"  [SAVE] New best QWK: {best_qwk_stage2:.4f}. Model saved!\")\n        else:\n            patience_counter += 1\n\n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n    print(f\"\\n--> TRAINING COMPLETED!\")\n    print(\"=\" * 60)\n    print(f\"Stage 1 Best QWK: {best_qwk_stage1:.4f}\")\n    print(f\"Stage 2 Best QWK: {best_qwk_stage2:.4f}\")\n    print(f\"Improvement: {best_qwk_stage2 - best_qwk_stage1:.4f}\")\n\n    if os.path.exists('best_model_final_try2.pth'):\n        model.load_state_dict(torch.load('best_model_final_try2.pth'))\n    else:\n        print(\"Warning: Final model not found. Returning last model state.\")\n        \n    return model\n\n# =============================================================================\n# RUN TRAINING - FINAL\n# =============================================================================\nif __name__ == \"__main__\":\n    # --- CONFIGURATION ---\n    IMG_SIZE = 256\n    BATCH_SIZE = 16\n    NUM_WORKERS = 2 \n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n    \n    try:\n        # --- CORRECTED DATA PATHS ---\n        BASE_PATH = '/kaggle/input/aptos2019/'\n        train_csv_path = os.path.join(BASE_PATH, 'train_1.csv')\n        val_csv_path = os.path.join(BASE_PATH, 'valid.csv')\n        train_img_dir = os.path.join(BASE_PATH, 'train_images', 'train_images')\n        val_img_dir = os.path.join(BASE_PATH, 'val_images', 'val_images')\n\n        train_df = pd.read_csv(train_csv_path)\n        val_df = pd.read_csv(val_csv_path)\n        \n        print(f\"Training data: {len(train_df)} samples\")\n        print(f\"Validation data: {len(val_df)} samples\")\n        print(f\"Class distribution in training:\\n{train_df['diagnosis'].value_counts().sort_index()}\")\n\n        # --- Weighted Random Sampler (for imbalanced data) ---\n        class_counts = train_df['diagnosis'].value_counts().sort_index()\n        num_samples = len(train_df)\n        class_weights_sampler = 1.0 / class_counts.values\n        sample_weights = np.array([class_weights_sampler[t] for t in train_df['diagnosis']])\n        sample_weights = torch.from_numpy(sample_weights).double()\n        \n        train_sampler = WeightedRandomSampler(\n            weights=sample_weights,\n            num_samples=num_samples,\n            replacement=True\n        )\n\n        # --- DATA AUGMENTATION & LOADERS ---\n        train_transforms = transforms.Compose([\n            AdvancedBenGrahamPreprocess(output_size=IMG_SIZE),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        val_transforms = transforms.Compose([\n            AdvancedBenGrahamPreprocess(output_size=IMG_SIZE),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        train_dataset = DiabeticRetinopathyDataset(train_df, train_img_dir, transform=train_transforms)\n        val_dataset = DiabeticRetinopathyDataset(val_df, val_img_dir, transform=val_transforms)\n\n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=BATCH_SIZE, \n            sampler=train_sampler,\n            num_workers=NUM_WORKERS, \n            pin_memory=True\n        )\n        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n        final_model = main_training_pipeline(train_loader, val_loader, train_df, device)\n        print(\"\\n[SUCCESS] Training pipeline completed successfully!\")\n        \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        print(\"[NOTE] Please ensure your data paths are correct and the required libraries are installed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T07:13:59.460295Z","iopub.execute_input":"2025-09-10T07:13:59.460606Z","iopub.status.idle":"2025-09-10T08:13:43.608541Z","shell.execute_reply.started":"2025-09-10T07:13:59.460583Z","shell.execute_reply":"2025-09-10T08:13:43.607187Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nTraining data: 2930 samples\nValidation data: 366 samples\nClass distribution in training:\ndiagnosis\n0    1434\n1     300\n2     808\n3     154\n4     234\nName: count, dtype: int64\n--> STARTING ORDINAL REGRESSION TRAINING\n============================================================\n[INFO] Model created: EfficientNet-B2 with ordinal head\nClass weights: [0.41 1.95 0.73 3.81 2.5 ]\n\n[INFO] Stage 1 completed! Best QWK: 0.8984\n\n--> STAGE 2: KAPPA LOSS FINE-TUNING (30 EPOCHS)\n============================================================\nEpoch 1/30:\n  Train: Loss=0.1836, Acc=0.8273, QWK=0.9437, 1=0.9833\n  Val:   Loss=0.2576, Acc=0.7295, QWK=0.8526, 1=0.9262\nEpoch 2/30:\n  Train: Loss=0.1501, Acc=0.8137, QWK=0.9361, 1=0.9805\n  Val:   Loss=0.2133, Acc=0.7186, QWK=0.8651, 1=0.9645\nEpoch 3/30:\n  Train: Loss=0.1125, Acc=0.8266, QWK=0.9485, 1=0.9887\n  Val:   Loss=0.1931, Acc=0.7158, QWK=0.8688, 1=0.9699\nEpoch 4/30:\n  Train: Loss=0.1010, Acc=0.8311, QWK=0.9510, 1=0.9908\n  Val:   Loss=0.1808, Acc=0.7186, QWK=0.8596, 1=0.9617\nEpoch 5/30:\n  Train: Loss=0.0983, Acc=0.8389, QWK=0.9487, 1=0.9881\n  Val:   Loss=0.1776, Acc=0.7240, QWK=0.8578, 1=0.9645\nEpoch 6/30:\n  Train: Loss=0.0893, Acc=0.8389, QWK=0.9503, 1=0.9877\n  Val:   Loss=0.1580, Acc=0.7432, QWK=0.8707, 1=0.9672\nEpoch 7/30:\n  Train: Loss=0.0804, Acc=0.8519, QWK=0.9548, 1=0.9894\n  Val:   Loss=0.1567, Acc=0.7322, QWK=0.8599, 1=0.9590\nEpoch 8/30:\n  Train: Loss=0.0811, Acc=0.8618, QWK=0.9555, 1=0.9901\n  Val:   Loss=0.1383, Acc=0.7623, QWK=0.8854, 1=0.9617\nEpoch 9/30:\n  Train: Loss=0.0740, Acc=0.8563, QWK=0.9605, 1=0.9952\n  Val:   Loss=0.1452, Acc=0.7350, QWK=0.8603, 1=0.9590\nEpoch 10/30:\n  Train: Loss=0.0725, Acc=0.8614, QWK=0.9562, 1=0.9901\n  Val:   Loss=0.1395, Acc=0.7486, QWK=0.8766, 1=0.9617\nEarly stopping at epoch 10\n\n--> TRAINING COMPLETED!\n============================================================\nAn error occurred: cannot access local variable 'best_qwk_stage1' where it is not associated with a value\n[NOTE] Please ensure your data paths are correct and the required libraries are installed.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"3rd try   \nstage 1=> focal loss\nstage 2=> 0.5 focal loss +0.5 kappa loss","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torchvision.transforms as transforms\n\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport timm\n\n# ---------------------------\n# CONFIG\n# ---------------------------\nBASE_PATH = \"/kaggle/input/aptos2019\"\nTRAIN_CSV = os.path.join(BASE_PATH, \"train_1.csv\")\nVAL_CSV   = os.path.join(BASE_PATH, \"valid.csv\")\nTEST_CSV  = os.path.join(BASE_PATH, \"test.csv\")\n\nTRAIN_DIR = os.path.join(BASE_PATH, \"train_images\", \"train_images\")\nVAL_DIR   = os.path.join(BASE_PATH, \"val_images\", \"val_images\")\nTEST_DIR  = os.path.join(BASE_PATH, \"test_images\", \"test_images\")\n\nIMG_SIZE = 256\nBATCH_SIZE = 16\nNUM_WORKERS = 2\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nPRINT_FREQ = 1\n\n# ---------------------------\n# Preprocessing helpers\n# ---------------------------\n\ndef crop_black_border_and_center(img_np, thresh_val=10):\n    \"\"\"Crop black borders by thresholding then return cropped image.\"\"\"\n    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n    _, thresh = cv2.threshold(gray, thresh_val, 255, cv2.THRESH_BINARY)\n    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    if contours:\n        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n        return img_np[y:y+h, x:x+w]\n    return img_np\n\ndef crop_circle_hough(img_np):\n    \"\"\"Attempt HoughCircle to center on retina and crop a circular region (useful when vinette exists).\"\"\"\n    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n    gray = cv2.medianBlur(gray, 5)\n    h, w = gray.shape\n    minr = int(min(h, w) * 0.2)\n    maxr = int(min(h, w) * 0.6)\n    circles = None\n    try:\n        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1, minDist=100,\n                                   param1=50, param2=30,\n                                   minRadius=minr, maxRadius=maxr)\n    except Exception:\n        circles = None\n    if circles is not None:\n        circles = np.uint16(np.around(circles))\n        x, y, r = circles[0][0]\n\n        # Explicitly cast to float to prevent the overflow warning\n        x_f, y_f, r_f = float(x), float(y), float(r)\n        \n        # Calculate coordinates\n        x1_f, y1_f = x_f - r_f, y_f - r_f\n        x2_f, y2_f = x_f + r_f, y_f + r_f\n        \n        # Clip and convert to int for slicing\n        x1 = int(np.clip(x1_f, 0, w))\n        y1 = int(np.clip(y1_f, 0, h))\n        x2 = int(np.clip(x2_f, 0, w))\n        y2 = int(np.clip(y2_f, 0, h))\n        \n        if x2 > x1 and y2 > y1:\n            return img_np[y1:y2, x1:x2]\n    return img_np\n\n\ndef apply_clahe(img_np):\n    if img_np is None or img_np.size == 0:\n        return img_np\n    if len(img_np.shape) != 3 or img_np.shape[2] != 3:\n        img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n    b, g, r = cv2.split(img_np)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    g = clahe.apply(g)\n    return cv2.merge((b, g, r))\n\n\ndef multiscale_retinex(img_np, scales=[15,80,250], weights=None):\n    \"\"\"Simple Multiscale Retinex (MSR) implementation.\n       img_np is RGB uint8 [H,W,3]\n    \"\"\"\n    if weights is None:\n        weights = [1/len(scales)] * len(scales)\n    img = img_np.astype(np.float32) + 1.0\n    retinex = np.zeros_like(img)\n    for i, scale in enumerate(scales):\n        blur = cv2.GaussianBlur(img, (0,0), sigmaX=scale, sigmaY=scale)\n        # avoid log(0)\n        retinex += weights[i] * (np.log(img) - np.log(blur + 1e-6))\n    # color restore\n    for c in range(3):\n        retinex[:,:,c] = (retinex[:,:,c] - np.min(retinex[:,:,c])) / (np.max(retinex[:,:,c]) - np.min(retinex[:,:,c]) + 1e-9) * 255.0\n    return retinex.astype(np.uint8)\n\ndef gaussian_filter(img_np, k=5):\n    return cv2.GaussianBlur(img_np, (k,k), 0)\n\ndef denoise_nlmeans(img_np):\n    # OpenCV fast NL means for colored images - moderate cost\n    return cv2.fastNlMeansDenoisingColored(img_np, None, h=10, hColor=10, templateWindowSize=7, searchWindowSize=21)\n\n\n# Combined preprocess pipeline\ndef preprocess_image_pipeline(pil_image, output_size=IMG_SIZE, do_msr=True, do_hough=True):\n    \"\"\"Takes PIL.Image, returns PIL.Image after preprocessing.\"\"\"\n    img_np = np.array(pil_image.convert('RGB'))\n\n    # 1. Crop black border\n    img_np = crop_black_border_and_center(img_np, thresh_val=10)\n\n    # 2. Attempt Hough crop (if it finds a circle, crop tighter)\n    if do_hough:\n        img_np = crop_circle_hough(img_np)\n\n    # 3. CLAHE on green channel\n    img_np = apply_clahe(img_np)\n\n    # 4. Mild denoise\n    img_np = denoise_nlmeans(img_np)\n\n    # 5. Gaussian smoothing\n    img_np = gaussian_filter(img_np, k=3)\n\n    # 6. Multiscale Retinex enhance (optional)\n    if do_msr:\n        try:\n            img_np = multiscale_retinex(img_np)\n        except Exception:\n            # fallback if something goes wrong\n            pass\n\n    # 7. Resize to output_size\n    img_resized = cv2.resize(img_np, (output_size, output_size), interpolation=cv2.INTER_AREA)\n    return Image.fromarray(img_resized)\n\n# ---------------------------\n# Dataset\n# ---------------------------\nclass DiabeticRetinopathyDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, preprocess_fn=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.preprocess_fn = preprocess_fn\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id_code'] + '.png')\n        img = Image.open(img_path).convert('RGB')\n\n        if self.preprocess_fn:\n            img = self.preprocess_fn(img)\n\n        if self.transform:\n            img = self.transform(img)\n        label = torch.tensor(row['diagnosis'], dtype=torch.long)\n        return img, label\n\n# ---------------------------\n# Losses & Model\n# ---------------------------\nclass OrdinalFocalLoss(nn.Module):\n    def __init__(self, num_classes=5, gamma=2.0):\n        super().__init__()\n        self.num_classes = num_classes\n        self.gamma = gamma\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n\n    def forward(self, outputs, targets):\n        # outputs: (B, C-1), targets: (B,)\n        ordinal_targets = torch.zeros_like(outputs)\n        for i, t in enumerate(targets):\n            if t > 0:\n                ordinal_targets[i, :t] = 1.0\n        bce = self.bce(outputs, ordinal_targets)\n        pt = torch.exp(-bce)\n        focal = (1 - pt) ** self.gamma * bce\n        return focal.mean()\n\nclass SmoothKappaLoss(nn.Module):\n    def __init__(self, num_classes=5, eps=1e-7):\n        super().__init__()\n        self.num_classes = num_classes\n        self.eps = eps\n        W = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes):\n                W[i,j] = ((i - j)**2) / ((num_classes - 1)**2)\n        self.register_buffer(\"W\", W)\n\n    def forward(self, outputs, targets):\n        device = outputs.device\n        B = outputs.size(0)\n        probs = torch.sigmoid(outputs)\n        class_probs = torch.zeros(B, self.num_classes, device=device)\n        class_probs[:, 0] = 1 - probs[:, 0]\n        for k in range(1, self.num_classes-1):\n            class_probs[:, k] = probs[:, k-1] - probs[:, k]\n        class_probs[:, -1] = probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=self.eps, max=1.0)\n        class_probs = class_probs / class_probs.sum(dim=1, keepdim=True)\n\n        one_hot = F.one_hot(targets, num_classes=self.num_classes).float().to(device)\n\n        conf_mat = torch.matmul(one_hot.T, class_probs)\n        conf_mat = conf_mat / (conf_mat.sum() + self.eps)\n\n        hist_true = one_hot.sum(dim=0)\n        hist_pred = class_probs.sum(dim=0)\n        expected = torch.outer(hist_true, hist_pred)\n        expected = expected / (expected.sum() + self.eps)\n\n        W = self.W.to(device)\n        obs = torch.sum(W * conf_mat)\n        exp = torch.sum(W * expected)\n        kappa = 1.0 - obs / (exp + self.eps)\n        return 1.0 - kappa\n\nclass EfficientNetOrdinal(nn.Module):\n    def __init__(self, model_name='efficientnet_b2', num_classes=5, pretrained=True):\n        super().__init__()\n        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n        feature_dim = self.backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes - 1)\n        )\n    def forward(self, x):\n        feat = self.backbone(x)\n        return self.classifier(feat)\n\n# ---------------------------\n# Utilities\n# ---------------------------\ndef ordinal_to_class(outputs):\n    probs = torch.sigmoid(outputs)\n    return torch.sum(probs > 0.5, dim=1).long()\n\ndef calculate_metrics(outputs, targets):\n    preds = ordinal_to_class(outputs).cpu().numpy()\n    targets_np = targets.cpu().numpy()\n    acc = accuracy_score(targets_np, preds)\n    qwk = cohen_kappa_score(targets_np, preds, weights='quadratic')\n    within1 = np.mean(np.abs(targets_np - preds) <= 1)\n    return acc, qwk, within1\n\ndef clear_memory():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\ndef mixup_data(x, y, alpha=0.4):\n    '''Returns mixed inputs, targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n# ---------------------------\n# Training loops\n# ---------------------------\ndef train_epoch(model, loader, optimizer, criterion, scaler, device, use_mixup=True):\n    model.train()\n    running_loss = 0.0\n    all_out, all_t = [], []\n    for images, targets in loader:\n        images, targets = images.to(device), targets.to(device)\n        optimizer.zero_grad()\n        \n        if use_mixup:\n            images, targets_a, targets_b, lam = mixup_data(images, targets)\n        \n        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n            outputs = model(images)\n            if use_mixup:\n                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n            else:\n                loss = criterion(outputs, targets)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        running_loss += loss.item()\n        \n        all_out.append(outputs.detach())\n        all_t.append(targets.detach())\n    \n    all_out = torch.cat(all_out)\n    all_t = torch.cat(all_t)\n    return running_loss / len(loader), *calculate_metrics(all_out, all_t)\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_out, all_t = [], []\n    with torch.no_grad():\n        for images, targets in loader:\n            images, targets = images.to(device), targets.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, targets) if not isinstance(criterion, nn.Module) else criterion(outputs, targets)\n            running_loss += loss.item()\n            all_out.append(outputs)\n            all_t.append(targets)\n    all_out = torch.cat(all_out)\n    all_t = torch.cat(all_t)\n    return running_loss / len(loader), *calculate_metrics(all_out, all_t)\n\n# ---------------------------\n# Threshold optimization (simple grid) for ordinal outputs\n# ---------------------------\ndef optimize_thresholds(model, loader, device):\n    # Evaluate class probabilities on loader and perform simple rounding threshold search\n    model.eval()\n    probs_list, labels_list = [], []\n    with torch.no_grad():\n        for images, targets in loader:\n            images = images.to(device)\n            outputs = model(images)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            probs_list.append(probs)\n            labels_list.append(targets.numpy())\n    probs = np.vstack(probs_list)\n    labels = np.concatenate(labels_list)\n\n    # build class predictions by varying a simple single threshold t applied to each ordinal logit\n    best_t = 0.5\n    best_qwk = -1\n    for t in np.linspace(0.3, 0.7, 9):\n        preds = np.sum(probs > t, axis=1)\n        qwk = cohen_kappa_score(labels, preds, weights='quadratic')\n        if qwk > best_qwk:\n            best_qwk = qwk\n            best_t = t\n    return best_t, best_qwk\n\n# ---------------------------\n# TTA inference (averaging flips)\n# ---------------------------\ndef tta_predict(model, image_pil, device, tta_transforms):\n    model.eval()\n    probs_acc = None\n    with torch.no_grad():\n        for tf in tta_transforms:\n            x = tf(image_pil).unsqueeze(0).to(device)\n            out = model(x)\n            p = torch.sigmoid(out).cpu().numpy()\n            probs_acc = p if probs_acc is None else probs_acc + p\n    probs_acc /= len(tta_transforms)\n    return probs_acc[0]\n\n# ---------------------------\n# Main training pipeline\n# ---------------------------\ndef main():\n    print(\"Device:\", DEVICE)\n    # load csvs\n    train_df = pd.read_csv(TRAIN_CSV)\n    val_df = pd.read_csv(VAL_CSV)\n    test_df = pd.read_csv(TEST_CSV)\n\n    print(\"Train samples:\", len(train_df), \"Val samples:\", len(val_df))\n\n    # transforms\n    train_tf = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=0.12, contrast=0.12, saturation=0.12, hue=0.04),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n    ])\n    val_tf = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n    ])\n\n    # dataset\n    train_ds = DiabeticRetinopathyDataset(train_df, TRAIN_DIR, transform=train_tf, preprocess_fn=lambda p: preprocess_image_pipeline(p, output_size=IMG_SIZE))\n    val_ds   = DiabeticRetinopathyDataset(val_df, VAL_DIR, transform=val_tf, preprocess_fn=lambda p: preprocess_image_pipeline(p, output_size=IMG_SIZE))\n    test_ds  = DiabeticRetinopathyDataset(test_df, TEST_DIR, transform=val_tf, preprocess_fn=lambda p: preprocess_image_pipeline(p, output_size=IMG_SIZE))\n\n    # Weighted sampler to balance classes\n    class_counts = train_df['diagnosis'].value_counts().sort_index().values\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_df['diagnosis']), y=train_df['diagnosis'])\n    sample_weights = np.array([class_weights[int(l)] for l in train_df['diagnosis']])\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n\n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n    # Model and losses\n    model = EfficientNetOrdinal('efficientnet_b2', num_classes=5).to(DEVICE)\n    focal = OrdinalFocalLoss(num_classes=5, gamma=2.0)\n    kappa = SmoothKappaLoss(num_classes=5)\n    # Using the new, non-deprecated syntax\n    scaler = torch.amp.GradScaler(device=\"cuda\", enabled=torch.cuda.is_available())\n\n    # STAGE 1: focal training\n    opt = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=5e-4)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=30)\n    best_val_qwk = -1\n    patience = 5\n    wait = 0\n\n    for epoch in range(30):\n        clear_memory()\n        train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, opt, focal, scaler, DEVICE, use_mixup=True)\n        val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, focal, DEVICE)\n        sched.step()\n\n        if (epoch+1) % PRINT_FREQ == 0:\n            print(f\"[Stage1] Epoch {epoch+1:02d} Train QWK: {train_qwk:.4f} | Val QWK: {val_qwk:.4f} | Val Acc: {val_acc:.4f}\")\n\n        if val_qwk > best_val_qwk:\n            best_val_qwk = val_qwk\n            torch.save(model.state_dict(), \"best_model_stage1.pth\")\n            wait = 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping Stage 1\")\n                break\n\n    # reload best stage1\n    model.load_state_dict(torch.load(\"best_model_stage1.pth\"))\n\n    # STAGE 2: hybrid loss (0.5 kappa + 0.5 focal)\n    opt = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=30)\n    best_val_qwk_stage2 = best_val_qwk\n    wait = 0\n    def hybrid(outputs, targets):\n        return 0.5 * kappa(outputs, targets) + 0.5 * focal(outputs, targets)\n\n    for epoch in range(30):\n        clear_memory()\n        train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, opt, hybrid, scaler, DEVICE, use_mixup=False)\n        val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, hybrid, DEVICE)\n        sched.step()\n\n        if (epoch+1) % PRINT_FREQ == 0:\n            print(f\"[Stage2] Epoch {epoch+1:02d} Train QWK: {train_qwk:.4f} | Val QWK: {val_qwk:.4f} | Val Acc: {val_acc:.4f}\")\n\n        if val_qwk > best_val_qwk_stage2:\n            best_val_qwk_stage2 = val_qwk\n            torch.save(model.state_dict(), \"best_model_final.pth\")\n            wait = 0\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping Stage 2\")\n                break\n\n    # load best final\n    model.load_state_dict(torch.load(\"best_model_final.pth\"))\n    print(\"Best Stage1 QWK:\", best_val_qwk, \"Best Stage2 QWK:\", best_val_qwk_stage2)\n\n    # Find best threshold on validation (simple search)\n    best_t, best_qwk_found = optimize_thresholds(model, val_loader, DEVICE)\n    print(\"Optimized ordinal threshold:\", best_t, \"val qwk:\", best_qwk_found)\n\n    # TTA transforms (simple set)\n    tta_transforms = [\n        lambda x: val_tf(x),\n        lambda x: val_tf(x.transpose(Image.FLIP_LEFT_RIGHT)),\n        lambda x: val_tf(x.transpose(Image.FLIP_TOP_BOTTOM)),\n    ]\n\n    # Inference on test set using TTA and threshold\n    model.eval()\n    ids, preds = [], []\n    with torch.no_grad():\n        for img_idx in tqdm(range(len(test_df))):\n            row = test_df.iloc[img_idx]\n            img_path = os.path.join(TEST_DIR, row['id_code'] + '.png')\n            pil = Image.open(img_path).convert('RGB')\n            probs_acc = None\n            # perform TTA\n            for tf in tta_transforms:\n                x = tf(pil).unsqueeze(0).to(DEVICE)\n                out = model(x)\n                p = torch.sigmoid(out).cpu().numpy()\n                probs_acc = p if probs_acc is None else probs_acc + p\n            probs_acc /= len(tta_transforms)\n            pred = int(np.sum(probs_acc > best_t))\n            ids.append(row['id_code'])\n            preds.append(pred)\n\n    submission = pd.DataFrame({\"id_code\": ids, \"diagnosis\": preds})\n    submission.to_csv(\"submission.csv\", index=False)\n    print(\"Saved submission.csv\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T08:13:43.611426Z","iopub.execute_input":"2025-09-10T08:13:43.611776Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nTrain samples: 2930 Val samples: 366\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_441/2751803802.py:307: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"4th try","metadata":{}},{"cell_type":"code","source":"# corrected_full_pipeline_kaggle.py\n# Paste into Kaggle notebook cell and run.\n\nimport os\nimport gc\nimport cv2\nimport math\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torchvision.transforms as transforms\n\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport timm\n\n# ---------------------------\n# CONFIG\n# ---------------------------\nBASE_PATH = \"/kaggle/input/aptos2019\"\nTRAIN_CSV = os.path.join(BASE_PATH, \"train_1.csv\")\nVAL_CSV   = os.path.join(BASE_PATH, \"valid.csv\")\nTEST_CSV  = os.path.join(BASE_PATH, \"test.csv\")\n\nTRAIN_DIR = os.path.join(BASE_PATH, \"train_images\",\"train_images\")\nVAL_DIR   = os.path.join(BASE_PATH, \"val_images\",\"val_images\")\nTEST_DIR  = os.path.join(BASE_PATH, \"test_images\",\"test_images\")\n\nIMG_SIZE = 448           # you had tried larger sizes  choose based on memory\nBATCH_SIZE = 8\nNUM_WORKERS = 2\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nPRINT_FREQ = 1\nSEED = 42\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# small global to avoid spammy logs from many broken images\n_bad_image_log_count = 0\n\n# ---------------------------\n# Preprocessing helpers (robust)\n# ---------------------------\ndef crop_black_border_and_center(img_np, thresh_val=10):\n    \"\"\"Crop black borders by thresholding then return cropped image.\"\"\"\n    if img_np is None or img_np.size == 0:\n        return img_np\n    try:\n        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n    except Exception:\n        # unexpected format - return as is\n        return img_np\n    _, thresh = cv2.threshold(gray, thresh_val, 255, cv2.THRESH_BINARY)\n    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    if contours:\n        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n        # validate coords\n        if w > 10 and h > 10:\n            return img_np[y:y+h, x:x+w]\n    return img_np\n\ndef crop_circle_hough(img_np):\n    \"\"\"Attempt HoughCircle to center on retina and crop a circular region safely.\"\"\"\n    if img_np is None or img_np.size == 0:\n        return img_np\n    try:\n        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n    except Exception:\n        return img_np\n\n    # small blur to reduce noise\n    gray = cv2.medianBlur(gray, 5)\n    h, w = gray.shape[:2]\n    minr = max(6, int(min(h, w) * 0.18))\n    maxr = max(minr+1, int(min(h, w) * 0.62))\n    try:\n        circles = cv2.HoughCircles(\n            gray, cv2.HOUGH_GRADIENT, dp=1.0, minDist=min(h, w)//8,\n            param1=50, param2=30, minRadius=minr, maxRadius=maxr\n        )\n    except Exception:\n        circles = None\n\n    if circles is not None and len(circles) > 0:\n        # select the best candidate  ensure numeric & valid\n        circles = np.round(circles).astype(int)\n        x, y, r = circles[0][0].tolist()\n        # clamp values and ensure positive\n        r = int(abs(r))\n        x = int(np.clip(x, 0, w-1))\n        y = int(np.clip(y, 0, h-1))\n        r = int(np.clip(r, 1, max(h, w)))\n        # compute bounding box with clamping\n        x1 = max(0, x - r)\n        y1 = max(0, y - r)\n        x2 = min(w, x + r)\n        y2 = min(h, y + r)\n        # ensure non-empty crop\n        if x2 > x1 + 4 and y2 > y1 + 4:\n            cropped = img_np[y1:y2, x1:x2]\n            if cropped.size != 0:\n                return cropped\n    return img_np\n\ndef apply_clahe(img_np):\n    \"\"\"Apply CLAHE to green channel. Be robust to shapes.\"\"\"\n    if img_np is None or img_np.size == 0:\n        return img_np\n    # if grayscale convert to 3 channel\n    if img_np.ndim == 2:\n        img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n    if img_np.ndim == 3 and img_np.shape[2] == 4:\n        # drop alpha\n        img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2RGB)\n    if img_np.ndim != 3 or img_np.shape[2] != 3:\n        # fallback: try to convert with PIL\n        try:\n            img_np = np.array(Image.fromarray(img_np).convert('RGB'))\n        except Exception:\n            return img_np\n\n    try:\n        b, g, r = cv2.split(img_np)\n    except Exception:\n        return img_np\n\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    try:\n        g2 = clahe.apply(g)\n    except Exception:\n        g2 = g\n    img_clahe = cv2.merge((b, g2, r))\n    return img_clahe\n\ndef multiscale_retinex(img_np, scales=[15,80,250], weights=None):\n    \"\"\"Robust MSR; returns uint8.\"\"\"\n    if img_np is None or img_np.size == 0:\n        return img_np\n    if weights is None:\n        weights = [1.0 / len(scales)] * len(scales)\n    img = img_np.astype(np.float32) + 1.0\n    retinex = np.zeros_like(img)\n    for i, scale in enumerate(scales):\n        blur = cv2.GaussianBlur(img, (0,0), sigmaX=scale, sigmaY=scale)\n        retinex += weights[i] * (np.log(img) - np.log(blur + 1e-6))\n    out = np.zeros_like(retinex)\n    for c in range(retinex.shape[2]):\n        arr = retinex[:,:,c]\n        mn, mx = arr.min(), arr.max()\n        if mx - mn > 1e-6:\n            out[:,:,c] = (arr - mn) / (mx - mn) * 255.0\n        else:\n            out[:,:,c] = arr\n    return out.astype(np.uint8)\n\ndef denoise_nlmeans(img_np):\n    try:\n        return cv2.fastNlMeansDenoisingColored(img_np, None, h=8, hColor=8, templateWindowSize=7, searchWindowSize=21)\n    except Exception:\n        return img_np\n\ndef preprocess_image_pipeline(pil_image, output_size=IMG_SIZE, do_msr=True, do_hough=True):\n    \"\"\"Takes PIL.Image, returns PIL.Image after preprocessing with robust fallbacks.\"\"\"\n    global _bad_image_log_count\n    try:\n        img_np = np.array(pil_image.convert('RGB'))\n    except Exception:\n        # if PIL failed, return a gray image of target size\n        if _bad_image_log_count < 5:\n            warnings.warn(\"PIL conversion failed in preprocess_image_pipeline; returning gray image.\")\n            _bad_image_log_count += 1\n        return Image.fromarray(np.uint8(np.ones((output_size, output_size, 3)) * 127))\n\n    img_np = crop_black_border_and_center(img_np, thresh_val=10)\n\n    if do_hough:\n        img_np = crop_circle_hough(img_np)\n\n    img_np = apply_clahe(img_np)\n    img_np = denoise_nlmeans(img_np)\n    img_np = cv2.GaussianBlur(img_np, (3,3), 0)\n\n    if do_msr:\n        try:\n            img_np = multiscale_retinex(img_np)\n        except Exception:\n            # fall back silently\n            pass\n\n    # final safety: if shape invalid, make a gray image\n    if img_np is None or img_np.size == 0 or img_np.ndim != 3 or img_np.shape[2] != 3:\n        if _bad_image_log_count < 5:\n            warnings.warn(\"Preprocessing produced invalid image; using gray fallback.\")\n            _bad_image_log_count += 1\n        img_np = np.ones((output_size, output_size, 3), dtype=np.uint8) * 127\n\n    img_resized = cv2.resize(img_np, (output_size, output_size), interpolation=cv2.INTER_AREA)\n    return Image.fromarray(img_resized)\n\n# ---------------------------\n# Dataset\n# ---------------------------\nclass DiabeticRetinopathyDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, preprocess_fn=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.preprocess_fn = preprocess_fn\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        global _bad_image_log_count\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, str(row['id_code']) + '.png')\n        try:\n            img = Image.open(img_path)\n            img = img.convert('RGB')\n        except Exception as e:\n            # broken file  return a gray image but don't crash the worker\n            if _bad_image_log_count < 10:\n                warnings.warn(f\"Failed to open image {img_path}: {e}. Returning gray fallback for this sample.\")\n                _bad_image_log_count += 1\n            img = Image.fromarray(np.uint8(np.ones((IMG_SIZE, IMG_SIZE, 3)) * 127))\n\n        try:\n            if self.preprocess_fn:\n                img = self.preprocess_fn(img)\n            if self.transform:\n                img = self.transform(img)\n        except Exception as e:\n            # Preprocessing/transforms crashed for this image -> fallback gray tensor\n            if _bad_image_log_count < 10:\n                warnings.warn(f\"Preprocess/transform failed for {img_path}: {e}. Returning gray fallback.\")\n                _bad_image_log_count += 1\n            # create a gray tensor directly respecting transform normalization if possible\n            img = Image.fromarray(np.uint8(np.ones((IMG_SIZE, IMG_SIZE, 3)) * 127))\n            if self.transform:\n                try:\n                    img = self.transform(img)\n                except Exception:\n                    # if transform also fails, create a simple tensor\n                    img = transforms.ToTensor()(Image.fromarray(np.uint8(np.ones((IMG_SIZE, IMG_SIZE, 3)) * 127)))\n\n        label = torch.tensor(int(row['diagnosis']), dtype=torch.long)\n        return img, label\n\n# ---------------------------\n# Losses & Model (kept as high-level multi-class now)\n# ---------------------------\nclass SmoothKappaLoss(nn.Module):\n    \"\"\"Differentiable QWK loss using softmax probabilities (multi-class).\"\"\"\n    def __init__(self, num_classes=5, eps=1e-7):\n        super().__init__()\n        self.num_classes = num_classes\n        self.eps = eps\n        W = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes):\n                W[i,j] = float((i - j)**2)\n        self.register_buffer('W', W)\n\n    def forward(self, logits, targets):\n        device = logits.device\n        probs = F.softmax(logits, dim=1)\n        one_hot = F.one_hot(targets, num_classes=self.num_classes).float().to(device)\n        conf_mat = torch.matmul(one_hot.T, probs)\n        conf_mat = conf_mat / (conf_mat.sum() + self.eps)\n        hist_true = one_hot.sum(dim=0)\n        hist_pred = probs.sum(dim=0)\n        expected = torch.outer(hist_true, hist_pred)\n        expected = expected / (expected.sum() + self.eps)\n        W = self.W.to(device)\n        obs = torch.sum(W * conf_mat)\n        exp = torch.sum(W * expected)\n        kappa = 1.0 - obs / (exp + self.eps)\n        return 1.0 - kappa\n\nclass EfficientNetB3Classifier(nn.Module):\n    def __init__(self, model_name='tf_efficientnet_b3_ns', num_classes=5, pretrained=True):\n        super().__init__()\n        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n        feat = self.backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(feat, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n    def forward(self, x):\n        f = self.backbone(x)\n        return self.classifier(f)\n\n# ---------------------------\n# Utilities & training loops (kept similar to your prior code)\n# ---------------------------\ndef calc_metrics_from_logits(logits, targets):\n    probs = F.softmax(logits, dim=1).cpu().numpy()\n    preds = np.argmax(probs, axis=1)\n    targets_np = targets.cpu().numpy()\n    acc = accuracy_score(targets_np, preds)\n    qwk = cohen_kappa_score(targets_np, preds, weights='quadratic')\n    within1 = np.mean(np.abs(targets_np - preds) <= 1)\n    return acc, qwk, within1\n\ndef clear_memory():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\ndef mixup_data(x, y, alpha=0.2):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.0\n    batch_size = x.size(0)\n    if batch_size == 1:\n        return x, y, y, 1.0\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef train_epoch(model, loader, optimizer, criterion, scaler, device, use_mixup=False):\n    model.train()\n    total_loss = 0.0\n    all_logits = []\n    all_targets = []\n    for images, targets in loader:\n        images = images.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        if use_mixup:\n            images, y_a, y_b, lam = mixup_data(images, targets, alpha=0.2)\n            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n                logits = model(images)\n                loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n        else:\n            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n                logits = model(images)\n                loss = criterion(logits, targets)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        total_loss += loss.item() * images.size(0)\n        all_logits.append(logits.detach().cpu())\n        all_targets.append(targets.detach().cpu())\n    if len(all_logits) == 0:\n        return 0.0, 0.0, 0.0, 0.0\n    all_logits = torch.cat(all_logits, dim=0)\n    all_targets = torch.cat(all_targets, dim=0)\n    avg_loss = total_loss / len(loader.dataset)\n    acc, qwk, within1 = calc_metrics_from_logits(all_logits, all_targets)\n    return avg_loss, acc, qwk, within1\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    all_logits = []\n    all_targets = []\n    with torch.no_grad():\n        for images, targets in loader:\n            images = images.to(device)\n            targets = targets.to(device)\n            logits = model(images)\n            loss = criterion(logits, targets)\n            total_loss += loss.item() * images.size(0)\n            all_logits.append(logits.detach().cpu())\n            all_targets.append(targets.detach().cpu())\n    if len(all_logits) == 0:\n        return 0.0, 0.0, 0.0, 0.0\n    all_logits = torch.cat(all_logits, dim=0)\n    all_targets = torch.cat(all_targets, dim=0)\n    avg_loss = total_loss / len(loader.dataset)\n    acc, qwk, within1 = calc_metrics_from_logits(all_logits, all_targets)\n    return avg_loss, acc, qwk, within1\n\n# ---------------------------\n# Main training pipeline (two stages)\n# ---------------------------\ndef main():\n    print(\"Device:\", DEVICE)\n    # load csvs - ensure these files exist in your Kaggle dataset\n    train_df = pd.read_csv(TRAIN_CSV)\n    val_df = pd.read_csv(VAL_CSV)\n    test_df = pd.read_csv(TEST_CSV)\n\n    print(\"Train samples:\", len(train_df), \"Val samples:\", len(val_df))\n\n    # Stronger transforms + RandomErasing\n    train_tf = transforms.Compose([\n        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0), ratio=(0.9,1.1)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(20),\n        transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.2, hue=0.02),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n        transforms.RandomErasing(p=0.2, scale=(0.02,0.2))\n    ])\n    val_tf = transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n    ])\n\n    train_ds = DiabeticRetinopathyDataset(train_df, TRAIN_DIR, transform=train_tf, preprocess_fn=lambda p: preprocess_image_pipeline(p, output_size=IMG_SIZE))\n    val_ds   = DiabeticRetinopathyDataset(val_df, VAL_DIR, transform=val_tf, preprocess_fn=lambda p: preprocess_image_pipeline(p, output_size=IMG_SIZE))\n\n    classes = np.unique(train_df['diagnosis'])\n    class_weights = compute_class_weight('balanced', classes=classes, y=train_df['diagnosis'])\n    sample_weights = np.array([class_weights[int(x)] for x in train_df['diagnosis']])\n    sampler = WeightedRandomSampler(sample_weights.astype(float), num_samples=len(sample_weights), replacement=True)\n\n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True, drop_last=False)\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n    # Model + losses\n    model = EfficientNetB3Classifier(model_name='tf_efficientnet_b3_ns', num_classes=5).to(DEVICE)\n\n    ce_class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n    ce_loss_fn = nn.CrossEntropyLoss(weight=ce_class_weights)\n    kappa_loss_fn = SmoothKappaLoss(num_classes=5)\n\n    # Use recommended GradScaler API\n    scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n\n    # STAGE 1: CE with mixup\n    opt = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n    steps_per_epoch = max(1, len(train_loader))\n    sched = optim.lr_scheduler.OneCycleLR(opt, max_lr=1e-3, steps_per_epoch=steps_per_epoch, epochs=30)\n\n    best_val_qwk = -1.0\n    best_val_acc = -1.0\n    patience = 7\n    wait = 0\n    use_mixup = True\n\n    for epoch in range(30):\n        clear_memory()\n        train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, opt, ce_loss_fn, scaler, DEVICE, use_mixup=use_mixup)\n        val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, ce_loss_fn, DEVICE)\n        try:\n            sched.step()\n        except Exception:\n            pass\n\n        if (epoch+1) % PRINT_FREQ == 0:\n            print(f\"[Stage1] Epoch {epoch+1:02d} Train acc: {train_acc:.4f} QWK: {train_qwk:.4f} | Val acc: {val_acc:.4f} QWK: {val_qwk:.4f}\")\n\n        score_for_save = val_qwk\n        if score_for_save > best_val_qwk or val_acc > best_val_acc:\n            best_val_qwk = max(best_val_qwk, val_qwk)\n            best_val_acc = max(best_val_acc, val_acc)\n            torch.save(model.state_dict(), \"best_stage1.pth\")\n            wait = 0\n            print(f\"  [SAVE] Stage1 model saved (val_qwk: {val_qwk:.4f}, val_acc: {val_acc:.4f})\")\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping Stage 1\")\n                break\n\n    # reload best stage1\n    if os.path.exists(\"best_stage1.pth\"):\n        model.load_state_dict(torch.load(\"best_stage1.pth\", map_location=DEVICE))\n    else:\n        print(\"Warning: best_stage1.pth not found, continuing with current weights.\")\n\n    # STAGE 2: hybrid (CE + kappa)\n    opt = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=5e-5)\n    sched = optim.lr_scheduler.OneCycleLR(opt, max_lr=5e-4, steps_per_epoch=steps_per_epoch, epochs=30)\n\n    def hybrid_loss(logits, targets):\n        ce = nn.CrossEntropyLoss(weight=ce_class_weights)(logits, targets)\n        k = kappa_loss_fn(logits, targets)\n        return 0.6 * ce + 0.4 * k\n\n    best_val_qwk_stage2 = best_val_qwk\n    wait = 0\n    patience = 8\n\n    for epoch in range(30):\n        clear_memory()\n        train_loss, train_acc, train_qwk, train_within1 = train_epoch(model, train_loader, opt, hybrid_loss, scaler, DEVICE, use_mixup=False)\n        val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, hybrid_loss, DEVICE)\n        try:\n            sched.step()\n        except Exception:\n            pass\n\n        if (epoch+1) % PRINT_FREQ == 0:\n            print(f\"[Stage2] Epoch {epoch+1:02d} Train acc: {train_acc:.4f} QWK: {train_qwk:.4f} | Val acc: {val_acc:.4f} QWK: {val_qwk:.4f}\")\n\n        if val_qwk > best_val_qwk_stage2:\n            best_val_qwk_stage2 = val_qwk\n            torch.save(model.state_dict(), \"best_model_final.pth\")\n            wait = 0\n            print(f\"  [SAVE] Stage2 model saved (val_qwk: {val_qwk:.4f})\")\n        else:\n            wait += 1\n            if wait >= patience:\n                print(\"Early stopping Stage 2\")\n                break\n\n    # finalize\n    if os.path.exists(\"best_model_final.pth\"):\n        model.load_state_dict(torch.load(\"best_model_final.pth\", map_location=DEVICE))\n    else:\n        print(\"Warning: best_model_final.pth not found. Using last model state.\")\n\n    print(\"Training finished. Best Stage1 QWK:\", best_val_qwk, \"Best Stage2 QWK:\", best_val_qwk_stage2)\n\n    # quick final CE eval on val set\n    val_loss, val_acc, val_qwk, val_within1 = validate_epoch(model, val_loader, nn.CrossEntropyLoss(weight=ce_class_weights), DEVICE)\n    print(\"Final evaluation (CE): Val acc: {:.4f} | Val QWK: {:.4f} | 1: {:.4f}\".format(val_acc, val_qwk, val_within1))\n\n    torch.save(model.state_dict(), \"final_model.pth\")\n    print(\"Saved final_model.pth\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nimport torchvision.transforms as transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport timm\n\n# =============================================================================\n# CONFIGURATION\n# =============================================================================\nclass CFG:\n    # Data paths\n    BASE_PATH = \"/kaggle/input/aptos2019\"\n    TRAIN_CSV = os.path.join(BASE_PATH, \"train_1.csv\")\n    VAL_CSV   = os.path.join(BASE_PATH, \"valid.csv\")\n    TRAIN_DIR = os.path.join(BASE_PATH, \"train_images\", \"train_images\")\n    VAL_DIR   = os.path.join(BASE_PATH, \"val_images\", \"val_images\")\n\n    # Model & Training parameters\n    MODEL_NAME = 'efficientnet_b3' # Upgraded model\n    IMG_SIZE = 384                 # Increased image size\n    BATCH_SIZE = 8                 # Reduced batch size to fit larger images in memory\n    NUM_WORKERS = 2\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Stage 1: Weighted Focal Loss Training\n    S1_EPOCHS = 15\n    S1_LR = 1e-4\n    S1_USE_MIXUP = True\n    \n    # Stage 2: Hybrid Loss Fine-tuning\n    S2_EPOCHS = 15\n    S2_LR = 3e-5 \n    S2_USE_MIXUP = False\n    \n    # General\n    PATIENCE = 5\n    SEED = 42\n    LABEL_SMOOTHING = 0.05\n\n# Seed everything for reproducibility\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True # Can be True for performance if input sizes are fixed\n\nseed_everything(CFG.SEED)\n\n\n# =============================================================================\n# PREPROCESSING & AUGMENTATIONS\n# =============================================================================\ndef preprocess_ben_graham(image_np, output_size):\n    # This function now expects a numpy array from Albumentations\n    try:\n        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n        if gray.mean() < 15: # Heuristic for nearly all-black images\n             return cv2.resize(image_np, (output_size, output_size), interpolation=cv2.INTER_AREA)\n\n        _, thresh = cv2.threshold(gray, 15, 255, cv2.THRESH_BINARY)\n        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        if contours:\n            largest_contour = max(contours, key=cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(largest_contour)\n            image_np = image_np[y:y+h, x:x+w]\n    except Exception:\n        pass\n\n    image_resized = cv2.resize(image_np, (output_size, output_size), interpolation=cv2.INTER_AREA)\n    b, g, r = cv2.split(image_resized)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    g = clahe.apply(g)\n    return cv2.merge((b, g, r))\n\n# Advanced Augmentations using Albumentations\ndef get_transforms(img_size):\n    # Pre-normalization transforms (applied to raw image)\n    pre_transforms = A.Compose([\n        A.Lambda(image=lambda x, **kwargs: preprocess_ben_graham(x, img_size), name=\"ben_graham_preprocess\"),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.7),\n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n    ])\n    # Post-normalization transforms\n    post_transforms = A.Compose([\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    val_transforms = A.Compose([\n        A.Lambda(image=lambda x, **kwargs: preprocess_ben_graham(x, img_size), name=\"ben_graham_preprocess\"),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    return pre_transforms, post_transforms, val_transforms\n\n\n# =============================================================================\n# DATASET\n# =============================================================================\nclass DiabeticRetinopathyDataset(Dataset):\n    def __init__(self, df, img_dir, pre_transform=None, post_transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.pre_transform = pre_transform\n        self.post_transform = post_transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id_code'] + '.png')\n        # Load with OpenCV for Albumentations\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if self.pre_transform:\n            augmented = self.pre_transform(image=img)\n            img = augmented['image']\n        \n        # Apply normalization and ToTensor after other augs\n        if self.post_transform:\n            tensor_aug = self.post_transform(image=img)\n            img = tensor_aug['image']\n\n        label = torch.tensor(row['diagnosis'], dtype=torch.long)\n        return img, label\n\n# =============================================================================\n# LOSSES & MODEL\n# =============================================================================\nclass WeightedOrdinalFocalLoss(nn.Module):\n    def __init__(self, num_classes=5, gamma=2.0, class_weights=None, label_smoothing=0.0):\n        super().__init__()\n        self.num_classes = num_classes\n        self.gamma = gamma\n        self.class_weights = class_weights\n        self.label_smoothing = label_smoothing\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n\n    def forward(self, outputs, targets):\n        # Create ordinal targets with label smoothing\n        ordinal_targets = torch.zeros_like(outputs)\n        for i, t in enumerate(targets):\n            if t > 0:\n                ordinal_targets[i, :t] = 1.0\n        \n        # Apply label smoothing\n        if self.label_smoothing > 0.0:\n            ordinal_targets = ordinal_targets * (1.0 - self.label_smoothing) + 0.5 * self.label_smoothing\n\n        bce = self.bce(outputs, ordinal_targets)\n        \n        # Apply class weights to the loss for each sample\n        if self.class_weights is not None:\n            weights = self.class_weights[targets].view(-1, 1).expand(-1, outputs.shape[1])\n            bce = bce * weights\n\n        pt = torch.exp(-bce)\n        focal = (1 - pt) ** self.gamma * bce\n        return focal.mean()\n\n# SmoothKappaLoss and Model remain the same as before...\nclass SmoothKappaLoss(nn.Module):\n    def __init__(self, num_classes=5, eps=1e-7):\n        super().__init__()\n        self.num_classes = num_classes\n        self.eps = eps\n        W = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes):\n                W[i,j] = ((i - j)**2) / ((num_classes - 1)**2)\n        self.register_buffer(\"W\", W)\n\n    def forward(self, outputs, targets):\n        device = outputs.device\n        B = outputs.size(0)\n        probs = torch.sigmoid(outputs)\n        class_probs = torch.zeros(B, self.num_classes, device=device)\n        class_probs[:, 0] = 1 - probs[:, 0]\n        for k in range(1, self.num_classes-1):\n            class_probs[:, k] = probs[:, k-1] - probs[:, k]\n        class_probs[:, -1] = probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=self.eps, max=1.0)\n        \n        one_hot = F.one_hot(targets, num_classes=self.num_classes).float().to(device)\n        conf_mat = torch.matmul(one_hot.T, class_probs)\n        \n        hist_true = one_hot.sum(dim=0)\n        hist_pred = class_probs.sum(dim=0)\n        expected = torch.outer(hist_true, hist_pred)\n\n        W = self.W.to(device)\n        obs = torch.sum(W * conf_mat)\n        exp = torch.sum(W * expected)\n        kappa = 1.0 - (B * obs) / (exp + self.eps)\n        return 1.0 - kappa\n        \nclass EfficientNetOrdinal(nn.Module):\n    def __init__(self, model_name='efficientnet_b3', num_classes=5, pretrained=True):\n        super().__init__()\n        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n        feature_dim = self.backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes - 1)\n        )\n    def forward(self, x):\n        feat = self.backbone(x)\n        return self.classifier(feat)\n\n\n# Utilities and Training loops remain the same...\n\ndef ordinal_to_class(outputs):\n    probs = torch.sigmoid(outputs)\n    return torch.sum(probs > 0.5, dim=1).long()\n\ndef calculate_metrics(outputs, targets):\n    preds = ordinal_to_class(outputs).cpu().numpy()\n    targets_np = targets.cpu().numpy()\n    acc = accuracy_score(targets_np, preds)\n    qwk = cohen_kappa_score(targets_np, preds, weights='quadratic')\n    return acc, qwk\n\ndef clear_memory():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\ndef mixup_data(x, y, alpha=0.4):\n    if alpha > 0: lam = np.random.beta(alpha, alpha)\n    else: lam = 1\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef train_epoch(model, loader, optimizer, criterion, scaler, device, use_mixup):\n    model.train()\n    running_loss = 0.0\n    all_out, all_t = [], []\n    pbar = tqdm(loader, desc=\"Training\", leave=False)\n    for images, targets in pbar:\n        images, targets = images.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n        if use_mixup: images, targets_a, targets_b, lam = mixup_data(images, targets)\n        with torch.cuda.amp.autocast():\n            outputs = model(images)\n            if use_mixup: loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n            else: loss = criterion(outputs, targets)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        running_loss += loss.item()\n        all_out.append(outputs.detach())\n        all_t.append(targets.detach())\n        pbar.set_postfix(loss=loss.item())\n    all_out, all_t = torch.cat(all_out), torch.cat(all_t)\n    return running_loss / len(loader), *calculate_metrics(all_out, all_t)\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_out, all_t = [], []\n    with torch.no_grad():\n        pbar = tqdm(loader, desc=\"Validating\", leave=False)\n        for images, targets in pbar:\n            images, targets = images.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n                loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            all_out.append(outputs)\n            all_t.append(targets)\n    all_out, all_t = torch.cat(all_out), torch.cat(all_t)\n    return running_loss / len(loader), *calculate_metrics(all_out, all_t)\n\n# =============================================================================\n# MAIN TRAINING PIPELINE\n# =============================================================================\ndef main():\n    print(f\"Device: {CFG.DEVICE}, Model: {CFG.MODEL_NAME}, Image Size: {CFG.IMG_SIZE}\")\n    train_df = pd.read_csv(CFG.TRAIN_CSV)\n    val_df = pd.read_csv(CFG.VAL_CSV)\n\n    pre_tf, post_tf, val_tf = get_transforms(CFG.IMG_SIZE)\n\n    train_ds = DiabeticRetinopathyDataset(train_df, CFG.TRAIN_DIR, pre_transform=pre_tf, post_transform=post_tf)\n    val_ds   = DiabeticRetinopathyDataset(val_df, CFG.VAL_DIR, pre_transform=val_tf) # val_tf does all steps\n\n    # Sampler for imbalance\n    class_weights_sampler = compute_class_weight('balanced', classes=np.unique(train_df['diagnosis']), y=train_df['diagnosis'])\n    sample_weights = np.array([class_weights_sampler[int(l)] for l in train_df['diagnosis']])\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n\n    train_loader = DataLoader(train_ds, batch_size=CFG.BATCH_SIZE, sampler=sampler, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE*2, shuffle=False, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n\n    # Model and losses\n    model = EfficientNetOrdinal(CFG.MODEL_NAME, num_classes=5).to(CFG.DEVICE)\n    \n    # Class weights for the loss function\n    class_weights_loss = torch.tensor(class_weights_sampler, dtype=torch.float).to(CFG.DEVICE)\n    \n    # LOSSES\n    focal_loss = WeightedOrdinalFocalLoss(num_classes=5, gamma=2.0, class_weights=class_weights_loss, label_smoothing=CFG.LABEL_SMOOTHING)\n    kappa_loss = SmoothKappaLoss(num_classes=5)\n    \n    # HYBRID LOSS for STAGE 2\n    def hybrid_loss(outputs, targets):\n        return 0.7 * kappa_loss(outputs, targets) + 0.3 * focal_loss(outputs, targets)\n    \n    scaler = torch.cuda.amp.GradScaler()\n\n    # --- STAGE 1: WEIGHTED FOCAL LOSS ---\n    print(\"\\n\" + \"=\"*50 + \"\\n     STARTING STAGE 1: WEIGHTED FOCAL LOSS\\n\" + \"=\"*50)\n    opt = optim.AdamW(model.parameters(), lr=CFG.S1_LR, weight_decay=1e-4)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG.S1_EPOCHS)\n    best_val_qwk, patience_counter = -1, 0\n\n    for epoch in range(CFG.S1_EPOCHS):\n        clear_memory()\n        print(f\"\\nEpoch {epoch+1}/{CFG.S1_EPOCHS}\")\n        train_loss, train_acc, train_qwk = train_epoch(model, train_loader, opt, focal_loss, scaler, CFG.DEVICE, CFG.S1_USE_MIXUP)\n        val_loss, val_acc, val_qwk = validate_epoch(model, val_loader, focal_loss, CFG.DEVICE)\n        sched.step()\n\n        print(f\"Train -> Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, QWK: {train_qwk:.4f}\")\n        print(f\"Valid -> Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, QWK: {val_qwk:.4f}\")\n\n        if val_qwk > best_val_qwk:\n            print(f\"Val QWK improved from {best_val_qwk:.4f} to {val_qwk:.4f}. Saving model...\")\n            best_val_qwk, patience_counter = val_qwk, 0\n            torch.save(model.state_dict(), \"best_model_stage1.pth\")\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.PATIENCE: print(\"Early stopping in Stage 1.\"); break\n    \n    # --- STAGE 2: HYBRID LOSS FINE-TUNING ---\n    print(\"\\n\" + \"=\"*50 + \"\\n     STARTING STAGE 2: HYBRID LOSS FINE-TUNING\\n\" + \"=\"*50)\n    model.load_state_dict(torch.load(\"best_model_stage1.pth\"))\n    opt = optim.AdamW(model.parameters(), lr=CFG.S2_LR, weight_decay=1e-5)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG.S2_EPOCHS)\n    best_val_qwk_stage2, patience_counter = best_val_qwk, 0\n\n    for epoch in range(CFG.S2_EPOCHS):\n        clear_memory()\n        print(f\"\\nEpoch {epoch+1}/{CFG.S2_EPOCHS}\")\n        train_loss, train_acc, train_qwk = train_epoch(model, train_loader, opt, hybrid_loss, scaler, CFG.DEVICE, CFG.S2_USE_MIXUP)\n        val_loss, val_acc, val_qwk = validate_epoch(model, val_loader, hybrid_loss, CFG.DEVICE)\n        sched.step()\n        \n        print(f\"Train -> Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, QWK: {train_qwk:.4f}\")\n        print(f\"Valid -> Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, QWK: {val_qwk:.4f}\")\n\n        if val_qwk > best_val_qwk_stage2:\n            print(f\"Val QWK improved from {best_val_qwk_stage2:.4f} to {val_qwk:.4f}. Saving final model...\")\n            best_val_qwk_stage2, patience_counter = val_qwk, 0\n            torch.save(model.state_dict(), \"best_model_final.pth\")\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.PATIENCE: print(\"Early stopping in Stage 2.\"); break\n\n    print(f\"\\nTraining Finished!\\nBest Stage 1 QWK: {best_val_qwk:.4f}\\nFinal Best QWK: {best_val_qwk_stage2:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T16:55:54.211111Z","iopub.execute_input":"2025-09-10T16:55:54.211422Z","iopub.status.idle":"2025-09-10T19:06:49.505448Z","shell.execute_reply.started":"2025-09-10T16:55:54.211394Z","shell.execute_reply":"2025-09-10T19:06:49.504557Z"}},"outputs":[{"name":"stdout","text":"Device: cuda, Model: efficientnet_b3, Image Size: 384\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:98: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n  A.Lambda(image=lambda x, **kwargs: preprocess_ben_graham(x, img_size), name=\"ben_graham_preprocess\"),\n/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n/tmp/ipykernel_36/372004193.py:111: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n  A.Lambda(image=lambda x, **kwargs: preprocess_ben_graham(x, img_size), name=\"ben_graham_preprocess\"),\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\n     STARTING STAGE 1: WEIGHTED FOCAL LOSS\n==================================================\n\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:339: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.4438, Acc: 0.2464, QWK: 0.1653\nValid -> Loss: 0.1856, Acc: 0.1503, QWK: 0.4354\nVal QWK improved from -1.0000 to 0.4354. Saving model...\n\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.3393, Acc: 0.3328, QWK: 0.3459\nValid -> Loss: 0.1556, Acc: 0.2022, QWK: 0.6399\nVal QWK improved from 0.4354 to 0.6399. Saving model...\n\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.2983, Acc: 0.3509, QWK: 0.3603\nValid -> Loss: 0.1411, Acc: 0.2158, QWK: 0.6129\n\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.2794, Acc: 0.3867, QWK: 0.4052\nValid -> Loss: 0.1416, Acc: 0.2186, QWK: 0.5195\n\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.2482, Acc: 0.4109, QWK: 0.4062\nValid -> Loss: 0.1400, Acc: 0.2268, QWK: 0.5981\n\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.2475, Acc: 0.4014, QWK: 0.4336\nValid -> Loss: 0.1432, Acc: 0.2350, QWK: 0.6654\nVal QWK improved from 0.6399 to 0.6654. Saving model...\n\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.2167, Acc: 0.4195, QWK: 0.4325\nValid -> Loss: 0.1312, Acc: 0.3087, QWK: 0.6807\nVal QWK improved from 0.6654 to 0.6807. Saving model...\n\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.2073, Acc: 0.4283, QWK: 0.4407\nValid -> Loss: 0.1271, Acc: 0.3525, QWK: 0.7137\nVal QWK improved from 0.6807 to 0.7137. Saving model...\n\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1960, Acc: 0.4096, QWK: 0.4376\nValid -> Loss: 0.1288, Acc: 0.4454, QWK: 0.7233\nVal QWK improved from 0.7137 to 0.7233. Saving model...\n\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd828028c6749abac102d2ec8105f15"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1978, Acc: 0.4427, QWK: 0.4771\nValid -> Loss: 0.1307, Acc: 0.2978, QWK: 0.6990\n\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03646bbd3d994027a5b7eb5492b93465"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcf5004f324f4267aca72e053f3a52ea"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1991, Acc: 0.4471, QWK: 0.4641\nValid -> Loss: 0.1403, Acc: 0.3825, QWK: 0.6565\n\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ebad1ae227469e8e63b9c1c2da06bb"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb924be1f2f54500966ac003fa8cb32d"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.2065, Acc: 0.4447, QWK: 0.4840\nValid -> Loss: 0.1353, Acc: 0.3825, QWK: 0.6700\n\nEpoch 13/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1922, Acc: 0.4560, QWK: 0.4925\nValid -> Loss: 0.1325, Acc: 0.4290, QWK: 0.7101\n\nEpoch 14/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1886, Acc: 0.4567, QWK: 0.4739\nValid -> Loss: 0.1322, Acc: 0.4781, QWK: 0.7123\nEarly stopping in Stage 1.\n\n==================================================\n     STARTING STAGE 2: HYBRID LOSS FINE-TUNING\n==================================================\n\nEpoch 1/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1774, Acc: 0.6857, QWK: 0.9012\nValid -> Loss: 0.2355, Acc: 0.7213, QWK: 0.8650\nVal QWK improved from 0.7233 to 0.8650. Saving final model...\n\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1209, Acc: 0.8106, QWK: 0.9449\nValid -> Loss: 0.1931, Acc: 0.7705, QWK: 0.8943\nVal QWK improved from 0.8650 to 0.8943. Saving final model...\n\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.1042, Acc: 0.8433, QWK: 0.9529\nValid -> Loss: 0.1684, Acc: 0.7650, QWK: 0.9013\nVal QWK improved from 0.8943 to 0.9013. Saving final model...\n\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0989, Acc: 0.8604, QWK: 0.9584\nValid -> Loss: 0.1904, Acc: 0.7760, QWK: 0.8877\n\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0870, Acc: 0.8720, QWK: 0.9621\nValid -> Loss: 0.1616, Acc: 0.7787, QWK: 0.9045\nVal QWK improved from 0.9013 to 0.9045. Saving final model...\n\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0791, Acc: 0.8925, QWK: 0.9681\nValid -> Loss: 0.1647, Acc: 0.7787, QWK: 0.9007\n\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0728, Acc: 0.8990, QWK: 0.9706\nValid -> Loss: 0.1576, Acc: 0.8060, QWK: 0.9139\nVal QWK improved from 0.9045 to 0.9139. Saving final model...\n\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0635, Acc: 0.9222, QWK: 0.9790\nValid -> Loss: 0.1589, Acc: 0.7923, QWK: 0.9076\n\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0727, Acc: 0.8986, QWK: 0.9690\nValid -> Loss: 0.1602, Acc: 0.8115, QWK: 0.9119\n\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0739, Acc: 0.9096, QWK: 0.9716\nValid -> Loss: 0.1653, Acc: 0.7978, QWK: 0.9043\n\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0676, Acc: 0.9068, QWK: 0.9715\nValid -> Loss: 0.1524, Acc: 0.7787, QWK: 0.9127\n\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:273: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/372004193.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss: 0.0645, Acc: 0.9232, QWK: 0.9787\nValid -> Loss: 0.1574, Acc: 0.7923, QWK: 0.9072\nEarly stopping in Stage 2.\n\nTraining Finished!\nBest Stage 1 QWK: 0.7233\nFinal Best QWK: 0.9139\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport cv2  # The library is imported as cv2\nimport os\nimport timm\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# =============================================================================\n# REUSED CLASSES AND FUNCTIONS\n# =============================================================================\n\nclass CFG:\n    # Set these to match your final successful training run\n    MODEL_NAME = 'efficientnet_b3'\n    IMG_SIZE = 384\n    \n    # CORRECTED Paths to your test data\n    BASE_PATH = \"/kaggle/input/aptos2019\"\n    TEST_CSV = os.path.join(BASE_PATH, \"test.csv\")\n    TEST_DIR = os.path.join(BASE_PATH, \"test_images\", \"test_images\")\n    \n    # Path to your saved model\n    MODEL_PATH = \"best_model_final.pth\"\n    \n    BATCH_SIZE = 16 \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# --- Model Class ---\nclass EfficientNetOrdinal(nn.Module):\n    def __init__(self, model_name, num_classes=5, pretrained=False):\n        super().__init__()\n        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n        feature_dim = self.backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes - 1)\n        )\n    def forward(self, x):\n        feat = self.backbone(x)\n        return self.classifier(feat)\n\n# --- Preprocessing and Dataset ---\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\n\ndef preprocess_ben_graham(image_np, output_size):\n    try:\n        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY) # FIXED: cv2\n        if gray.mean() < 15:\n             return cv2.resize(image_np, (output_size, output_size), interpolation=cv2.INTER_AREA) # FIXED: cv2\n        _, thresh = cv2.threshold(gray, 15, 255, cv2.THRESH_BINARY) # FIXED: cv2\n        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # FIXED: cv2\n        if contours:\n            largest_contour = max(contours, key=cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(largest_contour) # FIXED: cv2\n            image_np = image_np[y:y+h, x:x+w]\n    except Exception:\n        pass\n    image_resized = cv2.resize(image_np, (output_size, output_size), interpolation=cv2.INTER_AREA) # FIXED: cv2\n    b, g, r = cv2.split(image_resized) # FIXED: cv2\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)) # FIXED: cv2\n    g = clahe.apply(g)\n    return cv2.merge((b, g, r)) # FIXED: cv2\n\nclass DiabeticRetinopathyDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id_code'] + '.png')\n        img = cv2.imread(img_path) # FIXED: cv2\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # FIXED: cv2\n        if self.transform:\n            augmented = self.transform(image=img)\n            img = augmented['image']\n        label = torch.tensor(row['diagnosis'], dtype=torch.long)\n        return img, label\n\n# --- Utility ---\ndef ordinal_to_class(outputs):\n    probs = torch.sigmoid(outputs)\n    return torch.sum(probs > 0.5, dim=1).long()\n\n\n# =============================================================================\n# TESTING FUNCTION\n# =============================================================================\ndef test_model():\n    print(\"--- Starting Final Model Evaluation ---\")\n    \n    # 1. Load Data\n    test_df = pd.read_csv(CFG.TEST_CSV)\n    print(f\"Test data loaded: {len(test_df)} samples from {CFG.TEST_CSV.split('/')[-1]}\")\n    \n    # 2. Define Transforms (no augmentations for testing)\n    test_transform = A.Compose([\n        A.Lambda(image=lambda x, **kwargs: preprocess_ben_graham(x, CFG.IMG_SIZE)),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ])\n    \n    # 3. Create Dataset and DataLoader\n    test_dataset = DiabeticRetinopathyDataset(test_df, CFG.TEST_DIR, transform=test_transform)\n    test_loader = DataLoader(test_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n    \n    # 4. Load Model\n    model = EfficientNetOrdinal(CFG.MODEL_NAME, pretrained=False).to(CFG.DEVICE)\n    model.load_state_dict(torch.load(CFG.MODEL_PATH, map_location=CFG.DEVICE))\n    model.eval()\n    print(f\"Model loaded from {CFG.MODEL_PATH}\")\n    \n    # 5. Get Predictions\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Predicting on test set\"):\n            images = images.to(CFG.DEVICE)\n            \n            outputs = model(images)\n            preds = ordinal_to_class(outputs)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n    # 6. Calculate and Display Metrics\n    print(\"\\n--- Final Test Results ---\")\n    qwk = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n    accuracy = accuracy_score(all_labels, all_preds)\n    \n    print(f\"Quadratic Weighted Kappa: {qwk:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    \n    # 7. Detailed Report\n    print(\"\\n--- Classification Report ---\")\n    print(classification_report(all_labels, all_preds, target_names=[f\"Class {i}\" for i in range(5)]))\n    \n    # 8. Confusion Matrix\n    print(\"\\n--- Confusion Matrix ---\")\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(5), yticklabels=range(5))\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\n# --- RUN THE EVALUATION ---\ntest_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T19:24:36.293147Z","iopub.execute_input":"2025-09-10T19:24:36.293941Z","iopub.status.idle":"2025-09-10T19:25:19.624411Z","shell.execute_reply.started":"2025-09-10T19:24:36.293903Z","shell.execute_reply":"2025-09-10T19:25:19.623564Z"}},"outputs":[{"name":"stdout","text":"--- Starting Final Model Evaluation ---\nTest data loaded: 366 samples from test.csv\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/1543076114.py:109: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n  A.Lambda(image=lambda x, **kwargs: preprocess_ben_graham(x, CFG.IMG_SIZE)),\n","output_type":"stream"},{"name":"stdout","text":"Model loaded from best_model_final.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting on test set:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ed9ee672fe44898142df9b331b5b81"}},"metadata":{}},{"name":"stdout","text":"\n--- Final Test Results ---\nQuadratic Weighted Kappa: 0.9129\nAccuracy: 0.8142 (81.42%)\n\n--- Classification Report ---\n              precision    recall  f1-score   support\n\n     Class 0       0.99      0.97      0.98       199\n     Class 1       0.46      0.57      0.51        30\n     Class 2       0.72      0.69      0.71        87\n     Class 3       0.30      0.47      0.36        17\n     Class 4       0.79      0.58      0.67        33\n\n    accuracy                           0.81       366\n   macro avg       0.65      0.66      0.65       366\nweighted avg       0.84      0.81      0.82       366\n\n\n--- Confusion Matrix ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5}]}