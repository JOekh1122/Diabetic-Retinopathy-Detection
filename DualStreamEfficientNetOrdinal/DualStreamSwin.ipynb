{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2822650,"sourceType":"datasetVersion","datasetId":1715304},{"sourceId":13052187,"sourceType":"datasetVersion","datasetId":8265092}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport timm\n\n# ================= CONFIG =================\nclass CFG:\n    MODEL_NAME = 'swinv2_tiny_window8_256'\n    IMG_SIZE = 256\n    BATCH_SIZE = 8\n    BASE_PATH = \"/kaggle/input/aptos2019\"\n    TRAIN_CSV = os.path.join(BASE_PATH, \"train_1.csv\")\n    VAL_CSV   = os.path.join(BASE_PATH, \"valid.csv\")\n    TRAIN_DIR = os.path.join(BASE_PATH, \"train_images\", \"train_images\")\n    VAL_DIR   = os.path.join(BASE_PATH, \"val_images\", \"val_images\")\n    SEG_TRAIN_DIR = \"/kaggle/input/aptos-2019-dataset-vessel-segmentation/segmented_outputs_train_1/segmented_outputs_train_1\"\n    SEG_VAL_DIR   = \"/kaggle/input/aptos-2019-dataset-vessel-segmentation/segmented_outputs_val/segmented_outputs_val\"\n    \n    S1_EPOCHS = 15; S1_LR = 1e-4; S1_USE_MIXUP = True\n    S2_EPOCHS = 15; S2_LR = 3e-5; S2_USE_MIXUP = False\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    NUM_WORKERS = 2\n    PATIENCE = 5\n    SEED = 42\n    LABEL_SMOOTHING = 0.05\n    \n    SAVE_PATH_S1 = \"best_model_swin_stage1.pth\"\n    SAVE_PATH_FINAL = \"best_model_swin_final.pth\"\n\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.SEED)\n\n# ================= Dataset =================\nclass DatasetDualStream(Dataset):\n    def __init__(self, df, img_dir, seg_dir, transform=None):\n        self.df, self.img_dir, self.seg_dir, self.transform = df.reset_index(drop=True), img_dir, seg_dir, transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id_code'] + '.png')\n        seg_path = os.path.join(self.seg_dir, row['id_code'] + '.png')\n        \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(seg_path, cv2.IMREAD_GRAYSCALE)\n        \n        img = cv2.resize(img, (CFG.IMG_SIZE, CFG.IMG_SIZE))\n        mask = cv2.resize(mask, (CFG.IMG_SIZE, CFG.IMG_SIZE))\n        \n        if self.transform:\n            augmented = self.transform(image=img, mask=mask)\n            img, mask = augmented['image'], augmented['mask']\n        \n        img = A.Normalize()(image=img)['image']\n        mask = (mask / 255.0)[None, :, :]\n        img = ToTensorV2()(image=img)['image']\n        mask = torch.tensor(mask, dtype=torch.float)\n        label = torch.tensor(row['diagnosis'], dtype=torch.long)\n        return img, mask, label\n\ndef get_transforms(is_train=True):\n    if is_train:\n        return A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.7),\n            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7)\n        ])\n    return None\n\n# ================= Model =================\nclass DualStreamSwin(nn.Module):\n    def __init__(self, model_name='swinv2_tiny_window8_256', num_classes=5, pretrained=True):\n        super().__init__()\n        self.rgb_backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n        self.mask_backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n        \n        # 1-channel patch embed\n        orig_proj = self.mask_backbone.patch_embed.proj\n        new_proj = nn.Conv2d(1, orig_proj.out_channels,\n                             kernel_size=orig_proj.kernel_size,\n                             stride=orig_proj.stride,\n                             padding=orig_proj.padding,\n                             bias=(orig_proj.bias is not None))\n        with torch.no_grad():\n            new_proj.weight[:, 0] = orig_proj.weight.mean(dim=1)\n        self.mask_backbone.patch_embed.proj = new_proj\n        \n        feat_dim = self.rgb_backbone.num_features + self.mask_backbone.num_features\n        self.classifier = nn.Sequential(\n            nn.Linear(feat_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes - 1)\n        )\n        \n    def forward(self, rgb, mask):\n        rgb_feat = self.rgb_backbone(rgb)\n        mask_feat = self.mask_backbone(mask)\n        fused_feat = torch.cat([rgb_feat, mask_feat], dim=1)\n        return self.classifier(fused_feat)\n\n# ================= Loss =================\nclass WeightedOrdinalFocalLoss(nn.Module):\n    def __init__(self, num_classes=5, gamma=2.0, class_weights=None, label_smoothing=0.0):\n        super().__init__()\n        self.num_classes, self.gamma, self.class_weights, self.label_smoothing = num_classes, gamma, class_weights, label_smoothing\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n    def forward(self, outputs, targets):\n        ordinal_targets = torch.zeros_like(outputs)\n        for i, t in enumerate(targets):\n            if t > 0: ordinal_targets[i, :t] = 1.0\n        if self.label_smoothing > 0.0: ordinal_targets = ordinal_targets * (1.0 - self.label_smoothing) + 0.5 * self.label_smoothing\n        bce = self.bce(outputs, ordinal_targets)\n        if self.class_weights is not None:\n            weights = self.class_weights[targets].view(-1, 1).expand(-1, outputs.shape[1])\n            bce = bce * weights\n        pt = torch.exp(-bce)\n        focal = (1 - pt) ** self.gamma * bce\n        return focal.mean()\n\nclass SmoothKappaLoss(nn.Module):\n    def __init__(self, num_classes=5, eps=1e-7):\n        super().__init__()\n        self.num_classes, self.eps = num_classes, eps\n        W = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes):\n                W[i,j] = ((i-j)**2) / ((num_classes-1)**2)\n        self.register_buffer(\"W\", W)\n    def forward(self, outputs, targets):\n        device = outputs.device; B = outputs.size(0); probs = torch.sigmoid(outputs)\n        class_probs = torch.zeros(B, self.num_classes, device=device)\n        class_probs[:,0] = 1-probs[:,0]\n        for k in range(1,self.num_classes-1):\n            class_probs[:,k] = probs[:,k-1]-probs[:,k]\n        class_probs[:,-1] = probs[:,-1]\n        class_probs = torch.clamp(class_probs, min=1e-7, max=1.0)\n        one_hot = F.one_hot(targets, num_classes=self.num_classes).float().to(device)\n        conf_mat = torch.matmul(one_hot.T, class_probs)\n        hist_true = one_hot.sum(dim=0); hist_pred = class_probs.sum(dim=0)\n        expected = torch.outer(hist_true, hist_pred)\n        W = self.W.to(device); obs = torch.sum(W*conf_mat); exp = torch.sum(W*expected)\n        kappa = 1.0 - (B*obs)/(exp+self.eps)\n        return 1.0 - kappa\n\n# ================= Training Utils =================\ndef ordinal_to_class(outputs): return torch.sum(torch.sigmoid(outputs) > 0.5, dim=1).long()\ndef calculate_metrics(outputs, targets):\n    preds = ordinal_to_class(outputs).cpu().numpy()\n    targets_np = targets.cpu().numpy()\n    return accuracy_score(targets_np, preds), cohen_kappa_score(targets_np, preds, weights='quadratic')\ndef clear_memory(): gc.collect(); torch.cuda.empty_cache()\ndef mixup_data(x, y, alpha=0.4):\n    lam = np.random.beta(alpha, alpha) if alpha>0 else 1\n    index = torch.randperm(x.size(0)).to(x.device)\n    return lam*x + (1-lam)*x[index], y, y[index], lam\n\ndef train_epoch(model, loader, optimizer, criterion, scaler, device, use_mixup):\n    model.train(); running_loss=0.0; all_out, all_t=[],[]\n    for img, mask, targets in tqdm(loader, desc=\"Train\", leave=False):\n        img, mask, targets = img.to(device), mask.to(device), targets.to(device)\n        optimizer.zero_grad(set_to_none=True)\n        if use_mixup:\n            img, targets_a, targets_b, lam = mixup_data(img, targets)\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(img, mask)\n            loss = lam*criterion(outputs, targets_a)+(1-lam)*criterion(outputs, targets_b) if use_mixup else criterion(outputs, targets)\n        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n        running_loss += loss.item(); all_out.append(outputs.detach()); all_t.append(targets.detach())\n    all_out, all_t = torch.cat(all_out), torch.cat(all_t)\n    acc, qwk = calculate_metrics(all_out, all_t)\n    return running_loss/len(loader), acc, qwk\n\ndef valid_epoch(model, loader, criterion, device):\n    model.eval(); running_loss=0.0; all_out, all_t=[],[]\n    with torch.no_grad():\n        for img, mask, targets in tqdm(loader, desc=\"Valid\", leave=False):\n            img, mask, targets = img.to(device), mask.to(device), targets.to(device)\n            outputs = model(img, mask); loss = criterion(outputs, targets)\n            running_loss += loss.item(); all_out.append(outputs); all_t.append(targets)\n    all_out, all_t = torch.cat(all_out), torch.cat(all_t)\n    acc, qwk = calculate_metrics(all_out, all_t)\n    return running_loss/len(loader), acc, qwk\n\n\n\ndef main():\n    print(f\"Device: {CFG.DEVICE}, Model: {CFG.MODEL_NAME} (4-Channel), Image Size: {CFG.IMG_SIZE}\")\n    train_df = pd.read_csv(CFG.TRAIN_CSV)\n    val_df = pd.read_csv(CFG.VAL_CSV)\n    \n    train_tf = get_transforms(is_train=True)\n    val_tf = get_transforms(is_train=False)\n\n    train_ds = DatasetDualStream(train_df, CFG.TRAIN_DIR, CFG.SEG_TRAIN_DIR, transform=train_tf)\n    val_ds   = DatasetDualStream(val_df, CFG.VAL_DIR, CFG.SEG_VAL_DIR, transform=val_tf)\n\n    class_weights_sampler = compute_class_weight('balanced', classes=np.unique(train_df['diagnosis']), y=train_df['diagnosis'])\n    sample_weights = np.array([class_weights_sampler[int(l)] for l in train_df['diagnosis']])\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n    train_loader = DataLoader(train_ds, batch_size=CFG.BATCH_SIZE, sampler=sampler, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE*2, shuffle=False, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n    \n    model = DualStreamSwin(model_name='swinv2_tiny_window8_256').to(CFG.DEVICE)\n    class_weights_loss = torch.tensor(class_weights_sampler, dtype=torch.float).to(CFG.DEVICE)\n    focal_loss = WeightedOrdinalFocalLoss(num_classes=5, gamma=2.0, class_weights=class_weights_loss, label_smoothing=CFG.LABEL_SMOOTHING)\n    kappa_loss = SmoothKappaLoss(num_classes=5)\n    \n    def hybrid_loss(outputs, targets): \n        return 0.7 * kappa_loss(outputs, targets) + 0.3 * focal_loss(outputs, targets)\n    \n    scaler = torch.cuda.amp.GradScaler()\n\n    # --- STAGE 1 ---\n    print(\"\\n\" + \"=\"*50 + \"\\n     STARTING STAGE 1 (4-Channel)\\n\" + \"=\"*50)\n    opt = optim.AdamW(model.parameters(), lr=CFG.S1_LR, weight_decay=1e-4)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG.S1_EPOCHS)\n    best_val_qwk, patience_counter = -1, 0\n\n    for epoch in range(CFG.S1_EPOCHS):\n        clear_memory()\n        print(f\"\\nEpoch {epoch+1}/{CFG.S1_EPOCHS}\")\n        train_loss, train_acc, train_qwk = train_epoch(model, train_loader, opt, focal_loss, scaler, CFG.DEVICE, CFG.S1_USE_MIXUP)\n        val_loss, val_acc, val_qwk = validate_epoch(model, val_loader, focal_loss, CFG.DEVICE)\n        sched.step()\n        print(f\"Train -> Loss:{train_loss:.4f} Acc:{train_acc:.4f} QWK:{train_qwk:.4f}\")\n        print(f\"Valid -> Loss:{val_loss:.4f} Acc:{val_acc:.4f} QWK:{val_qwk:.4f}\")\n        if val_qwk > best_val_qwk:\n            print(f\"Val QWK improved from {best_val_qwk:.4f} to {val_qwk:.4f}. Saving model...\")\n            best_val_qwk, patience_counter = val_qwk, 0\n            torch.save(model.state_dict(), CFG.SAVE_PATH_S1)\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.PATIENCE: \n                print(\"Early stopping in Stage 1.\")\n                break\n    \n    # --- STAGE 2 ---\n    print(\"\\n\" + \"=\"*50 + \"\\n     STARTING STAGE 2 (4-Channel)\\n\" + \"=\"*50)\n    if os.path.exists(CFG.SAVE_PATH_S1):\n        model.load_state_dict(torch.load(CFG.SAVE_PATH_S1))\n    else:\n        print(\"No Stage 1 model was saved. Continuing with the current model.\")\n\n    opt = optim.AdamW(model.parameters(), lr=CFG.S2_LR, weight_decay=1e-5)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG.S2_EPOCHS)\n    best_val_qwk_stage2, patience_counter = best_val_qwk, 0\n\n    for epoch in range(CFG.S2_EPOCHS):\n        clear_memory()\n        print(f\"\\nEpoch {epoch+1}/{CFG.S2_EPOCHS}\")\n        train_loss, train_acc, train_qwk = train_epoch(model, train_loader, opt, hybrid_loss, scaler, CFG.DEVICE, CFG.S2_USE_MIXUP)\n        val_loss, val_acc, val_qwk = validate_epoch(model, val_loader, hybrid_loss, CFG.DEVICE)\n        sched.step()\n        print(f\"Train -> Loss:{train_loss:.4f} Acc:{train_acc:.4f} QWK:{train_qwk:.4f}\")\n        print(f\"Valid -> Loss:{val_loss:.4f} Acc:{val_acc:.4f} QWK:{val_qwk:.4f}\")\n        if val_qwk > best_val_qwk_stage2:\n            print(f\"Val QWK improved from {best_val_qwk_stage2:.4f} to {val_qwk:.4f}. Saving final model...\")\n            best_val_qwk_stage2, patience_counter = val_qwk, 0\n            torch.save(model.state_dict(), CFG.SAVE_PATH_FINAL)\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.PATIENCE: \n                print(\"Early stopping in Stage 2.\")\n                break\n\n    print(f\"\\nTraining Finished!\\nFinal Best QWK: {best_val_qwk_stage2:.4f}\")\n\nif __name__ == \"__main__\":\n    main()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:47:37.975222Z","iopub.execute_input":"2025-09-14T18:47:37.976078Z","iopub.status.idle":"2025-09-14T20:59:20.528104Z","shell.execute_reply.started":"2025-09-14T18:47:37.976041Z","shell.execute_reply":"2025-09-14T20:59:20.527164Z"}},"outputs":[{"name":"stdout","text":"Device: cuda, Model: swinv2_tiny_window8_256 (4-Channel), Image Size: 256\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n/tmp/ipykernel_36/2405025121.py:239: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\n     STARTING STAGE 1 (4-Channel)\n==================================================\n\nEpoch 1/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.4892 Acc:0.2420 QWK:0.1556\nValid -> Loss:0.2857 Acc:0.1011 QWK:0.3169\nVal QWK improved from -1.0000 to 0.3169. Saving model...\n\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.4011 Acc:0.3177 QWK:0.3763\nValid -> Loss:0.1907 Acc:0.1393 QWK:0.5029\nVal QWK improved from 0.3169 to 0.5029. Saving model...\n\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.3521 Acc:0.3126 QWK:0.3832\nValid -> Loss:0.1717 Acc:0.1639 QWK:0.5995\nVal QWK improved from 0.5029 to 0.5995. Saving model...\n\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.3602 Acc:0.3345 QWK:0.4180\nValid -> Loss:0.1516 Acc:0.1913 QWK:0.6417\nVal QWK improved from 0.5995 to 0.6417. Saving model...\n\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.3431 Acc:0.3454 QWK:0.4303\nValid -> Loss:0.1581 Acc:0.1995 QWK:0.3942\n\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.3241 Acc:0.3509 QWK:0.3881\nValid -> Loss:0.1363 Acc:0.2131 QWK:0.6549\nVal QWK improved from 0.6417 to 0.6549. Saving model...\n\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2821 Acc:0.3823 QWK:0.4448\nValid -> Loss:0.1677 Acc:0.3142 QWK:0.6854\nVal QWK improved from 0.6549 to 0.6854. Saving model...\n\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2698 Acc:0.3850 QWK:0.4390\nValid -> Loss:0.1451 Acc:0.4918 QWK:0.7530\nVal QWK improved from 0.6854 to 0.7530. Saving model...\n\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2642 Acc:0.4044 QWK:0.4384\nValid -> Loss:0.1356 Acc:0.3415 QWK:0.7093\n\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2483 Acc:0.4184 QWK:0.4478\nValid -> Loss:0.1353 Acc:0.4126 QWK:0.7224\n\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2356 Acc:0.4331 QWK:0.4719\nValid -> Loss:0.1596 Acc:0.5328 QWK:0.7491\n\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2216 Acc:0.4440 QWK:0.4872\nValid -> Loss:0.1356 Acc:0.4781 QWK:0.7549\nVal QWK improved from 0.7530 to 0.7549. Saving model...\n\nEpoch 13/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd59aba0cb9b442a84ed68ec1751f358"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca9beec627842ae8bf7aa7a053aa7f7"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2208 Acc:0.4621 QWK:0.4832\nValid -> Loss:0.1372 Acc:0.4672 QWK:0.7574\nVal QWK improved from 0.7549 to 0.7574. Saving model...\n\nEpoch 14/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acdf4697c0d7487cb89495bcc3874a23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4e49bd8ca9c42d7966ab4e6c7153a76"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2006 Acc:0.4611 QWK:0.4886\nValid -> Loss:0.1448 Acc:0.4153 QWK:0.7354\n\nEpoch 15/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b5280c291741fdb3ff0d88e576dbbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f2d91954fe94b0581ee2c0d035d745e"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2157 Acc:0.4526 QWK:0.4680\nValid -> Loss:0.1413 Acc:0.4235 QWK:0.7406\n\n==================================================\n     STARTING STAGE 2 (4-Channel)\n==================================================\n\nEpoch 1/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78d97607a6964a72a4bf9c87ca2a01d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ab02fa3953142a8902f819941614ead"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1433 Acc:0.7737 QWK:0.9245\nValid -> Loss:0.1969 Acc:0.7322 QWK:0.8661\nVal QWK improved from 0.7574 to 0.8661. Saving final model...\n\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be617c0acefa45bc8b1938311d0466d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db837f6cfdca4fdaaf563de79a24cc2b"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1183 Acc:0.8109 QWK:0.9389\nValid -> Loss:0.1817 Acc:0.7650 QWK:0.8882\nVal QWK improved from 0.8661 to 0.8882. Saving final model...\n\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1195 Acc:0.8177 QWK:0.9408\nValid -> Loss:0.1917 Acc:0.7049 QWK:0.8662\n\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1141 Acc:0.8235 QWK:0.9452\nValid -> Loss:0.1831 Acc:0.7213 QWK:0.8712\n\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1116 Acc:0.8287 QWK:0.9421\nValid -> Loss:0.1773 Acc:0.7705 QWK:0.8976\nVal QWK improved from 0.8882 to 0.8976. Saving final model...\n\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1132 Acc:0.8307 QWK:0.9388\nValid -> Loss:0.1944 Acc:0.7350 QWK:0.8707\n\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1021 Acc:0.8553 QWK:0.9514\nValid -> Loss:0.1767 Acc:0.7896 QWK:0.8886\n\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0960 Acc:0.8580 QWK:0.9540\nValid -> Loss:0.1629 Acc:0.7869 QWK:0.8984\nVal QWK improved from 0.8976 to 0.8984. Saving final model...\n\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0815 Acc:0.8717 QWK:0.9587\nValid -> Loss:0.1668 Acc:0.7869 QWK:0.8946\n\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0797 Acc:0.8741 QWK:0.9617\nValid -> Loss:0.1749 Acc:0.7923 QWK:0.8982\n\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0756 Acc:0.8891 QWK:0.9675\nValid -> Loss:0.1763 Acc:0.8060 QWK:0.8915\n\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0740 Acc:0.8925 QWK:0.9652\nValid -> Loss:0.1715 Acc:0.8087 QWK:0.9008\nVal QWK improved from 0.8984 to 0.9008. Saving final model...\n\nEpoch 13/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0693 Acc:0.8980 QWK:0.9691\nValid -> Loss:0.1660 Acc:0.8142 QWK:0.9057\nVal QWK improved from 0.9008 to 0.9057. Saving final model...\n\nEpoch 14/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0680 Acc:0.9038 QWK:0.9726\nValid -> Loss:0.1627 Acc:0.8060 QWK:0.9034\n\nEpoch 15/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/1163770134.py:282: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0695 Acc:0.9000 QWK:0.9680\nValid -> Loss:0.1634 Acc:0.8060 QWK:0.9031\n\nTraining Finished!\nFinal Best QWK: 0.9057\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os, cv2, torch\nimport numpy as np, pandas as pd\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, cohen_kappa_score\n\n# نفس الداتا ستراكشر بس من غير label\nclass DatasetDualStreamTest(Dataset):\n    def __init__(self, df, img_dir, seg_dir, transform=None):\n        self.df, self.img_dir, self.seg_dir, self.transform = df.reset_index(drop=True), img_dir, seg_dir, transform\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id_code'] + '.png')\n        seg_path = os.path.join(self.seg_dir, row['id_code'] + '.png')\n\n        img = cv2.imread(img_path); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(seg_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (CFG.IMG_SIZE, CFG.IMG_SIZE))\n        mask = cv2.resize(mask, (CFG.IMG_SIZE, CFG.IMG_SIZE))\n\n        if self.transform:\n            augmented = self.transform(image=img, mask=mask)\n            img, mask = augmented['image'], augmented['mask']\n\n        img = A.Normalize()(image=img)['image']\n        img = ToTensorV2()(image=img)['image']\n        mask = torch.tensor((mask / 255.0)[None, :, :], dtype=torch.float)\n\n        return img, mask, row.get('diagnosis', -1), row['id_code']\n\n# --- Load Test Data\ntest_df = pd.read_csv(\"/kaggle/input/aptos2019/test.csv\")\nhas_labels = 'diagnosis' in test_df.columns\n\ntest_ds = DatasetDualStreamTest(\n    test_df,\n    \"/kaggle/input/aptos2019/test_images/test_images\",\n    \"/kaggle/input/aptos-2019-dataset-vessel-segmentation/segmented_outputs_test/segmented_outputs_test\",\n    transform=None\n)\ntest_loader = DataLoader(test_ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=CFG.NUM_WORKERS)\n\n# --- Define Model again (DualStreamSwin)\nmodel = DualStreamSwin(\n    model_name=\"swinv2_tiny_window8_256\",\n    num_classes=5,\n    pretrained=False\n).to(CFG.DEVICE)\n\n# --- Load weights\nmodel.load_state_dict(torch.load(CFG.SAVE_PATH_FINAL, map_location=CFG.DEVICE))\nmodel.eval()\n\n# --- Inference\nall_preds, all_labels, all_ids = [], [], []\nwith torch.no_grad():\n    for img_rgb, mask, labels, ids in tqdm(test_loader, desc=\"Test Inference\"):\n        img_rgb, mask = img_rgb.to(CFG.DEVICE), mask.to(CFG.DEVICE)\n        outputs = model(img_rgb, mask)\n        preds = ordinal_to_class(outputs).cpu().numpy()\n        all_preds.extend(preds); all_ids.extend(ids)\n\n        if has_labels:\n            all_labels.extend(labels.numpy())\n\n# --- Metrics\nif has_labels:\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    recall = recall_score(all_labels, all_preds, average='macro')\n    precision = precision_score(all_labels, all_preds, average='macro')\n    qwk = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n\n    print(f\"Accuracy : {acc:.4f}\")\n    print(f\"F1 Score : {f1:.4f}\")\n    print(f\"Recall   : {recall:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"QWK      : {qwk:.4f}\")\nelse:\n    sub = pd.DataFrame({\"id_code\": all_ids, \"diagnosis\": all_preds})\n    sub.to_csv(\"submission.csv\", index=False)\n    print(\"Submission file saved: submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T21:02:29.155795Z","iopub.execute_input":"2025-09-14T21:02:29.156665Z","iopub.status.idle":"2025-09-14T21:02:56.316514Z","shell.execute_reply.started":"2025-09-14T21:02:29.156635Z","shell.execute_reply":"2025-09-14T21:02:56.315500Z"}},"outputs":[{"name":"stderr","text":"Test Inference: 100%|██████████| 46/46 [00:25<00:00,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy : 0.8005\nF1 Score : 0.6526\nRecall   : 0.6710\nPrecision: 0.6680\nQWK      : 0.9088\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}