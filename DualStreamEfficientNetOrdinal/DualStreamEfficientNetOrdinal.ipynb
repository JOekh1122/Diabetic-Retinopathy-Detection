{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"de6e6ba0","cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport timm\n\n# =============================================================================\n# CONFIGURATION FOR 4-CHANNEL (IMAGE + VESSEL MASK) INPUT\n# =============================================================================\nclass CFG:\n    # --- MODEL & IMAGE SIZE (Same as your baseline EffNet-B3) ---\n    MODEL_NAME = 'efficientnet_b3'\n    IMG_SIZE = 384\n    BATCH_SIZE = 8\n\n    # --- DATA PATHS ---\n    BASE_PATH = \"/kaggle/input/aptos2019\"\n    TRAIN_CSV = os.path.join(BASE_PATH, \"train_1.csv\")\n    VAL_CSV   = os.path.join(BASE_PATH, \"valid.csv\")\n    TRAIN_DIR = os.path.join(BASE_PATH, \"train_images\", \"train_images\")\n    VAL_DIR   = os.path.join(BASE_PATH, \"val_images\", \"val_images\")\n    \n    # --- PATHS TO YOUR NEW SEGMENTED MASKS ---\n    SEG_BASE_PATH = \"/kaggle/input/segmentaion-dataset/\"\n    SEG_TRAIN_DIR = os.path.join(SEG_BASE_PATH, \"segmented_outputs_train_1/segmented_outputs_train_1/\")\n    SEG_VAL_DIR   = os.path.join(SEG_BASE_PATH, \"segmented_outputs_val/segmented_outputs_val/\")\n\n    # --- TRAINING PIPELINE (Identical to your successful run for fair comparison) ---\n    S1_EPOCHS = 15; S1_LR = 1e-4; S1_USE_MIXUP = True\n    S2_EPOCHS = 15; S2_LR = 3e-5; S2_USE_MIXUP = False\n    \n    # --- GENERAL & SAVING ---\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    NUM_WORKERS = 2\n    PATIENCE = 5\n    SEED = 42\n    LABEL_SMOOTHING = 0.05\n    # New save paths for this experiment\n    SAVE_PATH_S1 = \"best_model_effnet_b3_seg_stage1.pth\"\n    SAVE_PATH_FINAL = \"best_model_effnet_b3_seg_final.pth\"\n\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = True\nseed_everything(CFG.SEED)\n\n# =============================================================================\n# PREPROCESSING & AUGMENTATIONS (CORRECTED LOGIC)\n# =============================================================================\ndef preprocess_ben_graham(image, output_size):\n    # This function only preprocesses the 3-channel image\n    try:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        if gray.mean() < 15: \n            image = cv2.resize(image, (output_size, output_size), interpolation=cv2.INTER_AREA)\n        else:\n            _, thresh = cv2.threshold(gray, 15, 255, cv2.THRESH_BINARY)\n            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            if contours:\n                largest_contour = max(contours, key=cv2.contourArea)\n                x, y, w, h = cv2.boundingRect(largest_contour)\n                image = image[y:y+h, x:x+w]\n            image = cv2.resize(image, (output_size, output_size), interpolation=cv2.INTER_AREA)\n    except Exception: \n        image = cv2.resize(image, (output_size, output_size), interpolation=cv2.INTER_AREA)\n    \n    b, g, r = cv2.split(image)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    g = clahe.apply(g)\n    \n    return cv2.merge((b, g, r))\n\ndef get_transforms(is_train=True):\n    # This pipeline now only contains augmentations. Preprocessing happens before.\n    if is_train:\n        return A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.7),\n            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n        ])\n    else:\n        # No augmentations for validation/test\n        return None\n\n# =============================================================================\n# UPGRADED DATASET (CORRECTED LOGIC)\n# =============================================================================\nclass Dataset4Channel(Dataset):\n    def __init__(self, df, img_dir, seg_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.seg_dir = seg_dir\n        self.transform = transform\n        # The final normalization/tensor conversion is always applied\n        self.post_transform = A.Compose([\n            A.Normalize(mean=[0.485, 0.456, 0.406, 0.5], std=[0.229, 0.224, 0.225, 0.5]),\n            ToTensorV2()\n        ])\n\n    def __len__(self): \n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['id_code'] + '.png')\n        seg_path = os.path.join(self.seg_dir, row['id_code'] + '.png')\n        \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        mask = cv2.imread(seg_path, cv2.IMREAD_GRAYSCALE)\n        \n        # Step 1: Apply preprocessing to the 3-channel RGB image first\n        img = preprocess_ben_graham(img, CFG.IMG_SIZE)\n        \n        # Step 2: Resize the mask to the exact same size to ensure alignment\n        mask = cv2.resize(mask, (CFG.IMG_SIZE, CFG.IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n        \n        # Step 3: Apply geometric and color augmentations to the ALIGNED pair\n        if self.transform:\n            augmented = self.transform(image=img, mask=mask)\n            img = augmented['image']\n            mask = augmented['mask']\n            \n        # Step 4: Add the mask as the 4th channel\n        img_4_channel = np.dstack((img, mask))\n        \n        # Step 5: Apply final normalization and convert to tensor\n        img_4_channel = self.post_transform(image=img_4_channel)['image']\n            \n        label = torch.tensor(row['diagnosis'], dtype=torch.long)\n        return img_4_channel, label\n\n# =============================================================================\n# UPGRADED MODEL TO ACCEPT 4 CHANNELS (Unchanged, was already correct)\n# =============================================================================\nclass DualStreamEfficientNetOrdinal(nn.Module):\n    def __init__(self, model_name=\"efficientnet_b3\", num_classes=5, pretrained=True):\n        super().__init__()\n        # --- RGB branch (keep pretrained EfficientNet) ---\n        self.rgb_backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n        rgb_dim = self.rgb_backbone.num_features\n\n        # --- Mask branch (tiny CNN encoder) ---\n        self.mask_encoder = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1, 1))\n        )\n        mask_dim = 32\n\n        # --- Fusion head ---\n        fusion_dim = rgb_dim + mask_dim\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(fusion_dim, 256), nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes - 1)\n        )\n\n    def forward(self, x):\n        # Split input: RGB (first 3 channels), Mask (last channel)\n        rgb = x[:, :3, :, :]\n        mask = x[:, 3:, :, :]\n\n        # Forward pass\n        rgb_feat = self.rgb_backbone(rgb)                  # [B, rgb_dim]\n        mask_feat = self.mask_encoder(mask).flatten(1)     # [B, mask_dim]\n\n        fused = torch.cat([rgb_feat, mask_feat], dim=1)    # concat features\n        return self.classifier(fused)\n\n# --- Loss functions, training loops, and other utilities are unchanged ---\nclass WeightedOrdinalFocalLoss(nn.Module):\n    def __init__(self, num_classes=5, gamma=2.0, class_weights=None, label_smoothing=0.0):\n        super().__init__()\n        self.num_classes, self.gamma, self.class_weights, self.label_smoothing = num_classes, gamma, class_weights, label_smoothing\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n    def forward(self, outputs, targets):\n        ordinal_targets = torch.zeros_like(outputs)\n        for i, t in enumerate(targets):\n            if t > 0: ordinal_targets[i, :t] = 1.0\n        if self.label_smoothing > 0.0: ordinal_targets = ordinal_targets * (1.0 - self.label_smoothing) + 0.5 * self.label_smoothing\n        bce = self.bce(outputs, ordinal_targets)\n        if self.class_weights is not None:\n            weights = self.class_weights[targets].view(-1, 1).expand(-1, outputs.shape[1])\n            bce = bce * weights\n        pt = torch.exp(-bce)\n        focal = (1 - pt) ** self.gamma * bce\n        return focal.mean()\n\nclass SmoothKappaLoss(nn.Module):\n    def __init__(self, num_classes=5, eps=1e-7):\n        super().__init__()\n        self.num_classes, self.eps = num_classes, eps\n        W = torch.zeros(num_classes, num_classes)\n        for i in range(num_classes):\n            for j in range(num_classes): W[i,j] = ((i - j)**2) / ((num_classes - 1)**2)\n        self.register_buffer(\"W\", W)\n    def forward(self, outputs, targets):\n        device = outputs.device; B = outputs.size(0); probs = torch.sigmoid(outputs)\n        class_probs = torch.zeros(B, self.num_classes, device=device)\n        class_probs[:, 0] = 1 - probs[:, 0]\n        for k in range(1, self.num_classes-1): class_probs[:, k] = probs[:, k-1] - probs[:, k]\n        class_probs[:, -1] = probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=self.eps, max=1.0)\n        one_hot = F.one_hot(targets, num_classes=self.num_classes).float().to(device)\n        conf_mat = torch.matmul(one_hot.T, class_probs)\n        hist_true = one_hot.sum(dim=0); hist_pred = class_probs.sum(dim=0)\n        expected = torch.outer(hist_true, hist_pred)\n        W = self.W.to(device); obs = torch.sum(W * conf_mat); exp = torch.sum(W * expected)\n        kappa = 1.0 - (B * obs) / (exp + self.eps)\n        return 1.0 - kappa\n\ndef mixup_data(x, y, alpha=0.4):\n    if alpha > 0: lam = np.random.beta(alpha, alpha)\n    else: lam = 1\n    batch_size = x.size()[0]; index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef ordinal_to_class(outputs): \n    return torch.sum(torch.sigmoid(outputs) > 0.5, dim=1).long()\n\ndef calculate_metrics(outputs, targets):\n    preds = ordinal_to_class(outputs).cpu().numpy()\n    targets_np = targets.cpu().numpy()\n    return accuracy_score(targets_np, preds), cohen_kappa_score(targets_np, preds, weights='quadratic')\n\ndef clear_memory(): \n    gc.collect()\n    torch.cuda.empty_cache()\n\ndef train_epoch(model, loader, optimizer, criterion, scaler, device, use_mixup):\n    model.train(); running_loss = 0.0; all_out, all_t = [], []\n    pbar = tqdm(loader, desc=\"Training\", leave=False)\n    for images, targets in pbar:\n        images, targets = images.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n        if use_mixup: images, targets_a, targets_b, lam = mixup_data(images, targets)\n        with torch.cuda.amp.autocast():\n            outputs = model(images)\n            if use_mixup: loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n            else: loss = criterion(outputs, targets)\n        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n        running_loss += loss.item(); all_out.append(outputs.detach()); all_t.append(targets.detach())\n        pbar.set_postfix(loss=loss.item())\n    all_out, all_t = torch.cat(all_out), torch.cat(all_t)\n    return running_loss / len(loader), *calculate_metrics(all_out, all_t)\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval(); running_loss = 0.0; all_out, all_t = [], []\n    with torch.no_grad():\n        pbar = tqdm(loader, desc=\"Validating\", leave=False)\n        for images, targets in pbar:\n            images, targets = images.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n                loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            all_out.append(outputs)\n            all_t.append(targets)\n    all_out, all_t = torch.cat(all_out), torch.cat(all_t)\n    return running_loss / len(loader), *calculate_metrics(all_out, all_t)\n\ndef main():\n    print(f\"Device: {CFG.DEVICE}, Model: {CFG.MODEL_NAME} (4-Channel), Image Size: {CFG.IMG_SIZE}\")\n    train_df = pd.read_csv(CFG.TRAIN_CSV)\n    val_df = pd.read_csv(CFG.VAL_CSV)\n    \n    train_tf = get_transforms(is_train=True)\n    val_tf = get_transforms(is_train=False)\n\n    train_ds = Dataset4Channel(train_df, CFG.TRAIN_DIR, CFG.SEG_TRAIN_DIR, transform=train_tf)\n    val_ds   = Dataset4Channel(val_df, CFG.VAL_DIR, CFG.SEG_VAL_DIR, transform=val_tf)\n\n    class_weights_sampler = compute_class_weight('balanced', classes=np.unique(train_df['diagnosis']), y=train_df['diagnosis'])\n    sample_weights = np.array([class_weights_sampler[int(l)] for l in train_df['diagnosis']])\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n    train_loader = DataLoader(train_ds, batch_size=CFG.BATCH_SIZE, sampler=sampler, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE*2, shuffle=False, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n    \n    model = DualStreamEfficientNetOrdinal(CFG.MODEL_NAME).to(CFG.DEVICE)\n    class_weights_loss = torch.tensor(class_weights_sampler, dtype=torch.float).to(CFG.DEVICE)\n    focal_loss = WeightedOrdinalFocalLoss(num_classes=5, gamma=2.0, class_weights=class_weights_loss, label_smoothing=CFG.LABEL_SMOOTHING)\n    kappa_loss = SmoothKappaLoss(num_classes=5)\n    \n    def hybrid_loss(outputs, targets): \n        return 0.7 * kappa_loss(outputs, targets) + 0.3 * focal_loss(outputs, targets)\n    \n    scaler = torch.cuda.amp.GradScaler()\n\n    # --- STAGE 1 ---\n    print(\"\\n\" + \"=\"*50 + \"\\n     STARTING STAGE 1 (4-Channel)\\n\" + \"=\"*50)\n    opt = optim.AdamW(model.parameters(), lr=CFG.S1_LR, weight_decay=1e-4)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG.S1_EPOCHS)\n    best_val_qwk, patience_counter = -1, 0\n\n    for epoch in range(CFG.S1_EPOCHS):\n        clear_memory()\n        print(f\"\\nEpoch {epoch+1}/{CFG.S1_EPOCHS}\")\n        train_loss, train_acc, train_qwk = train_epoch(model, train_loader, opt, focal_loss, scaler, CFG.DEVICE, CFG.S1_USE_MIXUP)\n        val_loss, val_acc, val_qwk = validate_epoch(model, val_loader, focal_loss, CFG.DEVICE)\n        sched.step()\n        print(f\"Train -> Loss:{train_loss:.4f} Acc:{train_acc:.4f} QWK:{train_qwk:.4f}\")\n        print(f\"Valid -> Loss:{val_loss:.4f} Acc:{val_acc:.4f} QWK:{val_qwk:.4f}\")\n        if val_qwk > best_val_qwk:\n            print(f\"Val QWK improved from {best_val_qwk:.4f} to {val_qwk:.4f}. Saving model...\")\n            best_val_qwk, patience_counter = val_qwk, 0\n            torch.save(model.state_dict(), CFG.SAVE_PATH_S1)\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.PATIENCE: \n                print(\"Early stopping in Stage 1.\")\n                break\n    \n    # --- STAGE 2 ---\n    print(\"\\n\" + \"=\"*50 + \"\\n     STARTING STAGE 2 (4-Channel)\\n\" + \"=\"*50)\n    if os.path.exists(CFG.SAVE_PATH_S1):\n        model.load_state_dict(torch.load(CFG.SAVE_PATH_S1))\n    else:\n        print(\"No Stage 1 model was saved. Continuing with the current model.\")\n\n    opt = optim.AdamW(model.parameters(), lr=CFG.S2_LR, weight_decay=1e-5)\n    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG.S2_EPOCHS)\n    best_val_qwk_stage2, patience_counter = best_val_qwk, 0\n\n    for epoch in range(CFG.S2_EPOCHS):\n        clear_memory()\n        print(f\"\\nEpoch {epoch+1}/{CFG.S2_EPOCHS}\")\n        train_loss, train_acc, train_qwk = train_epoch(model, train_loader, opt, hybrid_loss, scaler, CFG.DEVICE, CFG.S2_USE_MIXUP)\n        val_loss, val_acc, val_qwk = validate_epoch(model, val_loader, hybrid_loss, CFG.DEVICE)\n        sched.step()\n        print(f\"Train -> Loss:{train_loss:.4f} Acc:{train_acc:.4f} QWK:{train_qwk:.4f}\")\n        print(f\"Valid -> Loss:{val_loss:.4f} Acc:{val_acc:.4f} QWK:{val_qwk:.4f}\")\n        if val_qwk > best_val_qwk_stage2:\n            print(f\"Val QWK improved from {best_val_qwk_stage2:.4f} to {val_qwk:.4f}. Saving final model...\")\n            best_val_qwk_stage2, patience_counter = val_qwk, 0\n            torch.save(model.state_dict(), CFG.SAVE_PATH_FINAL)\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.PATIENCE: \n                print(\"Early stopping in Stage 2.\")\n                break\n\n    print(f\"\\nTraining Finished!\\nFinal Best QWK: {best_val_qwk_stage2:.4f}\")\n\nif __name__ == \"__main__\":\n    main()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T20:39:04.995940Z","iopub.execute_input":"2025-09-13T20:39:04.996184Z","iopub.status.idle":"2025-09-13T23:18:49.698893Z","shell.execute_reply.started":"2025-09-13T20:39:04.996164Z","shell.execute_reply":"2025-09-13T23:18:49.697766Z"}},"outputs":[{"name":"stdout","text":"Device: cuda, Model: efficientnet_b3 (4-Channel), Image Size: 384\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b52a85dce6104ea4acb5bad39fa54419"}},"metadata":{}},{"name":"stdout","text":"\n==================================================\n     STARTING STAGE 1 (4-Channel)\n==================================================\n\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:309: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.4256 Acc:0.2416 QWK:0.1768\nValid -> Loss:0.1539 Acc:0.2049 QWK:0.6408\nVal QWK improved from -1.0000 to 0.6408. Saving model...\n\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.3467 Acc:0.3150 QWK:0.3239\nValid -> Loss:0.1462 Acc:0.1940 QWK:0.5640\n\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.3244 Acc:0.3567 QWK:0.3513\nValid -> Loss:0.1392 Acc:0.2022 QWK:0.6446\nVal QWK improved from 0.6408 to 0.6446. Saving model...\n\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2743 Acc:0.3898 QWK:0.3980\nValid -> Loss:0.1471 Acc:0.2514 QWK:0.6881\nVal QWK improved from 0.6446 to 0.6881. Saving model...\n\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2600 Acc:0.4017 QWK:0.4168\nValid -> Loss:0.1403 Acc:0.2158 QWK:0.6644\n\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2404 Acc:0.3959 QWK:0.4114\nValid -> Loss:0.1420 Acc:0.2186 QWK:0.6657\n\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2313 Acc:0.4218 QWK:0.4524\nValid -> Loss:0.1412 Acc:0.2486 QWK:0.6343\n\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2114 Acc:0.4263 QWK:0.4556\nValid -> Loss:0.1276 Acc:0.2186 QWK:0.6774\n\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2150 Acc:0.4126 QWK:0.4353\nValid -> Loss:0.1335 Acc:0.2541 QWK:0.6955\nVal QWK improved from 0.6881 to 0.6955. Saving model...\n\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1925 Acc:0.4549 QWK:0.5055\nValid -> Loss:0.1329 Acc:0.2678 QWK:0.6656\n\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2007 Acc:0.4338 QWK:0.4488\nValid -> Loss:0.1316 Acc:0.2678 QWK:0.6556\n\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2076 Acc:0.4321 QWK:0.4612\nValid -> Loss:0.1331 Acc:0.2896 QWK:0.6872\n\nEpoch 13/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1992 Acc:0.4502 QWK:0.4700\nValid -> Loss:0.1314 Acc:0.2923 QWK:0.7030\nVal QWK improved from 0.6955 to 0.7030. Saving model...\n\nEpoch 14/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1863 Acc:0.4225 QWK:0.4509\nValid -> Loss:0.1286 Acc:0.2869 QWK:0.6901\n\nEpoch 15/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.2018 Acc:0.4382 QWK:0.4524\nValid -> Loss:0.1281 Acc:0.3005 QWK:0.6760\n\n==================================================\n     STARTING STAGE 2 (4-Channel)\n==================================================\n\nEpoch 1/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1650 Acc:0.7140 QWK:0.9097\nValid -> Loss:0.2017 Acc:0.7049 QWK:0.8843\nVal QWK improved from 0.7030 to 0.8843. Saving final model...\n\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.1088 Acc:0.8232 QWK:0.9488\nValid -> Loss:0.1678 Acc:0.7678 QWK:0.8978\nVal QWK improved from 0.8843 to 0.8978. Saving final model...\n\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0894 Acc:0.8652 QWK:0.9605\nValid -> Loss:0.1711 Acc:0.7896 QWK:0.9042\nVal QWK improved from 0.8978 to 0.9042. Saving final model...\n\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0837 Acc:0.8857 QWK:0.9655\nValid -> Loss:0.1663 Acc:0.7732 QWK:0.8959\n\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0825 Acc:0.8843 QWK:0.9640\nValid -> Loss:0.1646 Acc:0.7814 QWK:0.9101\nVal QWK improved from 0.9042 to 0.9101. Saving final model...\n\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0763 Acc:0.9003 QWK:0.9716\nValid -> Loss:0.1651 Acc:0.7896 QWK:0.9048\n\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0715 Acc:0.9034 QWK:0.9708\nValid -> Loss:0.1641 Acc:0.7951 QWK:0.9068\n\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0729 Acc:0.9017 QWK:0.9706\nValid -> Loss:0.1589 Acc:0.8033 QWK:0.9121\nVal QWK improved from 0.9101 to 0.9121. Saving final model...\n\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0697 Acc:0.9191 QWK:0.9743\nValid -> Loss:0.1699 Acc:0.8005 QWK:0.9101\n\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0617 Acc:0.9222 QWK:0.9764\nValid -> Loss:0.1628 Acc:0.8115 QWK:0.9125\nVal QWK improved from 0.9121 to 0.9125. Saving final model...\n\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0583 Acc:0.9253 QWK:0.9794\nValid -> Loss:0.1630 Acc:0.8005 QWK:0.9094\n\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0602 Acc:0.9208 QWK:0.9787\nValid -> Loss:0.1680 Acc:0.8005 QWK:0.9047\n\nEpoch 13/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0623 Acc:0.9242 QWK:0.9775\nValid -> Loss:0.1737 Acc:0.8033 QWK:0.9082\n\nEpoch 14/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0613 Acc:0.9195 QWK:0.9780\nValid -> Loss:0.1657 Acc:0.8060 QWK:0.9118\n\nEpoch 15/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/367 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/3244942555.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Train -> Loss:0.0628 Acc:0.9253 QWK:0.9774\nValid -> Loss:0.1626 Acc:0.8115 QWK:0.9124\nEarly stopping in Stage 2.\n\nTraining Finished!\nFinal Best QWK: 0.9125\n","output_type":"stream"}],"execution_count":1},{"id":"d43de2a1-31b6-478f-a656-94c49d80b115","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
